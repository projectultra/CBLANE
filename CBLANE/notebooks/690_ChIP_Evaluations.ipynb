{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QY3-eZNrvuKm",
        "EPZmTTGRvqsY",
        "_5cHHVvZuFvP",
        "nGaJo4PHumvM",
        "hvyeuCc3zTw7",
        "BC2UGUhourg8",
        "OC8HM0gNu5ct",
        "86BPvM97vArD",
        "L0wswARgzMj5",
        "P5lzNACDvFBA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Large Datasets"
      ],
      "metadata": {
        "id": "2J3FZ--Gou9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning"
      ],
      "metadata": {
        "id": "Rds7xsPE0QG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aoo6WaspsZGD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, features_path, labels_path, batch_size):\n",
        "        self.features = np.load(features_path)\n",
        "        self.labels = np.load(labels_path)\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.features))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.features) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = (index + 1) * self.batch_size\n",
        "        batch_features = self.features[start:end]\n",
        "        batch_labels = self.labels[start:end]\n",
        "        return batch_features, batch_labels\n",
        "\n",
        "# Example usage:\n",
        "train_features_path = \"train_features.npy\"\n",
        "train_labels_path = \"train_labels.npy\"\n",
        "batch_size = 4096\n",
        "\n",
        "train_generator = DataGenerator(train_features_path, train_labels_path, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD2K9SJKsjwD",
        "outputId": "366c0382-9001-45c1-c891-6b643d594f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "   6/3519 [..............................] - ETA: 36:22 - loss: 0.4004 - binary_accuracy: 0.8142 - auc: 0.8986"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2287s vs `on_train_batch_end` time: 0.3262s). Check your callbacks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3519/3519 [==============================] - 2301s 648ms/step - loss: 0.2629 - binary_accuracy: 0.8887 - auc: 0.9572\n",
            "Epoch 2/30\n",
            "3519/3519 [==============================] - 2275s 647ms/step - loss: 0.2282 - binary_accuracy: 0.9052 - auc: 0.9678\n",
            "Epoch 3/30\n",
            "3519/3519 [==============================] - 2275s 647ms/step - loss: 0.2174 - binary_accuracy: 0.9103 - auc: 0.9707\n",
            "Epoch 4/30\n",
            "2224/3519 [=================>............] - ETA: 13:57 - loss: 0.2113 - binary_accuracy: 0.9132 - auc: 0.9723"
          ]
        }
      ],
      "source": [
        "CBLANE = load_model(\"CBLANEFT.keras\")\n",
        "CBLANE.compile(loss='binary_crossentropy',\n",
        "                             optimizer=Adam(learning_rate=0.001),\n",
        "                             metrics=[BinaryAccuracy(),\n",
        "                                      AUC()]\n",
        "                             )\n",
        "history = CBLANE.fit(train_generator,\n",
        "                             epochs=30,\n",
        "                             verbose=1,\n",
        "                             callbacks=([\n",
        "                                         SaveSubModels()])\n",
        "                             )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Fine-Tuning"
      ],
      "metadata": {
        "id": "QY3-eZNrvuKm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSYbquhnlHUE",
        "outputId": "dc858e9a-538d-4ac6-c4c1-3dd7c5b12898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 1\n",
            "3/3 [==============================] - 8s 348ms/step - loss: 0.6136 - binary_accuracy: 0.7261 - auc: 0.8609\n",
            "Dataset: 2\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.1572 - binary_accuracy: 0.9421 - auc: 0.9869\n",
            "Dataset: 3\n",
            "7/7 [==============================] - 2s 355ms/step - loss: 0.3625 - binary_accuracy: 0.8385 - auc: 0.9365\n",
            "Dataset: 4\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.1841 - binary_accuracy: 0.9269 - auc: 0.9785\n",
            "Dataset: 5\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 0.3530 - binary_accuracy: 0.8424 - auc: 0.9308\n",
            "Dataset: 6\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3629 - binary_accuracy: 0.8458 - auc: 0.9294\n",
            "Dataset: 7\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.6040 - binary_accuracy: 0.7336 - auc: 0.8494\n",
            "Dataset: 8\n",
            "3/3 [==============================] - 1s 303ms/step - loss: 0.5761 - binary_accuracy: 0.7415 - auc: 0.8638\n",
            "Dataset: 9\n",
            "6/6 [==============================] - 2s 261ms/step - loss: 0.1591 - binary_accuracy: 0.9398 - auc: 0.9866\n",
            "Dataset: 10\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.1481 - binary_accuracy: 0.9461 - auc: 0.9891\n",
            "Dataset: 11\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.6128 - binary_accuracy: 0.7207 - auc: 0.8489\n",
            "Dataset: 12\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.4819 - binary_accuracy: 0.7814 - auc: 0.8964\n",
            "Dataset: 13\n",
            "3/3 [==============================] - 2s 920ms/step - loss: 0.1789 - binary_accuracy: 0.9301 - auc: 0.9797\n",
            "Dataset: 14\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.6007 - binary_accuracy: 0.7312 - auc: 0.8533\n",
            "Dataset: 15\n",
            "6/6 [==============================] - 3s 466ms/step - loss: 0.2191 - binary_accuracy: 0.9110 - auc: 0.9683\n",
            "Dataset: 16\n",
            "5/5 [==============================] - 2s 542ms/step - loss: 0.4276 - binary_accuracy: 0.8079 - auc: 0.9178\n",
            "Dataset: 17\n",
            "5/5 [==============================] - 2s 354ms/step - loss: 0.1527 - binary_accuracy: 0.9443 - auc: 0.9877\n",
            "Dataset: 18\n",
            "4/4 [==============================] - 2s 537ms/step - loss: 0.3401 - binary_accuracy: 0.8465 - auc: 0.9418\n",
            "Dataset: 19\n",
            "4/4 [==============================] - 2s 684ms/step - loss: 0.3667 - binary_accuracy: 0.8377 - auc: 0.9343\n",
            "Dataset: 20\n",
            "6/6 [==============================] - 2s 306ms/step - loss: 0.1512 - binary_accuracy: 0.9437 - auc: 0.9882\n",
            "Dataset: 21\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.2729 - binary_accuracy: 0.8833 - auc: 0.9561\n",
            "Dataset: 22\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 0.3544 - binary_accuracy: 0.8447 - auc: 0.9306\n",
            "Dataset: 23\n",
            "5/5 [==============================] - 1s 315ms/step - loss: 0.1474 - binary_accuracy: 0.9469 - auc: 0.9886\n",
            "Dataset: 24\n",
            "5/5 [==============================] - 2s 358ms/step - loss: 0.1460 - binary_accuracy: 0.9463 - auc: 0.9892\n",
            "Dataset: 25\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.1659 - binary_accuracy: 0.9385 - auc: 0.9835\n",
            "Dataset: 26\n",
            "5/5 [==============================] - 2s 500ms/step - loss: 0.1484 - binary_accuracy: 0.9451 - auc: 0.9899\n",
            "Dataset: 27\n",
            "5/5 [==============================] - 2s 572ms/step - loss: 0.2020 - binary_accuracy: 0.9201 - auc: 0.9729\n",
            "Dataset: 28\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5578 - binary_accuracy: 0.7447 - auc: 0.8701\n",
            "Dataset: 29\n",
            "3/3 [==============================] - 1s 453ms/step - loss: 0.1361 - binary_accuracy: 0.9512 - auc: 0.9925\n",
            "Dataset: 30\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.4607 - binary_accuracy: 0.8007 - auc: 0.9023\n",
            "Dataset: 31\n",
            "3/3 [==============================] - 2s 989ms/step - loss: 0.1644 - binary_accuracy: 0.9384 - auc: 0.9837\n",
            "Dataset: 32\n",
            "7/7 [==============================] - 2s 268ms/step - loss: 0.1709 - binary_accuracy: 0.9348 - auc: 0.9836\n",
            "Dataset: 33\n",
            "6/6 [==============================] - 1s 237ms/step - loss: 0.1754 - binary_accuracy: 0.9332 - auc: 0.9829\n",
            "Dataset: 34\n",
            "5/5 [==============================] - 2s 528ms/step - loss: 0.1534 - binary_accuracy: 0.9438 - auc: 0.9875\n",
            "Dataset: 35\n",
            "5/5 [==============================] - 2s 361ms/step - loss: 0.1476 - binary_accuracy: 0.9466 - auc: 0.9890\n",
            "Dataset: 36\n",
            "3/3 [==============================] - 2s 877ms/step - loss: 0.6278 - binary_accuracy: 0.7292 - auc: 0.8406\n",
            "Dataset: 37\n",
            "4/4 [==============================] - 1s 235ms/step - loss: 0.2321 - binary_accuracy: 0.9077 - auc: 0.9703\n",
            "Dataset: 38\n",
            "6/6 [==============================] - 2s 272ms/step - loss: 0.1916 - binary_accuracy: 0.9246 - auc: 0.9756\n",
            "Dataset: 39\n",
            "6/6 [==============================] - 2s 381ms/step - loss: 0.1402 - binary_accuracy: 0.9501 - auc: 0.9920\n",
            "Dataset: 40\n",
            "5/5 [==============================] - 1s 294ms/step - loss: 0.1764 - binary_accuracy: 0.9325 - auc: 0.9802\n",
            "Dataset: 41\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.3655 - binary_accuracy: 0.8357 - auc: 0.9357\n",
            "Dataset: 42\n",
            "3/3 [==============================] - 1s 635ms/step - loss: 0.3113 - binary_accuracy: 0.8655 - auc: 0.9451\n",
            "Dataset: 43\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 0.3456 - binary_accuracy: 0.8474 - auc: 0.9389\n",
            "Dataset: 44\n",
            "3/3 [==============================] - 2s 779ms/step - loss: 0.5685 - binary_accuracy: 0.7471 - auc: 0.8782\n",
            "Dataset: 45\n",
            "6/6 [==============================] - 1s 195ms/step - loss: 0.1412 - binary_accuracy: 0.9480 - auc: 0.9915\n",
            "Dataset: 46\n",
            "3/3 [==============================] - 1s 596ms/step - loss: 0.3801 - binary_accuracy: 0.8338 - auc: 0.9310\n",
            "Dataset: 47\n",
            "3/3 [==============================] - 2s 686ms/step - loss: 0.3390 - binary_accuracy: 0.8571 - auc: 0.9361\n",
            "Dataset: 48\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.5931 - binary_accuracy: 0.7333 - auc: 0.8572\n",
            "Dataset: 49\n",
            "6/6 [==============================] - 2s 383ms/step - loss: 0.1573 - binary_accuracy: 0.9402 - auc: 0.9870\n",
            "Dataset: 50\n",
            "7/7 [==============================] - 2s 271ms/step - loss: 0.1663 - binary_accuracy: 0.9374 - auc: 0.9847\n",
            "Dataset: 51\n",
            "4/4 [==============================] - 2s 517ms/step - loss: 0.1568 - binary_accuracy: 0.9400 - auc: 0.9862\n",
            "Dataset: 52\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.4734 - binary_accuracy: 0.7860 - auc: 0.8956\n",
            "Dataset: 53\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.3960 - binary_accuracy: 0.8190 - auc: 0.9269\n",
            "Dataset: 54\n",
            "4/4 [==============================] - 1s 374ms/step - loss: 0.1311 - binary_accuracy: 0.9534 - auc: 0.9929\n",
            "Dataset: 55\n",
            "5/5 [==============================] - 1s 219ms/step - loss: 0.2246 - binary_accuracy: 0.9110 - auc: 0.9682\n",
            "Dataset: 56\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.2762 - binary_accuracy: 0.8847 - auc: 0.9543\n",
            "Dataset: 57\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.1537 - binary_accuracy: 0.9434 - auc: 0.9883\n",
            "Dataset: 58\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.1390 - binary_accuracy: 0.9493 - auc: 0.9914\n",
            "Dataset: 59\n",
            "3/3 [==============================] - 2s 795ms/step - loss: 0.3511 - binary_accuracy: 0.8424 - auc: 0.9377\n",
            "Dataset: 60\n",
            "4/4 [==============================] - 2s 515ms/step - loss: 0.1495 - binary_accuracy: 0.9462 - auc: 0.9882\n",
            "Dataset: 61\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.4188 - binary_accuracy: 0.8122 - auc: 0.9187\n",
            "Dataset: 62\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.7155 - binary_accuracy: 0.6842 - auc: 0.8142\n",
            "Dataset: 63\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5625 - binary_accuracy: 0.7494 - auc: 0.8650\n",
            "Dataset: 64\n",
            "4/4 [==============================] - 3s 801ms/step - loss: 0.4421 - binary_accuracy: 0.8011 - auc: 0.9104\n",
            "Dataset: 65\n",
            "2/2 [==============================] - 0s 198ms/step - loss: 0.4560 - binary_accuracy: 0.7938 - auc: 0.9077\n",
            "Dataset: 66\n",
            "3/3 [==============================] - 1s 551ms/step - loss: 0.2851 - binary_accuracy: 0.8805 - auc: 0.9520\n",
            "Dataset: 67\n",
            "5/5 [==============================] - 1s 319ms/step - loss: 0.3733 - binary_accuracy: 0.8339 - auc: 0.9320\n",
            "Dataset: 68\n",
            "3/3 [==============================] - 2s 873ms/step - loss: 0.3756 - binary_accuracy: 0.8366 - auc: 0.9228\n",
            "Dataset: 69\n",
            "5/5 [==============================] - 1s 307ms/step - loss: 0.1480 - binary_accuracy: 0.9432 - auc: 0.9889\n",
            "Dataset: 70\n",
            "5/5 [==============================] - 2s 566ms/step - loss: 0.2275 - binary_accuracy: 0.9102 - auc: 0.9661\n",
            "Dataset: 71\n",
            "6/6 [==============================] - 3s 501ms/step - loss: 0.1716 - binary_accuracy: 0.9365 - auc: 0.9833\n",
            "Dataset: 72\n",
            "3/3 [==============================] - 1s 310ms/step - loss: 0.5587 - binary_accuracy: 0.7502 - auc: 0.8695\n",
            "Dataset: 73\n",
            "5/5 [==============================] - 2s 417ms/step - loss: 0.1489 - binary_accuracy: 0.9443 - auc: 0.9888\n",
            "Dataset: 74\n",
            "4/4 [==============================] - 2s 699ms/step - loss: 0.1899 - binary_accuracy: 0.9265 - auc: 0.9781\n",
            "Dataset: 75\n",
            "6/6 [==============================] - 2s 285ms/step - loss: 0.1418 - binary_accuracy: 0.9493 - auc: 0.9913\n",
            "Dataset: 76\n",
            "4/4 [==============================] - 1s 369ms/step - loss: 0.3518 - binary_accuracy: 0.8468 - auc: 0.9316\n",
            "Dataset: 77\n",
            "5/5 [==============================] - 2s 354ms/step - loss: 0.1511 - binary_accuracy: 0.9444 - auc: 0.9879\n",
            "Dataset: 78\n",
            "3/3 [==============================] - 1s 369ms/step - loss: 0.5085 - binary_accuracy: 0.7724 - auc: 0.8901\n",
            "Dataset: 79\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.2603 - binary_accuracy: 0.8932 - auc: 0.9621\n",
            "Dataset: 80\n",
            "5/5 [==============================] - 2s 349ms/step - loss: 0.1511 - binary_accuracy: 0.9440 - auc: 0.9881\n",
            "Dataset: 81\n",
            "6/6 [==============================] - 2s 400ms/step - loss: 0.2182 - binary_accuracy: 0.9123 - auc: 0.9708\n",
            "Dataset: 82\n",
            "3/3 [==============================] - 2s 725ms/step - loss: 0.5303 - binary_accuracy: 0.7604 - auc: 0.8864\n",
            "Dataset: 83\n",
            "5/5 [==============================] - 2s 457ms/step - loss: 0.1355 - binary_accuracy: 0.9520 - auc: 0.9925\n",
            "Dataset: 84\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.4820 - binary_accuracy: 0.7807 - auc: 0.8975\n",
            "Dataset: 85\n",
            "3/3 [==============================] - 1s 620ms/step - loss: 0.5835 - binary_accuracy: 0.7287 - auc: 0.8686\n",
            "Dataset: 86\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.1701 - binary_accuracy: 0.9365 - auc: 0.9825\n",
            "Dataset: 87\n",
            "4/4 [==============================] - 1s 287ms/step - loss: 0.3064 - binary_accuracy: 0.8671 - auc: 0.9445\n",
            "Dataset: 88\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.6645 - binary_accuracy: 0.7109 - auc: 0.8294\n",
            "Dataset: 89\n",
            "3/3 [==============================] - 1s 601ms/step - loss: 0.4421 - binary_accuracy: 0.7978 - auc: 0.9089\n",
            "Dataset: 90\n",
            "4/4 [==============================] - 1s 230ms/step - loss: 0.5234 - binary_accuracy: 0.7666 - auc: 0.8882\n",
            "Dataset: 91\n",
            "3/3 [==============================] - 2s 766ms/step - loss: 0.5046 - binary_accuracy: 0.7760 - auc: 0.8870\n",
            "Dataset: 92\n",
            "6/6 [==============================] - 1s 242ms/step - loss: 0.2129 - binary_accuracy: 0.9154 - auc: 0.9721\n",
            "Dataset: 93\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1278 - binary_accuracy: 0.9567 - auc: 0.9937\n",
            "Dataset: 94\n",
            "9/9 [==============================] - 2s 225ms/step - loss: 0.3121 - binary_accuracy: 0.8661 - auc: 0.9478\n",
            "Dataset: 95\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3373 - binary_accuracy: 0.8540 - auc: 0.9363\n",
            "Dataset: 96\n",
            "4/4 [==============================] - 1s 245ms/step - loss: 0.1623 - binary_accuracy: 0.9379 - auc: 0.9842\n",
            "Dataset: 97\n",
            "5/5 [==============================] - 2s 343ms/step - loss: 0.1861 - binary_accuracy: 0.9297 - auc: 0.9790\n",
            "Dataset: 98\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.1541 - binary_accuracy: 0.9425 - auc: 0.9871\n",
            "Dataset: 99\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.7385 - binary_accuracy: 0.6779 - auc: 0.8117\n",
            "Dataset: 100\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 0.1354 - binary_accuracy: 0.9518 - auc: 0.9925\n",
            "Dataset: 101\n",
            "5/5 [==============================] - 1s 310ms/step - loss: 0.3966 - binary_accuracy: 0.8264 - auc: 0.9184\n",
            "Dataset: 102\n",
            "4/4 [==============================] - 2s 703ms/step - loss: 0.4118 - binary_accuracy: 0.8151 - auc: 0.9205\n",
            "Dataset: 103\n",
            "4/4 [==============================] - 2s 622ms/step - loss: 0.1335 - binary_accuracy: 0.9517 - auc: 0.9916\n",
            "Dataset: 104\n",
            "3/3 [==============================] - 2s 850ms/step - loss: 0.1502 - binary_accuracy: 0.9468 - auc: 0.9875\n",
            "Dataset: 105\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.6109 - binary_accuracy: 0.7275 - auc: 0.8506\n",
            "Dataset: 106\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5618 - binary_accuracy: 0.7405 - auc: 0.8691\n",
            "Dataset: 107\n",
            "3/3 [==============================] - 1s 489ms/step - loss: 0.5563 - binary_accuracy: 0.7467 - auc: 0.8682\n",
            "Dataset: 108\n",
            "6/6 [==============================] - 2s 282ms/step - loss: 0.1544 - binary_accuracy: 0.9426 - auc: 0.9877\n",
            "Dataset: 109\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.4048 - binary_accuracy: 0.8216 - auc: 0.9149\n",
            "Dataset: 110\n",
            "6/6 [==============================] - 1s 231ms/step - loss: 0.1416 - binary_accuracy: 0.9486 - auc: 0.9902\n",
            "Dataset: 111\n",
            "3/3 [==============================] - 2s 841ms/step - loss: 0.2575 - binary_accuracy: 0.8947 - auc: 0.9567\n",
            "Dataset: 112\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.7108 - binary_accuracy: 0.6845 - auc: 0.8222\n",
            "Dataset: 113\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 0.3734 - binary_accuracy: 0.8358 - auc: 0.9320\n",
            "Dataset: 114\n",
            "4/4 [==============================] - 2s 715ms/step - loss: 0.1370 - binary_accuracy: 0.9504 - auc: 0.9923\n",
            "Dataset: 115\n",
            "5/5 [==============================] - 2s 345ms/step - loss: 0.1460 - binary_accuracy: 0.9451 - auc: 0.9898\n",
            "Dataset: 116\n",
            "4/4 [==============================] - 2s 658ms/step - loss: 0.2778 - binary_accuracy: 0.8841 - auc: 0.9541\n",
            "Dataset: 117\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.1494 - binary_accuracy: 0.9443 - auc: 0.9880\n",
            "Dataset: 118\n",
            "6/6 [==============================] - 2s 451ms/step - loss: 0.3482 - binary_accuracy: 0.8449 - auc: 0.9387\n",
            "Dataset: 119\n",
            "3/3 [==============================] - 1s 449ms/step - loss: 0.5234 - binary_accuracy: 0.7667 - auc: 0.8787\n",
            "Dataset: 120\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.4633 - binary_accuracy: 0.7926 - auc: 0.9035\n",
            "Dataset: 121\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1638 - binary_accuracy: 0.9407 - auc: 0.9858\n",
            "Dataset: 122\n",
            "6/6 [==============================] - 2s 454ms/step - loss: 0.1530 - binary_accuracy: 0.9431 - auc: 0.9878\n",
            "Dataset: 123\n",
            "3/3 [==============================] - 1s 379ms/step - loss: 0.5513 - binary_accuracy: 0.7480 - auc: 0.8750\n",
            "Dataset: 124\n",
            "3/3 [==============================] - 1s 213ms/step - loss: 0.6117 - binary_accuracy: 0.7255 - auc: 0.8526\n",
            "Dataset: 125\n",
            "4/4 [==============================] - 2s 513ms/step - loss: 0.1722 - binary_accuracy: 0.9326 - auc: 0.9830\n",
            "Dataset: 126\n",
            "3/3 [==============================] - 2s 771ms/step - loss: 0.3368 - binary_accuracy: 0.8517 - auc: 0.9364\n",
            "Dataset: 127\n",
            "6/6 [==============================] - 2s 383ms/step - loss: 0.1595 - binary_accuracy: 0.9410 - auc: 0.9861\n",
            "Dataset: 128\n",
            "4/4 [==============================] - 2s 665ms/step - loss: 0.1267 - binary_accuracy: 0.9554 - auc: 0.9943\n",
            "Dataset: 129\n",
            "3/3 [==============================] - 2s 801ms/step - loss: 0.2970 - binary_accuracy: 0.8764 - auc: 0.9497\n",
            "Dataset: 130\n",
            "3/3 [==============================] - 1s 600ms/step - loss: 0.3637 - binary_accuracy: 0.8428 - auc: 0.9285\n",
            "Dataset: 131\n",
            "4/4 [==============================] - 2s 500ms/step - loss: 0.3722 - binary_accuracy: 0.8356 - auc: 0.9258\n",
            "Dataset: 132\n",
            "6/6 [==============================] - 2s 268ms/step - loss: 0.1422 - binary_accuracy: 0.9476 - auc: 0.9902\n",
            "Dataset: 133\n",
            "4/4 [==============================] - 2s 616ms/step - loss: 0.1621 - binary_accuracy: 0.9379 - auc: 0.9852\n",
            "Dataset: 134\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5164 - binary_accuracy: 0.7657 - auc: 0.8795\n",
            "Dataset: 135\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.1376 - binary_accuracy: 0.9496 - auc: 0.9923\n",
            "Dataset: 136\n",
            "3/3 [==============================] - 2s 977ms/step - loss: 0.3754 - binary_accuracy: 0.8362 - auc: 0.9231\n",
            "Dataset: 137\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3989 - binary_accuracy: 0.8200 - auc: 0.9157\n",
            "Dataset: 138\n",
            "7/7 [==============================] - 3s 394ms/step - loss: 0.2770 - binary_accuracy: 0.8861 - auc: 0.9577\n",
            "Dataset: 139\n",
            "3/3 [==============================] - 2s 871ms/step - loss: 0.2843 - binary_accuracy: 0.8798 - auc: 0.9549\n",
            "Dataset: 140\n",
            "4/4 [==============================] - 1s 397ms/step - loss: 0.3552 - binary_accuracy: 0.8433 - auc: 0.9329\n",
            "Dataset: 141\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3100 - binary_accuracy: 0.8690 - auc: 0.9460\n",
            "Dataset: 142\n",
            "5/5 [==============================] - 2s 338ms/step - loss: 0.1816 - binary_accuracy: 0.9318 - auc: 0.9804\n",
            "Dataset: 143\n",
            "6/6 [==============================] - 1s 218ms/step - loss: 0.1827 - binary_accuracy: 0.9285 - auc: 0.9814\n",
            "Dataset: 144\n",
            "3/3 [==============================] - 1s 410ms/step - loss: 0.4486 - binary_accuracy: 0.8013 - auc: 0.9023\n",
            "Dataset: 145\n",
            "4/4 [==============================] - 2s 680ms/step - loss: 0.1211 - binary_accuracy: 0.9585 - auc: 0.9968\n",
            "Dataset: 146\n",
            "3/3 [==============================] - 1s 584ms/step - loss: 0.4987 - binary_accuracy: 0.7822 - auc: 0.8829\n",
            "Dataset: 147\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.6744 - binary_accuracy: 0.7012 - auc: 0.8266\n",
            "Dataset: 148\n",
            "4/4 [==============================] - 1s 278ms/step - loss: 0.6256 - binary_accuracy: 0.7132 - auc: 0.8564\n",
            "Dataset: 149\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.1315 - binary_accuracy: 0.9534 - auc: 0.9931\n",
            "Dataset: 150\n",
            "5/5 [==============================] - 1s 224ms/step - loss: 0.1776 - binary_accuracy: 0.9297 - auc: 0.9809\n",
            "Dataset: 151\n",
            "3/3 [==============================] - 1s 352ms/step - loss: 0.1255 - binary_accuracy: 0.9553 - auc: 0.9939\n",
            "Dataset: 152\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 0.1374 - binary_accuracy: 0.9509 - auc: 0.9916\n",
            "Dataset: 153\n",
            "3/3 [==============================] - 1s 223ms/step - loss: 0.4948 - binary_accuracy: 0.7786 - auc: 0.8860\n",
            "Dataset: 154\n",
            "4/4 [==============================] - 1s 400ms/step - loss: 0.1673 - binary_accuracy: 0.9382 - auc: 0.9828\n",
            "Dataset: 155\n",
            "5/5 [==============================] - 2s 456ms/step - loss: 0.2180 - binary_accuracy: 0.9132 - auc: 0.9700\n",
            "Dataset: 156\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.3883 - binary_accuracy: 0.8271 - auc: 0.9181\n",
            "Dataset: 157\n",
            "4/4 [==============================] - 1s 427ms/step - loss: 0.7340 - binary_accuracy: 0.6731 - auc: 0.8201\n",
            "Dataset: 158\n",
            "6/6 [==============================] - 2s 269ms/step - loss: 0.1777 - binary_accuracy: 0.9306 - auc: 0.9823\n",
            "Dataset: 159\n",
            "5/5 [==============================] - 1s 199ms/step - loss: 0.1398 - binary_accuracy: 0.9479 - auc: 0.9911\n",
            "Dataset: 160\n",
            "5/5 [==============================] - 2s 364ms/step - loss: 0.1419 - binary_accuracy: 0.9460 - auc: 0.9914\n",
            "Dataset: 161\n",
            "7/7 [==============================] - 2s 318ms/step - loss: 0.2760 - binary_accuracy: 0.8867 - auc: 0.9573\n",
            "Dataset: 162\n",
            "5/5 [==============================] - 2s 500ms/step - loss: 0.1670 - binary_accuracy: 0.9364 - auc: 0.9842\n",
            "Dataset: 163\n",
            "4/4 [==============================] - 2s 601ms/step - loss: 0.1567 - binary_accuracy: 0.9391 - auc: 0.9855\n",
            "Dataset: 164\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.3326 - binary_accuracy: 0.8581 - auc: 0.9419\n",
            "Dataset: 165\n",
            "3/3 [==============================] - 2s 991ms/step - loss: 0.4788 - binary_accuracy: 0.7815 - auc: 0.8997\n",
            "Dataset: 166\n",
            "6/6 [==============================] - 1s 234ms/step - loss: 0.1447 - binary_accuracy: 0.9473 - auc: 0.9899\n",
            "Dataset: 167\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 0.1609 - binary_accuracy: 0.9414 - auc: 0.9849\n",
            "Dataset: 168\n",
            "3/3 [==============================] - 1s 526ms/step - loss: 0.2913 - binary_accuracy: 0.8809 - auc: 0.9522\n",
            "Dataset: 169\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5790 - binary_accuracy: 0.7427 - auc: 0.8627\n",
            "Dataset: 170\n",
            "6/6 [==============================] - 2s 290ms/step - loss: 0.1410 - binary_accuracy: 0.9493 - auc: 0.9917\n",
            "Dataset: 171\n",
            "3/3 [==============================] - 2s 997ms/step - loss: 0.2828 - binary_accuracy: 0.8840 - auc: 0.9479\n",
            "Dataset: 172\n",
            "3/3 [==============================] - 1s 391ms/step - loss: 0.6447 - binary_accuracy: 0.7166 - auc: 0.8475\n",
            "Dataset: 173\n",
            "3/3 [==============================] - 2s 796ms/step - loss: 0.4243 - binary_accuracy: 0.8067 - auc: 0.9167\n",
            "Dataset: 174\n",
            "8/8 [==============================] - 2s 224ms/step - loss: 0.1846 - binary_accuracy: 0.9279 - auc: 0.9798\n",
            "Dataset: 175\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.1397 - binary_accuracy: 0.9489 - auc: 0.9905\n",
            "Dataset: 176\n",
            "5/5 [==============================] - 2s 374ms/step - loss: 0.1556 - binary_accuracy: 0.9424 - auc: 0.9870\n",
            "Dataset: 177\n",
            "4/4 [==============================] - 2s 599ms/step - loss: 0.1925 - binary_accuracy: 0.9224 - auc: 0.9767\n",
            "Dataset: 178\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.1467 - binary_accuracy: 0.9462 - auc: 0.9896\n",
            "Dataset: 179\n",
            "3/3 [==============================] - 2s 776ms/step - loss: 0.4055 - binary_accuracy: 0.8200 - auc: 0.9123\n",
            "Dataset: 180\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.4709 - binary_accuracy: 0.7864 - auc: 0.8963\n",
            "Dataset: 181\n",
            "4/4 [==============================] - 2s 627ms/step - loss: 0.1435 - binary_accuracy: 0.9471 - auc: 0.9916\n",
            "Dataset: 182\n",
            "5/5 [==============================] - 1s 213ms/step - loss: 0.3801 - binary_accuracy: 0.8270 - auc: 0.9316\n",
            "Dataset: 183\n",
            "3/3 [==============================] - 1s 207ms/step - loss: 0.6166 - binary_accuracy: 0.7207 - auc: 0.8483\n",
            "Dataset: 184\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3711 - binary_accuracy: 0.8385 - auc: 0.9271\n",
            "Dataset: 185\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.1293 - binary_accuracy: 0.9521 - auc: 0.9950\n",
            "Dataset: 186\n",
            "4/4 [==============================] - 1s 357ms/step - loss: 0.1392 - binary_accuracy: 0.9494 - auc: 0.9918\n",
            "Dataset: 187\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.2106 - binary_accuracy: 0.9154 - auc: 0.9718\n",
            "Dataset: 188\n",
            "4/4 [==============================] - 2s 651ms/step - loss: 0.1251 - binary_accuracy: 0.9564 - auc: 0.9952\n",
            "Dataset: 189\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.1616 - binary_accuracy: 0.9402 - auc: 0.9848\n",
            "Dataset: 190\n",
            "4/4 [==============================] - 2s 634ms/step - loss: 0.3637 - binary_accuracy: 0.8386 - auc: 0.9355\n",
            "Dataset: 191\n",
            "4/4 [==============================] - 2s 578ms/step - loss: 0.3297 - binary_accuracy: 0.8530 - auc: 0.9449\n",
            "Dataset: 192\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.6676 - binary_accuracy: 0.7065 - auc: 0.8415\n",
            "Dataset: 193\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 0.9732 - binary_accuracy: 0.5990 - auc: 0.7418\n",
            "Dataset: 194\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.1267 - binary_accuracy: 0.9544 - auc: 0.9944\n",
            "Dataset: 195\n",
            "3/3 [==============================] - 1s 571ms/step - loss: 0.4720 - binary_accuracy: 0.7868 - auc: 0.9011\n",
            "Dataset: 196\n",
            "3/3 [==============================] - 1s 383ms/step - loss: 0.1444 - binary_accuracy: 0.9472 - auc: 0.9897\n",
            "Dataset: 197\n",
            "5/5 [==============================] - 2s 379ms/step - loss: 0.1411 - binary_accuracy: 0.9499 - auc: 0.9908\n",
            "Dataset: 198\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.4733 - binary_accuracy: 0.7877 - auc: 0.8955\n",
            "Dataset: 199\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1523 - binary_accuracy: 0.9438 - auc: 0.9877\n",
            "Dataset: 200\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5370 - binary_accuracy: 0.7533 - auc: 0.8741\n",
            "Dataset: 201\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 0.1491 - binary_accuracy: 0.9450 - auc: 0.9889\n",
            "Dataset: 202\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.1480 - binary_accuracy: 0.9462 - auc: 0.9903\n",
            "Dataset: 203\n",
            "3/3 [==============================] - 1s 453ms/step - loss: 0.6206 - binary_accuracy: 0.7210 - auc: 0.8486\n",
            "Dataset: 204\n",
            "6/6 [==============================] - 1s 247ms/step - loss: 0.1524 - binary_accuracy: 0.9436 - auc: 0.9869\n",
            "Dataset: 205\n",
            "6/6 [==============================] - 2s 366ms/step - loss: 0.1950 - binary_accuracy: 0.9257 - auc: 0.9774\n",
            "Dataset: 206\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.3254 - binary_accuracy: 0.8604 - auc: 0.9442\n",
            "Dataset: 207\n",
            "3/3 [==============================] - 2s 661ms/step - loss: 0.3825 - binary_accuracy: 0.8302 - auc: 0.9229\n",
            "Dataset: 208\n",
            "4/4 [==============================] - 2s 445ms/step - loss: 0.5919 - binary_accuracy: 0.7312 - auc: 0.8617\n",
            "Dataset: 209\n",
            "6/6 [==============================] - 1s 226ms/step - loss: 0.1499 - binary_accuracy: 0.9447 - auc: 0.9894\n",
            "Dataset: 210\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.2954 - binary_accuracy: 0.8753 - auc: 0.9520\n",
            "Dataset: 211\n",
            "6/6 [==============================] - 2s 385ms/step - loss: 0.1498 - binary_accuracy: 0.9464 - auc: 0.9884\n",
            "Dataset: 212\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.6077 - binary_accuracy: 0.7391 - auc: 0.8550\n",
            "Dataset: 213\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1471 - binary_accuracy: 0.9454 - auc: 0.9896\n",
            "Dataset: 214\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.1728 - binary_accuracy: 0.9342 - auc: 0.9826\n",
            "Dataset: 215\n",
            "4/4 [==============================] - 2s 547ms/step - loss: 0.3293 - binary_accuracy: 0.8597 - auc: 0.9440\n",
            "Dataset: 216\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.1430 - binary_accuracy: 0.9484 - auc: 0.9903\n",
            "Dataset: 217\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.3220 - binary_accuracy: 0.8597 - auc: 0.9458\n",
            "Dataset: 218\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.6343 - binary_accuracy: 0.7176 - auc: 0.8537\n",
            "Dataset: 219\n",
            "3/3 [==============================] - 2s 851ms/step - loss: 0.5608 - binary_accuracy: 0.7478 - auc: 0.8679\n",
            "Dataset: 220\n",
            "4/4 [==============================] - 2s 485ms/step - loss: 0.4047 - binary_accuracy: 0.8203 - auc: 0.9182\n",
            "Dataset: 221\n",
            "3/3 [==============================] - 1s 454ms/step - loss: 0.3585 - binary_accuracy: 0.8420 - auc: 0.9287\n",
            "Dataset: 222\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1498 - binary_accuracy: 0.9430 - auc: 0.9895\n",
            "Dataset: 223\n",
            "3/3 [==============================] - 1s 568ms/step - loss: 0.5688 - binary_accuracy: 0.7440 - auc: 0.8597\n",
            "Dataset: 224\n",
            "5/5 [==============================] - 1s 292ms/step - loss: 0.1509 - binary_accuracy: 0.9430 - auc: 0.9882\n",
            "Dataset: 225\n",
            "3/3 [==============================] - 1s 551ms/step - loss: 0.5455 - binary_accuracy: 0.7519 - auc: 0.8747\n",
            "Dataset: 226\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.4433 - binary_accuracy: 0.8066 - auc: 0.9072\n",
            "Dataset: 227\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.5110 - binary_accuracy: 0.7698 - auc: 0.8842\n",
            "Dataset: 228\n",
            "3/3 [==============================] - 2s 928ms/step - loss: 0.1891 - binary_accuracy: 0.9254 - auc: 0.9761\n",
            "Dataset: 229\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.6448 - binary_accuracy: 0.7136 - auc: 0.8368\n",
            "Dataset: 230\n",
            "3/3 [==============================] - 1s 456ms/step - loss: 0.4227 - binary_accuracy: 0.8140 - auc: 0.9084\n",
            "Dataset: 231\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 0.1627 - binary_accuracy: 0.9382 - auc: 0.9850\n",
            "Dataset: 232\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.5084 - binary_accuracy: 0.7749 - auc: 0.8835\n",
            "Dataset: 233\n",
            "3/3 [==============================] - 2s 810ms/step - loss: 0.5169 - binary_accuracy: 0.7659 - auc: 0.8869\n",
            "Dataset: 234\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 0.1688 - binary_accuracy: 0.9364 - auc: 0.9838\n",
            "Dataset: 235\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.4232 - binary_accuracy: 0.8149 - auc: 0.9051\n",
            "Dataset: 236\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.1478 - binary_accuracy: 0.9474 - auc: 0.9893\n",
            "Dataset: 237\n",
            "4/4 [==============================] - 1s 185ms/step - loss: 0.2435 - binary_accuracy: 0.9025 - auc: 0.9656\n",
            "Dataset: 238\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.1456 - binary_accuracy: 0.9459 - auc: 0.9897\n",
            "Dataset: 239\n",
            "9/9 [==============================] - 3s 346ms/step - loss: 0.2954 - binary_accuracy: 0.8789 - auc: 0.9535\n",
            "Dataset: 240\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 0.1452 - binary_accuracy: 0.9457 - auc: 0.9899\n",
            "Dataset: 241\n",
            "6/6 [==============================] - 2s 343ms/step - loss: 0.3480 - binary_accuracy: 0.8443 - auc: 0.9404\n",
            "Dataset: 242\n",
            "3/3 [==============================] - 2s 1s/step - loss: 0.3682 - binary_accuracy: 0.8366 - auc: 0.9262\n",
            "Dataset: 243\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5504 - binary_accuracy: 0.7577 - auc: 0.8666\n",
            "Dataset: 244\n",
            "4/4 [==============================] - 2s 555ms/step - loss: 0.1376 - binary_accuracy: 0.9496 - auc: 0.9927\n",
            "Dataset: 245\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5748 - binary_accuracy: 0.7369 - auc: 0.8581\n",
            "0.9411252301566455\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for test_feature,test_label in zip(test_features,test_labels):\n",
        "  i=i+1\n",
        "  print(\"Dataset:\",i)\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1,batch_size=4096)\n",
        "  avg_acc.append(data[2])\n",
        "print(np.mean(avg_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ2-bW_Bm_Bt",
        "outputId": "469a24d8-8af9-4c8e-8f04-fc4947e2bd79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.860862135887146\n",
            "0.9868860840797424\n",
            "0.9364693760871887\n",
            "0.9784518480300903\n",
            "0.9308487772941589\n",
            "0.9294339418411255\n",
            "0.849390983581543\n",
            "0.863771378993988\n",
            "0.9866358041763306\n",
            "0.9890824556350708\n",
            "0.8488849997520447\n",
            "0.8964110016822815\n",
            "0.9797243475914001\n",
            "0.853316068649292\n",
            "0.9682753086090088\n",
            "0.9178335070610046\n",
            "0.9876718521118164\n",
            "0.9418314695358276\n",
            "0.9343411922454834\n",
            "0.9882460832595825\n",
            "0.956145167350769\n",
            "0.9306126832962036\n",
            "0.9886306524276733\n",
            "0.9891588091850281\n",
            "0.9835429787635803\n",
            "0.9899436235427856\n",
            "0.9729277491569519\n",
            "0.8700823783874512\n",
            "0.9925059676170349\n",
            "0.9023193120956421\n",
            "0.9837064146995544\n",
            "0.9836395382881165\n",
            "0.9828857183456421\n",
            "0.987529456615448\n",
            "0.9890211820602417\n",
            "0.8406006693840027\n",
            "0.970306396484375\n",
            "0.9756087064743042\n",
            "0.9920082688331604\n",
            "0.9802468419075012\n",
            "0.9356911778450012\n",
            "0.9451117515563965\n",
            "0.9389406442642212\n",
            "0.8782476186752319\n",
            "0.991473376750946\n",
            "0.9310184121131897\n",
            "0.9361149072647095\n",
            "0.8571627736091614\n",
            "0.9870307445526123\n",
            "0.9847317337989807\n",
            "0.9862375259399414\n",
            "0.8955679535865784\n",
            "0.9268822073936462\n",
            "0.9929104447364807\n",
            "0.9681726694107056\n",
            "0.9543130993843079\n",
            "0.9882989525794983\n",
            "0.9913589954376221\n",
            "0.9377120137214661\n",
            "0.9881976842880249\n",
            "0.9187313318252563\n",
            "0.8141855597496033\n",
            "0.8650380373001099\n",
            "0.9103736281394958\n",
            "0.9076915979385376\n",
            "0.9519816040992737\n",
            "0.931988537311554\n",
            "0.9228480458259583\n",
            "0.9888977408409119\n",
            "0.9661182165145874\n",
            "0.9833151698112488\n",
            "0.8695418238639832\n",
            "0.9888229370117188\n",
            "0.9781235456466675\n",
            "0.9912515878677368\n",
            "0.9315694570541382\n",
            "0.9879194498062134\n",
            "0.8901112079620361\n",
            "0.9621105194091797\n",
            "0.9880623817443848\n",
            "0.9708366990089417\n",
            "0.8864040970802307\n",
            "0.9925041794776917\n",
            "0.8974714279174805\n",
            "0.868582546710968\n",
            "0.9825185537338257\n",
            "0.9445275068283081\n",
            "0.829446017742157\n",
            "0.9089319705963135\n",
            "0.8881604671478271\n",
            "0.8870103359222412\n",
            "0.9720640778541565\n",
            "0.9937030673027039\n",
            "0.9477869868278503\n",
            "0.9363172650337219\n",
            "0.9841724038124084\n",
            "0.9790303111076355\n",
            "0.9870584607124329\n",
            "0.811729371547699\n",
            "0.9924706220626831\n",
            "0.9184303879737854\n",
            "0.9205056428909302\n",
            "0.9916260838508606\n",
            "0.9874931573867798\n",
            "0.8505870699882507\n",
            "0.8691163659095764\n",
            "0.8681886196136475\n",
            "0.9876796007156372\n",
            "0.9149409532546997\n",
            "0.9902386665344238\n",
            "0.9566647410392761\n",
            "0.8221567273139954\n",
            "0.9319732189178467\n",
            "0.992342472076416\n",
            "0.9898418188095093\n",
            "0.9540549516677856\n",
            "0.9880054593086243\n",
            "0.9386781454086304\n",
            "0.8787472248077393\n",
            "0.9034940004348755\n",
            "0.9858163595199585\n",
            "0.9878336191177368\n",
            "0.8749573826789856\n",
            "0.8525788187980652\n",
            "0.982967734336853\n",
            "0.9364492893218994\n",
            "0.9860713481903076\n",
            "0.9943054914474487\n",
            "0.9497462511062622\n",
            "0.9285130500793457\n",
            "0.925795316696167\n",
            "0.9902355074882507\n",
            "0.9851812720298767\n",
            "0.8794563412666321\n",
            "0.9922667741775513\n",
            "0.9230804443359375\n",
            "0.9156699776649475\n",
            "0.9577432870864868\n",
            "0.9549369215965271\n",
            "0.9329106211662292\n",
            "0.9460136294364929\n",
            "0.9803782105445862\n",
            "0.9813907742500305\n",
            "0.9022821187973022\n",
            "0.996761679649353\n",
            "0.882908284664154\n",
            "0.8265544772148132\n",
            "0.8564329743385315\n",
            "0.9931121468544006\n",
            "0.9809333086013794\n",
            "0.9939171671867371\n",
            "0.991624116897583\n",
            "0.8859696984291077\n",
            "0.9827708601951599\n",
            "0.970043420791626\n",
            "0.9181497097015381\n",
            "0.8200592398643494\n",
            "0.9823359251022339\n",
            "0.9911164045333862\n",
            "0.991384744644165\n",
            "0.9572601914405823\n",
            "0.984249472618103\n",
            "0.9854984879493713\n",
            "0.9418783187866211\n",
            "0.8996756672859192\n",
            "0.9898830056190491\n",
            "0.9849145412445068\n",
            "0.9522372484207153\n",
            "0.862670361995697\n",
            "0.9916537404060364\n",
            "0.9478684067726135\n",
            "0.8475202918052673\n",
            "0.9166591167449951\n",
            "0.9797813296318054\n",
            "0.9904649257659912\n",
            "0.9869961142539978\n",
            "0.9766627550125122\n",
            "0.9895574450492859\n",
            "0.9123080968856812\n",
            "0.896318793296814\n",
            "0.9915979504585266\n",
            "0.9315714836120605\n",
            "0.8483207821846008\n",
            "0.9271047711372375\n",
            "0.9950401782989502\n",
            "0.9917716979980469\n",
            "0.9718053340911865\n",
            "0.9952075481414795\n",
            "0.9847951531410217\n",
            "0.935517430305481\n",
            "0.9448786973953247\n",
            "0.8414524793624878\n",
            "0.7418100237846375\n",
            "0.9943828582763672\n",
            "0.9011358618736267\n",
            "0.9896523952484131\n",
            "0.990760087966919\n",
            "0.8955440521240234\n",
            "0.9877279996871948\n",
            "0.8741345405578613\n",
            "0.9888991117477417\n",
            "0.9903479814529419\n",
            "0.8485819101333618\n",
            "0.9868648052215576\n",
            "0.9774406552314758\n",
            "0.9442002773284912\n",
            "0.9229130744934082\n",
            "0.8617426753044128\n",
            "0.9893962144851685\n",
            "0.952039361000061\n",
            "0.9883767366409302\n",
            "0.8550267815589905\n",
            "0.9896407723426819\n",
            "0.9826428294181824\n",
            "0.9439629316329956\n",
            "0.9903029203414917\n",
            "0.9457713961601257\n",
            "0.8536921143531799\n",
            "0.8679326176643372\n",
            "0.9181837439537048\n",
            "0.9286967515945435\n",
            "0.9894653558731079\n",
            "0.8597098588943481\n",
            "0.9882140755653381\n",
            "0.8747258186340332\n",
            "0.9071520566940308\n",
            "0.8841723799705505\n",
            "0.976140558719635\n",
            "0.8367701172828674\n",
            "0.9083701372146606\n",
            "0.985049307346344\n",
            "0.8834551572799683\n",
            "0.8868834972381592\n",
            "0.9837864637374878\n",
            "0.9051225781440735\n",
            "0.9892961382865906\n",
            "0.9655603766441345\n",
            "0.9897220134735107\n",
            "0.9535097479820251\n",
            "0.9898871779441833\n",
            "0.9404201507568359\n",
            "0.9261656403541565\n",
            "0.8665540814399719\n",
            "0.9926961064338684\n",
            "0.8581327199935913\n"
          ]
        }
      ],
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Fine-Tuning"
      ],
      "metadata": {
        "id": "EPZmTTGRvqsY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EybnfsFFOcEg",
        "outputId": "c044268b-e0d7-4e46-c712-70a08212f301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 1\n",
            "275/275 [==============================] - 4s 8ms/step - loss: 0.4150 - binary_accuracy: 0.8113 - auc: 0.8962\n",
            "Dataset: 2\n",
            "558/558 [==============================] - 6s 8ms/step - loss: 0.1202 - binary_accuracy: 0.9587 - auc_1: 0.9903\n",
            "Dataset: 3\n",
            "858/858 [==============================] - 8s 8ms/step - loss: 0.1680 - binary_accuracy: 0.9377 - auc_2: 0.9833\n",
            "Dataset: 4\n",
            "245/245 [==============================] - 3s 7ms/step - loss: 0.1432 - binary_accuracy: 0.9525 - auc_3: 0.9859\n",
            "Dataset: 5\n",
            "386/386 [==============================] - 4s 7ms/step - loss: 0.2844 - binary_accuracy: 0.8810 - auc_4: 0.9518\n",
            "Dataset: 6\n",
            "236/236 [==============================] - 3s 7ms/step - loss: 0.2733 - binary_accuracy: 0.8852 - auc_5: 0.9548\n",
            "Dataset: 7\n",
            "252/252 [==============================] - 3s 7ms/step - loss: 0.4037 - binary_accuracy: 0.8100 - auc_6: 0.8977\n",
            "Dataset: 8\n",
            "278/278 [==============================] - 4s 7ms/step - loss: 0.3975 - binary_accuracy: 0.8166 - auc_7: 0.9007\n",
            "Dataset: 9\n",
            "674/674 [==============================] - 7s 7ms/step - loss: 0.1151 - binary_accuracy: 0.9612 - auc_8: 0.9912\n",
            "Dataset: 10\n",
            "611/611 [==============================] - 6s 8ms/step - loss: 0.1038 - binary_accuracy: 0.9674 - auc_9: 0.9918\n",
            "Dataset: 11\n",
            "246/246 [==============================] - 4s 9ms/step - loss: 0.4213 - binary_accuracy: 0.8061 - auc_10: 0.8933\n",
            "Dataset: 12\n",
            "251/251 [==============================] - 3s 7ms/step - loss: 0.2272 - binary_accuracy: 0.9114 - auc_11: 0.9697\n",
            "Dataset: 13\n",
            "377/377 [==============================] - 4s 8ms/step - loss: 0.1639 - binary_accuracy: 0.9419 - auc_12: 0.9835\n",
            "Dataset: 14\n",
            "236/236 [==============================] - 3s 9ms/step - loss: 0.4122 - binary_accuracy: 0.8119 - auc_13: 0.8965\n",
            "Dataset: 15\n",
            "756/756 [==============================] - 8s 8ms/step - loss: 0.1840 - binary_accuracy: 0.9274 - auc_14: 0.9789\n",
            "Dataset: 16\n",
            "627/627 [==============================] - 7s 8ms/step - loss: 0.1979 - binary_accuracy: 0.9243 - auc_15: 0.9765\n",
            "Dataset: 17\n",
            "566/566 [==============================] - 6s 8ms/step - loss: 0.1079 - binary_accuracy: 0.9644 - auc_16: 0.9915\n",
            "Dataset: 18\n",
            "472/472 [==============================] - 5s 7ms/step - loss: 0.1311 - binary_accuracy: 0.9546 - auc_17: 0.9886\n",
            "Dataset: 19\n",
            "505/505 [==============================] - 6s 8ms/step - loss: 0.2016 - binary_accuracy: 0.9221 - auc_18: 0.9763\n",
            "Dataset: 20\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=37:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgNh23EDs5vS",
        "outputId": "ce8fd28d-c983-49a6-d4ae-af3ed9270af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8961666822433472\n",
            "0.9903296232223511\n",
            "0.9833280444145203\n",
            "0.9858688116073608\n",
            "0.9518383741378784\n",
            "0.9547760486602783\n",
            "0.8977182507514954\n",
            "0.9006561636924744\n",
            "0.991176426410675\n",
            "0.9917778372764587\n",
            "0.8933342099189758\n",
            "0.9696537256240845\n",
            "0.9834957718849182\n",
            "0.8965144753456116\n",
            "0.9788564443588257\n",
            "0.9765400886535645\n",
            "0.9915405511856079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tow2lp66nWP",
        "outputId": "8e7a3b3f-cf5e-4327-822c-d28c8b4b5b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 18\n",
            "472/472 [==============================] - 6s 9ms/step - loss: 0.1329 - binary_accuracy: 0.9521 - auc: 0.9884\n",
            "Dataset: 19\n",
            "505/505 [==============================] - 7s 10ms/step - loss: 0.1962 - binary_accuracy: 0.9210 - auc_1: 0.9768\n",
            "Dataset: 20\n",
            "688/688 [==============================] - 7s 9ms/step - loss: 0.1023 - binary_accuracy: 0.9646 - auc_2: 0.9924\n",
            "Dataset: 21\n",
            "240/240 [==============================] - 4s 8ms/step - loss: 0.1330 - binary_accuracy: 0.9499 - auc_3: 0.9888\n",
            "Dataset: 22\n",
            "276/276 [==============================] - 4s 9ms/step - loss: 0.2585 - binary_accuracy: 0.8949 - auc_4: 0.9605\n",
            "Dataset: 23\n",
            "553/553 [==============================] - 6s 9ms/step - loss: 0.1021 - binary_accuracy: 0.9669 - auc_5: 0.9928\n",
            "Dataset: 24\n",
            "557/557 [==============================] - 6s 8ms/step - loss: 0.0998 - binary_accuracy: 0.9641 - auc_6: 0.9931\n",
            "Dataset: 25\n",
            "582/582 [==============================] - 7s 9ms/step - loss: 0.1383 - binary_accuracy: 0.9548 - auc_7: 0.9871\n",
            "Dataset: 26\n",
            "611/611 [==============================] - 7s 8ms/step - loss: 0.0948 - binary_accuracy: 0.9654 - auc_8: 0.9935\n",
            "Dataset: 27\n",
            "634/634 [==============================] - 7s 9ms/step - loss: 0.1693 - binary_accuracy: 0.9383 - auc_9: 0.9797\n",
            "Dataset: 28\n",
            "237/237 [==============================] - 4s 9ms/step - loss: 0.3830 - binary_accuracy: 0.8249 - auc_10: 0.9091\n",
            "Dataset: 29\n",
            "298/298 [==============================] - 4s 8ms/step - loss: 0.0838 - binary_accuracy: 0.9728 - auc_11: 0.9940\n",
            "Dataset: 30\n",
            "399/399 [==============================] - 5s 8ms/step - loss: 0.3283 - binary_accuracy: 0.8603 - auc_12: 0.9328\n",
            "Dataset: 31\n",
            "382/382 [==============================] - 4s 8ms/step - loss: 0.1280 - binary_accuracy: 0.9552 - auc_13: 0.9876\n",
            "Dataset: 32\n",
            "807/807 [==============================] - 8s 8ms/step - loss: 0.1256 - binary_accuracy: 0.9537 - auc_14: 0.9897\n",
            "Dataset: 33\n",
            "661/661 [==============================] - 6s 8ms/step - loss: 0.1346 - binary_accuracy: 0.9495 - auc_15: 0.9882\n",
            "Dataset: 34\n",
            "618/618 [==============================] - 7s 9ms/step - loss: 0.1122 - binary_accuracy: 0.9615 - auc_16: 0.9910\n",
            "Dataset: 35\n",
            "565/565 [==============================] - 6s 8ms/step - loss: 0.1070 - binary_accuracy: 0.9646 - auc_17: 0.9918\n",
            "Dataset: 36\n",
            "364/364 [==============================] - 4s 8ms/step - loss: 0.3684 - binary_accuracy: 0.8374 - auc_18: 0.9181\n",
            "Dataset: 37\n",
            "398/398 [==============================] - 4s 8ms/step - loss: 0.1254 - binary_accuracy: 0.9582 - auc_19: 0.9905\n",
            "Dataset: 38\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=17:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop])\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaRdEKb_spDd",
        "outputId": "4296f26c-4be9-4772-bb17-cd45ab0ef1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9884480237960815\n",
            "0.9767590165138245\n",
            "0.9923784136772156\n",
            "0.9888182282447815\n",
            "0.9604546427726746\n",
            "0.9927592873573303\n",
            "0.993060827255249\n",
            "0.9870992302894592\n",
            "0.9935159087181091\n",
            "0.9796700477600098\n",
            "0.9091038703918457\n",
            "0.9939607977867126\n",
            "0.9328449368476868\n",
            "0.9875848293304443\n",
            "0.9897491931915283\n",
            "0.9882411360740662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aX8wH6UPMJxg",
        "outputId": "ce247f87-400d-444f-a031-32767f9965ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 38\n",
            "674/674 [==============================] - 8s 8ms/step - loss: 0.1632 - binary_accuracy: 0.9409 - auc: 0.9811\n",
            "Dataset: 39\n",
            "711/711 [==============================] - 8s 8ms/step - loss: 0.0966 - binary_accuracy: 0.9696 - auc_1: 0.9933\n",
            "Dataset: 40\n",
            "543/543 [==============================] - 6s 9ms/step - loss: 0.1561 - binary_accuracy: 0.9485 - auc_2: 0.9836\n",
            "Dataset: 41\n",
            "541/541 [==============================] - 5s 7ms/step - loss: 0.2109 - binary_accuracy: 0.9213 - auc_3: 0.9748\n",
            "Dataset: 42\n",
            "320/320 [==============================] - 4s 9ms/step - loss: 0.1184 - binary_accuracy: 0.9612 - auc_4: 0.9909\n",
            "Dataset: 43\n",
            "272/272 [==============================] - 3s 7ms/step - loss: 0.2009 - binary_accuracy: 0.9306 - auc_5: 0.9765\n",
            "Dataset: 44\n",
            "348/348 [==============================] - 6s 9ms/step - loss: 0.3453 - binary_accuracy: 0.8539 - auc_6: 0.9307\n",
            "Dataset: 45\n",
            "644/644 [==============================] - 7s 9ms/step - loss: 0.0930 - binary_accuracy: 0.9699 - auc_7: 0.9935\n",
            "Dataset: 46\n",
            "315/315 [==============================] - 4s 9ms/step - loss: 0.2690 - binary_accuracy: 0.8906 - auc_8: 0.9573\n",
            "Dataset: 47\n",
            "327/327 [==============================] - 4s 8ms/step - loss: 0.2680 - binary_accuracy: 0.8931 - auc_9: 0.9582\n",
            "Dataset: 48\n",
            "267/267 [==============================] - 4s 8ms/step - loss: 0.4146 - binary_accuracy: 0.8147 - auc_10: 0.8985\n",
            "Dataset: 49\n",
            "709/709 [==============================] - 7s 8ms/step - loss: 0.1127 - binary_accuracy: 0.9596 - auc_11: 0.9916\n",
            "Dataset: 50\n",
            "805/805 [==============================] - 7s 7ms/step - loss: 0.1221 - binary_accuracy: 0.9584 - auc_12: 0.9893\n",
            "Dataset: 51\n",
            "453/453 [==============================] - 5s 8ms/step - loss: 0.1238 - binary_accuracy: 0.9533 - auc_13: 0.9896\n",
            "Dataset: 52\n",
            "281/281 [==============================] - 4s 8ms/step - loss: 0.3167 - binary_accuracy: 0.8649 - auc_14: 0.9394\n",
            "Dataset: 53\n",
            "596/596 [==============================] - 6s 8ms/step - loss: 0.1209 - binary_accuracy: 0.9574 - auc_15: 0.9902\n",
            "Dataset: 54\n",
            "424/424 [==============================] - 5s 8ms/step - loss: 0.0819 - binary_accuracy: 0.9740 - auc_16: 0.9942\n",
            "Dataset: 55\n",
            "521/521 [==============================] - 6s 8ms/step - loss: 0.1993 - binary_accuracy: 0.9256 - auc_17: 0.9751\n",
            "Dataset: 56\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a9637778c512>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                                         ]\n\u001b[1;32m     15\u001b[0m                               )\n\u001b[0;32m---> 16\u001b[0;31m   history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n\u001b[0m\u001b[1;32m     17\u001b[0m                               \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 )\n\u001b[1;32m   1383\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1679\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1680\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1681\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3271\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4069\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4071\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    541\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \"\"\"\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_backward_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mcall_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[0;34m(self, op, *doutputs)\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mforward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[1;32m    187\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[0;32m--> 188\u001b[0;31m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    189\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[1;32m    734\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[1;32m    735\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 734\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    735\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    426\u001b[0m   \u001b[0m_check_num_inputs_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_grad_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_grad_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m   outputs = _build_while_op(\n\u001b[0m\u001b[1;32m    429\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m       \u001b[0mcond_grad_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_build_while_op\u001b[0;34m(loop_vars, cond_graph, body_graph, output_shapes, parallel_iterations, name, num_original_outputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0mwhile_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_as_function_for_tape_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/control_flow_util_v2.py\u001b[0m in \u001b[0;36mrun_as_function_for_tape_gradients\u001b[0;34m(make_op, inputs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmake_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_make_op\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     while_op, tensors = util.get_op_and_outputs(op_fn(\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_new_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_functional_ops.py\u001b[0m in \u001b[0;36mstateless_while\u001b[0;34m(input, cond, body, output_shapes, parallel_iterations, name)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0mparallel_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m   \u001b[0mparallel_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parallel_iterations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;34m\"StatelessWhile\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                           \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    797\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mctxt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AddValue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     return super()._create_op_internal(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_captures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_validate_in_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/capture/capture_container.py\u001b[0m in \u001b[0;36mcapture_by_value\u001b[0;34m(self, graph, tensor, name)\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0;31m# cond/while graphs override _capture_helper() so cannot call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;31m# self.create_placeholder_helper() here directly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m    704\u001b[0m   \u001b[0;31m# TODO(panzf): Rename this method along with usages in cond/while graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m     return self._function_captures._create_placeholder_helper(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    707\u001b[0m         self, tensor, name)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/capture/capture_container.py\u001b[0m in \u001b[0;36m_create_placeholder_helper\u001b[0;34m(self, graph, tensor, name)\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mcomposite_device_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomposite_device_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m       )\n\u001b[0;32m--> 285\u001b[0;31m       \u001b[0mplaceholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaceholder_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m       self.add_or_replace(\n\u001b[1;32m    287\u001b[0m           \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_by_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36mplaceholder_value\u001b[0;34m(self, placeholder_context)\u001b[0m\n\u001b[1;32m   1025\u001b[0m       \u001b[0;31m# Record the requested/user-specified name in case it's different than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m       \u001b[0;31m# the uniquified name, for validation when exporting signatures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m       placeholder.op._set_attr(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   1028\u001b[0m           \u001b[0;34m\"_user_specified_name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m           attr_value_pb2.AttrValue(s=compat.as_bytes(name)))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_set_attr\u001b[0;34m(self, attr_name, attr_value)\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;34m\"\"\"Private method used to set an attribute in the node_def.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     buf = pywrap_tf_session.TF_NewBufferFromString(\n\u001b[0;32m-> 1484\u001b[0;31m         compat.as_bytes(attr_value.SerializeToString()))\n\u001b[0m\u001b[1;32m   1485\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_attr_with_buf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=37:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMtkZso-jftR",
        "outputId": "31b582d3-f1a3-43cf-f92c-f61a11ad8f09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9811234474182129\n",
            "0.9933409094810486\n",
            "0.9835965633392334\n",
            "0.9748156070709229\n",
            "0.9909233450889587\n",
            "0.9765442609786987\n",
            "0.930728554725647\n",
            "0.9935320019721985\n",
            "0.9573132991790771\n",
            "0.9581983089447021\n",
            "0.8984851241111755\n",
            "0.9915648102760315\n",
            "0.9893139600753784\n",
            "0.9896454811096191\n",
            "0.9394118189811707\n",
            "0.9902445077896118\n",
            "0.9941833019256592\n",
            "0.9751115441322327\n"
          ]
        }
      ],
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASyPXfskZ6MW",
        "outputId": "7fb87f6d-04fb-4391-d927-d4ea89bacaed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 56\n",
            "270/270 [==============================] - 4s 8ms/step - loss: 0.1340 - binary_accuracy: 0.9541 - auc: 0.9883\n",
            "0.988250195980072\n",
            "Dataset: 57\n",
            "593/593 [==============================] - 8s 9ms/step - loss: 0.1241 - binary_accuracy: 0.9598 - auc_1: 0.9895\n",
            "0.9894775748252869\n",
            "Dataset: 58\n",
            "570/570 [==============================] - 6s 8ms/step - loss: 0.0925 - binary_accuracy: 0.9697 - auc_2: 0.9934\n",
            "0.9934212565422058\n",
            "Dataset: 59\n",
            "350/350 [==============================] - 4s 9ms/step - loss: 0.1102 - binary_accuracy: 0.9635 - auc_3: 0.9918\n",
            "0.9918239116668701\n",
            "Dataset: 60\n",
            "454/454 [==============================] - 5s 8ms/step - loss: 0.1057 - binary_accuracy: 0.9642 - auc_4: 0.9913\n",
            "0.9912895560264587\n",
            "Dataset: 61\n",
            "528/528 [==============================] - 7s 9ms/step - loss: 0.2004 - binary_accuracy: 0.9237 - auc_5: 0.9759\n",
            "0.975909948348999\n",
            "Dataset: 62\n",
            "244/244 [==============================] - 3s 7ms/step - loss: 0.5023 - binary_accuracy: 0.7751 - auc_6: 0.8586\n",
            "0.8585928678512573\n",
            "Dataset: 63\n",
            "240/240 [==============================] - 4s 9ms/step - loss: 0.3987 - binary_accuracy: 0.8222 - auc_7: 0.9047\n",
            "0.9046685099601746\n",
            "Dataset: 64\n",
            "510/510 [==============================] - 7s 9ms/step - loss: 0.2309 - binary_accuracy: 0.9108 - auc_8: 0.9690\n",
            "0.9689800143241882\n",
            "Dataset: 65\n",
            "256/256 [==============================] - 3s 7ms/step - loss: 0.2021 - binary_accuracy: 0.9266 - auc_9: 0.9778\n",
            "0.9777894616127014\n",
            "Dataset: 66\n",
            "310/310 [==============================] - 3s 7ms/step - loss: 0.2134 - binary_accuracy: 0.9171 - auc_10: 0.9719\n",
            "0.9718601703643799\n",
            "Dataset: 67\n",
            "551/551 [==============================] - 7s 9ms/step - loss: 0.2075 - binary_accuracy: 0.9189 - auc_11: 0.9749\n",
            "0.9749179482460022\n",
            "Dataset: 68\n",
            "362/362 [==============================] - 5s 9ms/step - loss: 0.3176 - binary_accuracy: 0.8675 - auc_12: 0.9420\n",
            "0.9420496225357056\n",
            "Dataset: 69\n",
            "550/550 [==============================] - 6s 8ms/step - loss: 0.1066 - binary_accuracy: 0.9633 - auc_13: 0.9916\n",
            "0.9916483759880066\n",
            "Dataset: 70\n",
            "629/629 [==============================] - 7s 8ms/step - loss: 0.2014 - binary_accuracy: 0.9262 - auc_14: 0.9730\n",
            "0.9730498790740967\n",
            "Dataset: 71\n",
            "761/761 [==============================] - 9s 9ms/step - loss: 0.1387 - binary_accuracy: 0.9527 - auc_15: 0.9876\n",
            "0.9875651001930237\n",
            "Dataset: 72\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=55:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTzUpbn3jfVS",
        "outputId": "f6cb41a7-a8fc-4ad5-c989-5ca9b504e4a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 72\n",
            "277/277 [==============================] - 4s 8ms/step - loss: 0.3716 - binary_accuracy: 0.8361 - auc: 0.9147\n",
            "0.9147188663482666\n",
            "Dataset: 73\n",
            "578/578 [==============================] - 6s 8ms/step - loss: 0.1126 - binary_accuracy: 0.9620 - auc_1: 0.9913\n",
            "0.9913412928581238\n",
            "Dataset: 74\n",
            "502/502 [==============================] - 5s 7ms/step - loss: 0.1576 - binary_accuracy: 0.9422 - auc_2: 0.9846\n",
            "0.9845578074455261\n",
            "Dataset: 75\n",
            "678/678 [==============================] - 7s 7ms/step - loss: 0.0892 - binary_accuracy: 0.9696 - auc_3: 0.9943\n",
            "0.9943222999572754\n",
            "Dataset: 76\n",
            "426/426 [==============================] - 5s 8ms/step - loss: 0.2761 - binary_accuracy: 0.8904 - auc_4: 0.9567\n",
            "0.956654965877533\n",
            "Dataset: 77\n",
            "563/563 [==============================] - 5s 6ms/step - loss: 0.1133 - binary_accuracy: 0.9609 - auc_5: 0.9910\n",
            "0.9910193681716919\n",
            "Dataset: 78\n",
            "286/286 [==============================] - 3s 7ms/step - loss: 0.3595 - binary_accuracy: 0.8578 - auc_6: 0.9335\n",
            "0.933483362197876\n",
            "Dataset: 79\n",
            "236/236 [==============================] - 4s 8ms/step - loss: 0.1410 - binary_accuracy: 0.9533 - auc_7: 0.9870\n",
            "0.9870303273200989\n",
            "Dataset: 80\n",
            "560/560 [==============================] - 5s 7ms/step - loss: 0.1127 - binary_accuracy: 0.9614 - auc_8: 0.9909\n",
            "0.9908686280250549\n",
            "Dataset: 81\n",
            "715/715 [==============================] - 6s 6ms/step - loss: 0.1863 - binary_accuracy: 0.9322 - auc_9: 0.9792\n",
            "0.9792044162750244\n",
            "Dataset: 82\n",
            "334/334 [==============================] - 4s 7ms/step - loss: 0.3298 - binary_accuracy: 0.8600 - auc_10: 0.9345\n",
            "0.9345192909240723\n",
            "Dataset: 83\n",
            "591/591 [==============================] - 6s 8ms/step - loss: 0.0860 - binary_accuracy: 0.9697 - auc_11: 0.9949\n",
            "0.9949056506156921\n",
            "Dataset: 84\n",
            "824/824 [==============================] - 6s 6ms/step - loss: 0.2599 - binary_accuracy: 0.8962 - auc_12: 0.9604\n",
            "0.960409939289093\n",
            "Dataset: 85\n",
            "319/319 [==============================] - 3s 7ms/step - loss: 0.2453 - binary_accuracy: 0.9062 - auc_13: 0.9639\n",
            "0.963882565498352\n",
            "Dataset: 86\n",
            "570/570 [==============================] - 6s 7ms/step - loss: 0.1390 - binary_accuracy: 0.9512 - auc_14: 0.9866\n",
            "0.9865538477897644\n",
            "Dataset: 87\n",
            "409/409 [==============================] - 5s 8ms/step - loss: 0.2669 - binary_accuracy: 0.8940 - auc_15: 0.9596\n",
            "0.9596077799797058\n",
            "Dataset: 88\n",
            "250/250 [==============================] - 3s 7ms/step - loss: 0.4581 - binary_accuracy: 0.7921 - auc_16: 0.8792\n",
            "0.8791772127151489\n",
            "Dataset: 89\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=71:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IznWT163ipS",
        "outputId": "1a3195b8-4699-4806-d177-a6830a41895d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 89\n",
            "316/316 [==============================] - 4s 7ms/step - loss: 0.3232 - binary_accuracy: 0.8865 - auc: 0.9529\n",
            "0.9529357552528381\n",
            "Dataset: 90\n",
            "396/396 [==============================] - 5s 7ms/step - loss: 0.2433 - binary_accuracy: 0.9010 - auc_1: 0.9657\n",
            "0.9657166600227356\n",
            "Dataset: 91\n",
            "347/347 [==============================] - 4s 7ms/step - loss: 0.3767 - binary_accuracy: 0.8345 - auc_2: 0.9163\n",
            "0.9163068532943726\n",
            "Dataset: 92\n",
            "662/662 [==============================] - 6s 7ms/step - loss: 0.1960 - binary_accuracy: 0.9307 - auc_3: 0.9777\n",
            "0.9777268171310425\n",
            "Dataset: 93\n",
            "533/533 [==============================] - 5s 7ms/step - loss: 0.0723 - binary_accuracy: 0.9783 - auc_4: 0.9948\n",
            "0.994799017906189\n",
            "Dataset: 94\n",
            "1048/1048 [==============================] - 9s 7ms/step - loss: 0.1983 - binary_accuracy: 0.9289 - auc_5: 0.9785\n",
            "0.9785394072532654\n",
            "Dataset: 95\n",
            "249/249 [==============================] - 3s 7ms/step - loss: 0.2603 - binary_accuracy: 0.8918 - auc_6: 0.9597\n",
            "0.9596908688545227\n",
            "Dataset: 96\n",
            "400/400 [==============================] - 4s 8ms/step - loss: 0.1277 - binary_accuracy: 0.9559 - auc_7: 0.9885\n",
            "0.9885262250900269\n",
            "Dataset: 97\n",
            "559/559 [==============================] - 6s 8ms/step - loss: 0.1569 - binary_accuracy: 0.9444 - auc_8: 0.9837\n",
            "0.9836567640304565\n",
            "Dataset: 98\n",
            "572/572 [==============================] - 6s 8ms/step - loss: 0.1106 - binary_accuracy: 0.9623 - auc_9: 0.9913\n",
            "0.9912962913513184\n",
            "Dataset: 99\n",
            "239/239 [==============================] - 3s 7ms/step - loss: 0.5047 - binary_accuracy: 0.7650 - auc_10: 0.8504\n",
            "0.850351095199585\n",
            "Dataset: 100\n",
            "564/564 [==============================] - 5s 7ms/step - loss: 0.0984 - binary_accuracy: 0.9696 - auc_11: 0.9929\n",
            "0.9929468035697937\n",
            "Dataset: 101\n",
            "549/549 [==============================] - 5s 7ms/step - loss: 0.3111 - binary_accuracy: 0.8717 - auc_12: 0.9449\n",
            "0.9449282288551331\n",
            "Dataset: 102\n",
            "502/502 [==============================] - 5s 7ms/step - loss: 0.2052 - binary_accuracy: 0.9271 - auc_13: 0.9778\n",
            "0.9777621030807495\n",
            "Dataset: 103\n",
            "483/483 [==============================] - 4s 6ms/step - loss: 0.0900 - binary_accuracy: 0.9709 - auc_14: 0.9936\n",
            "0.9936025738716125\n",
            "Dataset: 104\n",
            "357/357 [==============================] - 4s 7ms/step - loss: 0.1059 - binary_accuracy: 0.9651 - auc_15: 0.9908\n",
            "0.9908197522163391\n",
            "Dataset: 105\n",
            "280/280 [==============================] - 4s 8ms/step - loss: 0.4259 - binary_accuracy: 0.8061 - auc_16: 0.8906\n",
            "0.8905954360961914\n",
            "Dataset: 106\n",
            "238/238 [==============================] - 3s 8ms/step - loss: 0.3885 - binary_accuracy: 0.8211 - auc_17: 0.9068\n",
            "0.9068058729171753\n",
            "Dataset: 107\n",
            "302/302 [==============================] - 4s 8ms/step - loss: 0.3975 - binary_accuracy: 0.8214 - auc_18: 0.9044\n",
            "0.9043962359428406\n",
            "Dataset: 108\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=88:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUJlOcDZpffb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ1ClAv8FuMT",
        "outputId": "da9fa403-f434-4155-943e-ad6689355d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 108\n",
            "675/675 [==============================] - 7s 7ms/step - loss: 0.1165 - binary_accuracy: 0.9588 - auc: 0.9908\n",
            "0.9908350110054016\n",
            "Dataset: 109\n",
            "245/245 [==============================] - 4s 7ms/step - loss: 0.2002 - binary_accuracy: 0.9266 - auc_1: 0.9763\n",
            "0.9762880802154541\n",
            "Dataset: 110\n",
            "655/655 [==============================] - 6s 7ms/step - loss: 0.0954 - binary_accuracy: 0.9675 - auc_2: 0.9932\n",
            "0.9931941628456116\n",
            "Dataset: 111\n",
            "357/357 [==============================] - 4s 7ms/step - loss: 0.2078 - binary_accuracy: 0.9227 - auc_3: 0.9747\n",
            "0.9747368693351746\n",
            "Dataset: 112\n",
            "245/245 [==============================] - 3s 7ms/step - loss: 0.4703 - binary_accuracy: 0.7803 - auc_4: 0.8689\n",
            "0.8688626885414124\n",
            "Dataset: 113\n",
            "757/757 [==============================] - 7s 7ms/step - loss: 0.0998 - binary_accuracy: 0.9705 - auc_5: 0.9923\n",
            "0.9923193454742432\n",
            "Dataset: 114\n",
            "505/505 [==============================] - 5s 6ms/step - loss: 0.0875 - binary_accuracy: 0.9703 - auc_6: 0.9941\n",
            "0.9940699338912964\n",
            "Dataset: 115\n",
            "559/559 [==============================] - 6s 8ms/step - loss: 0.0966 - binary_accuracy: 0.9658 - auc_7: 0.9935\n",
            "0.9934577345848083\n",
            "Dataset: 116\n",
            "491/491 [==============================] - 4s 7ms/step - loss: 0.2128 - binary_accuracy: 0.9206 - auc_8: 0.9739\n",
            "0.9739216566085815\n",
            "Dataset: 117\n",
            "467/467 [==============================] - 4s 7ms/step - loss: 0.1055 - binary_accuracy: 0.9649 - auc_9: 0.9914\n",
            "0.9913828372955322\n",
            "Dataset: 118\n",
            "742/742 [==============================] - 7s 8ms/step - loss: 0.2046 - binary_accuracy: 0.9226 - auc_10: 0.9756\n",
            "0.975624144077301\n",
            "Dataset: 119\n",
            "297/297 [==============================] - 4s 8ms/step - loss: 0.3468 - binary_accuracy: 0.8477 - auc_11: 0.9271\n",
            "0.9270617961883545\n",
            "Dataset: 120\n",
            "245/245 [==============================] - 3s 7ms/step - loss: 0.3293 - binary_accuracy: 0.8563 - auc_12: 0.9344\n",
            "0.9344022870063782\n",
            "Dataset: 121\n",
            "529/529 [==============================] - 5s 7ms/step - loss: 0.1222 - binary_accuracy: 0.9600 - auc_13: 0.9906\n",
            "0.9905737042427063\n",
            "Dataset: 122\n",
            "741/741 [==============================] - 7s 7ms/step - loss: 0.1113 - binary_accuracy: 0.9609 - auc_14: 0.9916\n",
            "0.9915959239006042\n",
            "Dataset: 123\n",
            "285/285 [==============================] - 3s 7ms/step - loss: 0.2994 - binary_accuracy: 0.8805 - auc_15: 0.9505\n",
            "0.9504982829093933\n",
            "Dataset: 124\n",
            "262/262 [==============================] - 3s 7ms/step - loss: 0.4073 - binary_accuracy: 0.8109 - auc_16: 0.8984\n",
            "0.8984352946281433\n",
            "Dataset: 125\n",
            "455/455 [==============================] - 6s 9ms/step - loss: 0.1526 - binary_accuracy: 0.9444 - auc_17: 0.9857\n",
            "0.9856993556022644\n",
            "Dataset: 126\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=107:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aio3tf24S8iH",
        "outputId": "ff45ab2e-d348-458e-8dda-26764b75aedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 126\n",
            "340/340 [==============================] - 4s 7ms/step - loss: 0.1909 - binary_accuracy: 0.9269 - auc: 0.9779\n",
            "0.9778608679771423\n",
            "Dataset: 127\n",
            "711/711 [==============================] - 6s 7ms/step - loss: 0.1248 - binary_accuracy: 0.9573 - auc_1: 0.9890\n",
            "0.9890339374542236\n",
            "Dataset: 128\n",
            "494/494 [==============================] - 5s 7ms/step - loss: 0.0682 - binary_accuracy: 0.9785 - auc_2: 0.9957\n",
            "0.9956973195075989\n",
            "Dataset: 129\n",
            "350/350 [==============================] - 4s 7ms/step - loss: 0.2151 - binary_accuracy: 0.9190 - auc_3: 0.9723\n",
            "0.9722987413406372\n",
            "Dataset: 130\n",
            "317/317 [==============================] - 3s 7ms/step - loss: 0.2670 - binary_accuracy: 0.8923 - auc_4: 0.9594\n",
            "0.959394633769989\n",
            "Dataset: 131\n",
            "452/452 [==============================] - 5s 7ms/step - loss: 0.1966 - binary_accuracy: 0.9256 - auc_5: 0.9770\n",
            "0.9770217537879944\n",
            "Dataset: 132\n",
            "671/671 [==============================] - 6s 8ms/step - loss: 0.1055 - binary_accuracy: 0.9657 - auc_6: 0.9924\n",
            "0.9924278855323792\n",
            "Dataset: 133\n",
            "483/483 [==============================] - 5s 8ms/step - loss: 0.1231 - binary_accuracy: 0.9556 - auc_7: 0.9898\n",
            "0.9898302555084229\n",
            "Dataset: 134\n",
            "243/243 [==============================] - 3s 8ms/step - loss: 0.3520 - binary_accuracy: 0.8544 - auc_8: 0.9333\n",
            "0.9332779049873352\n",
            "Dataset: 135\n",
            "456/456 [==============================] - 4s 7ms/step - loss: 0.0839 - binary_accuracy: 0.9730 - auc_9: 0.9943\n",
            "0.9943103194236755\n",
            "Dataset: 136\n",
            "377/377 [==============================] - 5s 9ms/step - loss: 0.2636 - binary_accuracy: 0.8913 - auc_10: 0.9603\n",
            "0.9602546095848083\n",
            "Dataset: 137\n",
            "236/236 [==============================] - 3s 9ms/step - loss: 0.3048 - binary_accuracy: 0.8685 - auc_11: 0.9433\n",
            "0.9432911276817322\n",
            "Dataset: 138\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=125:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "62GsVFrxTjWP",
        "outputId": "12e61a38-925a-42e8-d547-f3b827375787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 139\n",
            "361/361 [==============================] - 4s 8ms/step - loss: 0.1678 - binary_accuracy: 0.9368 - auc: 0.9827\n",
            "0.9826581478118896\n",
            "Dataset: 140\n",
            "432/432 [==============================] - 6s 10ms/step - loss: 0.2621 - binary_accuracy: 0.8927 - auc_1: 0.9602\n",
            "0.9601830840110779\n",
            "Dataset: 141\n",
            "267/267 [==============================] - 6s 15ms/step - loss: 0.2261 - binary_accuracy: 0.9094 - auc_2: 0.9699\n",
            "0.9699382185935974\n",
            "Dataset: 142\n",
            "557/557 [==============================] - 7s 10ms/step - loss: 0.1491 - binary_accuracy: 0.9483 - auc_3: 0.9851\n",
            "0.9851206541061401\n",
            "Dataset: 143\n",
            "653/653 [==============================] - 6s 8ms/step - loss: 0.1723 - binary_accuracy: 0.9452 - auc_4: 0.9834\n",
            "0.983420193195343\n",
            "Dataset: 144\n",
            "292/292 [==============================] - 4s 8ms/step - loss: 0.2904 - binary_accuracy: 0.8867 - auc_5: 0.9557\n",
            "0.9557333588600159\n",
            "Dataset: 145\n",
            "497/497 [==============================] - 5s 8ms/step - loss: 0.0614 - binary_accuracy: 0.9838 - auc_6: 0.9956\n",
            "0.9955934286117554\n",
            "Dataset: 146\n",
            "312/312 [==============================] - 4s 7ms/step - loss: 0.3443 - binary_accuracy: 0.8527 - auc_7: 0.9308\n",
            "0.9308165907859802\n",
            "Dataset: 147\n",
            "265/265 [==============================] - 4s 9ms/step - loss: 0.4495 - binary_accuracy: 0.7902 - auc_8: 0.8772\n",
            "0.8772042989730835\n",
            "Dataset: 148\n",
            "407/407 [==============================] - 4s 7ms/step - loss: 0.2926 - binary_accuracy: 0.8847 - auc_9: 0.9538\n",
            "0.9538384079933167\n",
            "Dataset: 149\n",
            "464/464 [==============================] - 5s 8ms/step - loss: 0.0772 - binary_accuracy: 0.9747 - auc_10: 0.9951\n",
            "0.9951468110084534\n",
            "Dataset: 150\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-995dcd41590e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                                         ]\n\u001b[1;32m     15\u001b[0m                               )\n\u001b[0;32m---> 16\u001b[0;31m   history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n\u001b[0m\u001b[1;32m     17\u001b[0m                               \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   1800\u001b[0m                             \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1413\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    691\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=138:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9f5e90-40cc-4e26-a6e0-d81425b06f68",
        "id": "UtBD-dSXINvI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 150\n",
            "525/525 [==============================] - 6s 8ms/step - loss: 0.1498 - binary_accuracy: 0.9430 - auc: 0.9858\n",
            "0.9858456254005432\n",
            "Dataset: 151\n",
            "283/283 [==============================] - 4s 9ms/step - loss: 0.0646 - binary_accuracy: 0.9813 - auc_1: 0.9955\n",
            "0.995506227016449\n",
            "Dataset: 152\n",
            "556/556 [==============================] - 7s 9ms/step - loss: 0.1032 - binary_accuracy: 0.9668 - auc_2: 0.9930\n",
            "0.9929628968238831\n",
            "Dataset: 153\n",
            "264/264 [==============================] - 3s 7ms/step - loss: 0.3564 - binary_accuracy: 0.8453 - auc_3: 0.9240\n",
            "0.9239739179611206\n",
            "Dataset: 154\n",
            "431/431 [==============================] - 4s 7ms/step - loss: 0.1297 - binary_accuracy: 0.9547 - auc_4: 0.9875\n",
            "0.9874840974807739\n",
            "Dataset: 155\n",
            "586/586 [==============================] - 6s 7ms/step - loss: 0.2244 - binary_accuracy: 0.9238 - auc_5: 0.9722\n",
            "0.9721807837486267\n",
            "Dataset: 156\n",
            "279/279 [==============================] - 5s 10ms/step - loss: 0.3067 - binary_accuracy: 0.8748 - auc_6: 0.9460\n",
            "0.9459815621376038\n",
            "Dataset: 157\n",
            "437/437 [==============================] - 5s 8ms/step - loss: 0.3415 - binary_accuracy: 0.8545 - auc_7: 0.9316\n",
            "0.9315682053565979\n",
            "Dataset: 158\n",
            "672/672 [==============================] - 6s 7ms/step - loss: 0.1360 - binary_accuracy: 0.9513 - auc_8: 0.9875\n",
            "0.9874973297119141\n",
            "Dataset: 159\n",
            "513/513 [==============================] - 5s 7ms/step - loss: 0.0953 - binary_accuracy: 0.9688 - auc_9: 0.9933\n",
            "0.9932547807693481\n",
            "Dataset: 160\n",
            "515/515 [==============================] - 5s 7ms/step - loss: 0.0928 - binary_accuracy: 0.9676 - auc_10: 0.9939\n",
            "0.9939046502113342\n",
            "Dataset: 161\n",
            "825/825 [==============================] - 8s 7ms/step - loss: 0.1619 - binary_accuracy: 0.9411 - auc_11: 0.9836\n",
            "0.9835938811302185\n",
            "Dataset: 162\n",
            "606/606 [==============================] - 6s 7ms/step - loss: 0.1391 - binary_accuracy: 0.9544 - auc_12: 0.9878\n",
            "0.9877949357032776\n",
            "Dataset: 163\n",
            "480/480 [==============================] - 5s 7ms/step - loss: 0.1330 - binary_accuracy: 0.9551 - auc_13: 0.9880\n",
            "0.9879627227783203\n",
            "Dataset: 164\n",
            "463/463 [==============================] - 4s 7ms/step - loss: 0.0961 - binary_accuracy: 0.9683 - auc_14: 0.9930\n",
            "0.9930088520050049\n",
            "Dataset: 165\n",
            "378/378 [==============================] - 4s 7ms/step - loss: 0.2801 - binary_accuracy: 0.8872 - auc_15: 0.9523\n",
            "0.9522536396980286\n",
            "Dataset: 166\n",
            "659/659 [==============================] - 6s 7ms/step - loss: 0.1030 - binary_accuracy: 0.9640 - auc_16: 0.9923\n",
            "0.9923349022865295\n",
            "Dataset: 167\n",
            "615/615 [==============================] - 6s 8ms/step - loss: 0.1208 - binary_accuracy: 0.9593 - auc_17: 0.9896\n",
            "0.9896381497383118\n",
            "Dataset: 168\n",
            "306/306 [==============================] - 4s 8ms/step - loss: 0.1441 - binary_accuracy: 0.9521 - auc_18: 0.9867\n",
            "0.9867297410964966\n",
            "Dataset: 169\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=149:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89MkQaxd1vjx",
        "outputId": "0c97d25e-0a3e-4f68-cad9-fe56ae27a960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 169\n",
            "245/245 [==============================] - 3s 7ms/step - loss: 0.3975 - binary_accuracy: 0.8190 - auc: 0.9014\n",
            "0.9013733267784119\n",
            "Dataset: 170\n",
            "679/679 [==============================] - 7s 7ms/step - loss: 0.0859 - binary_accuracy: 0.9719 - auc_1: 0.9944\n",
            "0.9943748116493225\n",
            "Dataset: 171\n",
            "380/380 [==============================] - 4s 7ms/step - loss: 0.2273 - binary_accuracy: 0.9058 - auc_2: 0.9665\n",
            "0.966536283493042\n",
            "Dataset: 172\n",
            "289/289 [==============================] - 3s 8ms/step - loss: 0.3791 - binary_accuracy: 0.8336 - auc_3: 0.9140\n",
            "0.9139936566352844\n",
            "Dataset: 173\n",
            "342/342 [==============================] - 4s 9ms/step - loss: 0.2560 - binary_accuracy: 0.8949 - auc_4: 0.9603\n",
            "0.9603320360183716\n",
            "Dataset: 174\n",
            "915/915 [==============================] - 8s 7ms/step - loss: 0.1405 - binary_accuracy: 0.9495 - auc_5: 0.9873\n",
            "0.9872773885726929\n",
            "Dataset: 175\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=168:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXhnx1X2piIg",
        "outputId": "94d0c1ea-5f45-44cb-d004-711a8454a595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 175\n",
            "532/532 [==============================] - 5s 7ms/step - loss: 0.0992 - binary_accuracy: 0.9678 - auc: 0.9924\n",
            "0.9924378991127014\n",
            "Dataset: 176\n",
            "568/568 [==============================] - 6s 7ms/step - loss: 0.1136 - binary_accuracy: 0.9617 - auc_1: 0.9909\n",
            "0.9908649325370789\n",
            "Dataset: 177\n",
            "480/480 [==============================] - 5s 8ms/step - loss: 0.1747 - binary_accuracy: 0.9316 - auc_2: 0.9805\n",
            "0.9805411100387573\n",
            "Dataset: 178\n",
            "513/513 [==============================] - 5s 7ms/step - loss: 0.1076 - binary_accuracy: 0.9632 - auc_3: 0.9920\n",
            "0.991970956325531\n",
            "Dataset: 179\n",
            "341/341 [==============================] - 5s 8ms/step - loss: 0.3313 - binary_accuracy: 0.8567 - auc_4: 0.9349\n",
            "0.9349426627159119\n",
            "Dataset: 180\n",
            "251/251 [==============================] - 3s 7ms/step - loss: 0.2745 - binary_accuracy: 0.8883 - auc_5: 0.9567\n",
            "0.9567063450813293\n",
            "Dataset: 181\n",
            "485/485 [==============================] - 5s 6ms/step - loss: 0.0842 - binary_accuracy: 0.9711 - auc_6: 0.9946\n",
            "0.9945854544639587\n",
            "Dataset: 182\n",
            "522/522 [==============================] - 5s 6ms/step - loss: 0.1180 - binary_accuracy: 0.9574 - auc_7: 0.9909\n",
            "0.9908897876739502\n",
            "Dataset: 183\n",
            "262/262 [==============================] - 3s 7ms/step - loss: 0.4278 - binary_accuracy: 0.8003 - auc_8: 0.8896\n",
            "0.8896013498306274\n",
            "Dataset: 184\n",
            "252/252 [==============================] - 4s 10ms/step - loss: 0.3020 - binary_accuracy: 0.8724 - auc_9: 0.9475\n",
            "0.9475192427635193\n",
            "Dataset: 185\n",
            "465/465 [==============================] - 5s 9ms/step - loss: 0.0663 - binary_accuracy: 0.9787 - auc_10: 0.9963\n",
            "0.996282696723938\n",
            "Dataset: 186\n",
            "422/422 [==============================] - 4s 7ms/step - loss: 0.0905 - binary_accuracy: 0.9680 - auc_11: 0.9934\n",
            "0.9933984875679016\n",
            "Dataset: 187\n",
            "606/606 [==============================] - 5s 7ms/step - loss: 0.1814 - binary_accuracy: 0.9335 - auc_12: 0.9782\n",
            "0.9782183170318604\n",
            "Dataset: 188\n",
            "490/490 [==============================] - 5s 7ms/step - loss: 0.0573 - binary_accuracy: 0.9800 - auc_13: 0.9975\n",
            "0.9975199103355408\n",
            "Dataset: 189\n",
            "533/533 [==============================] - 6s 7ms/step - loss: 0.1296 - binary_accuracy: 0.9581 - auc_14: 0.9881\n",
            "0.9881489872932434\n",
            "Dataset: 190\n",
            "487/487 [==============================] - 5s 9ms/step - loss: 0.2044 - binary_accuracy: 0.9213 - auc_15: 0.9756\n",
            "0.9755613803863525\n",
            "Dataset: 191\n",
            "475/475 [==============================] - 5s 8ms/step - loss: 0.1248 - binary_accuracy: 0.9548 - auc_16: 0.9898\n",
            "0.989804744720459\n",
            "Dataset: 192\n",
            "571/571 [==============================] - 5s 7ms/step - loss: 0.3998 - binary_accuracy: 0.8418 - auc_17: 0.9181\n",
            "0.9181244969367981\n",
            "Dataset: 193\n",
            "276/276 [==============================] - 3s 7ms/step - loss: 0.5010 - binary_accuracy: 0.7516 - auc_18: 0.8374\n",
            "0.8374230861663818\n",
            "Dataset: 194\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=149:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDwfI6gwQmla",
        "outputId": "800d0d94-f636-4b9a-e3ef-c8d6e42927bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 194\n",
            "461/461 [==============================] - 5s 7ms/step - loss: 0.0762 - binary_accuracy: 0.9759 - auc: 0.9953\n",
            "0.9952648878097534\n",
            "Dataset: 195\n",
            "313/313 [==============================] - 4s 9ms/step - loss: 0.2857 - binary_accuracy: 0.8899 - auc_1: 0.9559\n",
            "0.9559028744697571\n",
            "Dataset: 196\n",
            "288/288 [==============================] - 3s 7ms/step - loss: 0.1017 - binary_accuracy: 0.9690 - auc_2: 0.9914\n",
            "0.9914003610610962\n",
            "Dataset: 197\n",
            "569/569 [==============================] - 6s 8ms/step - loss: 0.0908 - binary_accuracy: 0.9700 - auc_3: 0.9935\n",
            "0.9935169816017151\n",
            "Dataset: 198\n",
            "239/239 [==============================] - 3s 7ms/step - loss: 0.3121 - binary_accuracy: 0.8733 - auc_4: 0.9446\n",
            "0.9446194171905518\n",
            "Dataset: 199\n",
            "534/534 [==============================] - 5s 7ms/step - loss: 0.1141 - binary_accuracy: 0.9620 - auc_5: 0.9904\n",
            "0.990407407283783\n",
            "Dataset: 200\n",
            "243/243 [==============================] - 3s 7ms/step - loss: 0.3857 - binary_accuracy: 0.8273 - auc_6: 0.9101\n",
            "0.9100667834281921\n",
            "Dataset: 201\n",
            "554/554 [==============================] - 5s 7ms/step - loss: 0.1165 - binary_accuracy: 0.9620 - auc_7: 0.9911\n",
            "0.9910739064216614\n",
            "Dataset: 202\n",
            "473/473 [==============================] - 5s 7ms/step - loss: 0.0923 - binary_accuracy: 0.9695 - auc_8: 0.9934\n",
            "0.993391215801239\n",
            "Dataset: 203\n",
            "297/297 [==============================] - 3s 7ms/step - loss: 0.4280 - binary_accuracy: 0.8013 - auc_9: 0.8888\n",
            "0.888762891292572\n",
            "Dataset: 204\n",
            "664/664 [==============================] - 6s 7ms/step - loss: 0.1128 - binary_accuracy: 0.9611 - auc_10: 0.9905\n",
            "0.9905170798301697\n",
            "Dataset: 205\n",
            "704/704 [==============================] - 7s 7ms/step - loss: 0.1514 - binary_accuracy: 0.9475 - auc_11: 0.9851\n",
            "0.9851080179214478\n",
            "Dataset: 206\n",
            "571/571 [==============================] - 6s 8ms/step - loss: 0.2245 - binary_accuracy: 0.9184 - auc_12: 0.9713\n",
            "0.9713033437728882\n",
            "Dataset: 207\n",
            "323/323 [==============================] - 4s 7ms/step - loss: 0.3352 - binary_accuracy: 0.8692 - auc_13: 0.9425\n",
            "0.94245445728302\n",
            "Dataset: 208\n",
            "442/442 [==============================] - 7s 8ms/step - loss: 0.3113 - binary_accuracy: 0.8698 - auc_14: 0.9425\n",
            "0.9424878358840942\n",
            "Dataset: 209\n",
            "657/657 [==============================] - 6s 7ms/step - loss: 0.0976 - binary_accuracy: 0.9664 - auc_15: 0.9934\n",
            "0.9934165477752686\n",
            "Dataset: 210\n",
            "267/267 [==============================] - 3s 7ms/step - loss: 0.2406 - binary_accuracy: 0.9134 - auc_16: 0.9700\n",
            "0.970041036605835\n",
            "Dataset: 211\n",
            "712/712 [==============================] - 6s 7ms/step - loss: 0.1028 - binary_accuracy: 0.9661 - auc_17: 0.9922\n",
            "0.9921844601631165\n",
            "Dataset: 212\n",
            "256/256 [==============================] - 3s 7ms/step - loss: 0.4065 - binary_accuracy: 0.8213 - auc_18: 0.9005\n",
            "0.9004718661308289\n",
            "Dataset: 213\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=193:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZh4HR203Fcv",
        "outputId": "1799c2f1-8ace-46ec-f23c-bf03764cbc2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 213\n",
            "535/535 [==============================] - 6s 7ms/step - loss: 0.1065 - binary_accuracy: 0.9651 - auc: 0.9923\n",
            "0.9923228025436401\n",
            "Dataset: 214\n",
            "615/615 [==============================] - 6s 7ms/step - loss: 0.1498 - binary_accuracy: 0.9500 - auc_1: 0.9854\n",
            "0.9853849411010742\n",
            "Dataset: 215\n",
            "461/461 [==============================] - 5s 8ms/step - loss: 0.1038 - binary_accuracy: 0.9653 - auc_2: 0.9921\n",
            "0.9921091794967651\n",
            "Dataset: 216\n",
            "560/560 [==============================] - 6s 8ms/step - loss: 0.1007 - binary_accuracy: 0.9662 - auc_3: 0.9926\n",
            "0.9925958514213562\n",
            "Dataset: 217\n",
            "494/494 [==============================] - 7s 11ms/step - loss: 0.1322 - binary_accuracy: 0.9532 - auc_4: 0.9890\n",
            "0.9890058636665344\n",
            "Dataset: 218\n",
            "456/456 [==============================] - 5s 8ms/step - loss: 0.3583 - binary_accuracy: 0.8545 - auc_5: 0.9300\n",
            "0.9299664497375488\n",
            "Dataset: 219\n",
            "341/341 [==============================] - 4s 7ms/step - loss: 0.3847 - binary_accuracy: 0.8321 - auc_6: 0.9121\n",
            "0.9121113419532776\n",
            "Dataset: 220\n",
            "440/440 [==============================] - 4s 7ms/step - loss: 0.2692 - binary_accuracy: 0.8969 - auc_7: 0.9573\n",
            "0.9572963118553162\n",
            "Dataset: 221\n",
            "296/296 [==============================] - 3s 8ms/step - loss: 0.2882 - binary_accuracy: 0.8789 - auc_8: 0.9503\n",
            "0.9503132700920105\n",
            "Dataset: 222\n",
            "525/525 [==============================] - 7s 7ms/step - loss: 0.0986 - binary_accuracy: 0.9672 - auc_9: 0.9930\n",
            "0.9929815530776978\n",
            "Dataset: 223\n",
            "302/302 [==============================] - 4s 8ms/step - loss: 0.4188 - binary_accuracy: 0.8090 - auc_10: 0.8958\n",
            "0.8957945704460144\n",
            "Dataset: 224\n",
            "543/543 [==============================] - 7s 8ms/step - loss: 0.1206 - binary_accuracy: 0.9590 - auc_11: 0.9909\n",
            "0.9908850193023682\n",
            "Dataset: 225\n",
            "310/310 [==============================] - 3s 7ms/step - loss: 0.3409 - binary_accuracy: 0.8493 - auc_12: 0.9285\n",
            "0.9285095930099487\n",
            "Dataset: 226\n",
            "249/249 [==============================] - 3s 7ms/step - loss: 0.3469 - binary_accuracy: 0.8511 - auc_13: 0.9286\n",
            "0.928642988204956\n",
            "Dataset: 227\n",
            "281/281 [==============================] - 4s 7ms/step - loss: 0.3234 - binary_accuracy: 0.8644 - auc_14: 0.9391\n",
            "0.9391118288040161\n",
            "Dataset: 228\n",
            "369/369 [==============================] - 4s 8ms/step - loss: 0.1562 - binary_accuracy: 0.9433 - auc_15: 0.9822\n",
            "0.9822400808334351\n",
            "Dataset: 229\n",
            "265/265 [==============================] - 3s 7ms/step - loss: 0.4609 - binary_accuracy: 0.7900 - auc_16: 0.8772\n",
            "0.8771888017654419\n",
            "Dataset: 230\n",
            "297/297 [==============================] - 3s 7ms/step - loss: 0.3444 - binary_accuracy: 0.8583 - auc_17: 0.9360\n",
            "0.9360307455062866\n",
            "Dataset: 231\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=212:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2181e68f-a699-4942-942e-5fa7673b307d",
        "id": "V9E3cESl_bED"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 231\n",
            "553/553 [==============================] - 6s 8ms/step - loss: 0.1412 - binary_accuracy: 0.9547 - auc: 0.9876\n",
            "0.9875994920730591\n",
            "Dataset: 232\n",
            "262/262 [==============================] - 4s 7ms/step - loss: 0.3674 - binary_accuracy: 0.8348 - auc_1: 0.9185\n",
            "0.9184787273406982\n",
            "Dataset: 233\n",
            "352/352 [==============================] - 4s 7ms/step - loss: 0.3059 - binary_accuracy: 0.8708 - auc_2: 0.9452\n",
            "0.9452080726623535\n",
            "Dataset: 234\n",
            "992/992 [==============================] - 8s 7ms/step - loss: 0.1380 - binary_accuracy: 0.9538 - auc_3: 0.9879\n",
            "0.987942099571228\n",
            "Dataset: 235\n",
            "258/258 [==============================] - 4s 9ms/step - loss: 0.3523 - binary_accuracy: 0.8525 - auc_4: 0.9294\n",
            "0.9294230341911316\n",
            "Dataset: 236\n",
            "595/595 [==============================] - 6s 8ms/step - loss: 0.1137 - binary_accuracy: 0.9657 - auc_5: 0.9914\n",
            "0.991375207901001\n",
            "Dataset: 237\n",
            "385/385 [==============================] - 5s 7ms/step - loss: 0.1733 - binary_accuracy: 0.9372 - auc_6: 0.9813\n",
            "0.981286883354187\n",
            "Dataset: 238\n",
            "601/601 [==============================] - 5s 6ms/step - loss: 0.1194 - binary_accuracy: 0.9621 - auc_7: 0.9910\n",
            "0.9910107851028442\n",
            "Dataset: 239\n",
            "1121/1121 [==============================] - 9s 7ms/step - loss: 0.1668 - binary_accuracy: 0.9391 - auc_8: 0.9829\n",
            "0.982881486415863\n",
            "Dataset: 240\n",
            "611/611 [==============================] - 5s 7ms/step - loss: 0.1026 - binary_accuracy: 0.9635 - auc_9: 0.9927\n",
            "0.9926669597625732\n",
            "Dataset: 241\n",
            "697/697 [==============================] - 6s 7ms/step - loss: 0.1088 - binary_accuracy: 0.9607 - auc_10: 0.9919\n",
            "0.9918854832649231\n",
            "Dataset: 242\n",
            "381/381 [==============================] - 4s 8ms/step - loss: 0.2802 - binary_accuracy: 0.8837 - auc_11: 0.9517\n",
            "0.9516823887825012\n",
            "Dataset: 243\n",
            "240/240 [==============================] - 3s 9ms/step - loss: 0.3925 - binary_accuracy: 0.8207 - auc_12: 0.9044\n",
            "0.9044122695922852\n",
            "Dataset: 244\n",
            "461/461 [==============================] - 4s 7ms/step - loss: 0.0790 - binary_accuracy: 0.9723 - auc_13: 0.9951\n",
            "0.9950674772262573\n",
            "Dataset: 245\n",
            "236/236 [==============================] - 3s 7ms/step - loss: 0.4304 - binary_accuracy: 0.8189 - auc_14: 0.9010\n",
            "0.9010213017463684\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=230:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  # avg_acc.append(data[2])\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3668d3-cbd9-4318-f9ec-c461879ffd49",
        "id": "xQI9lw0jKZx0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 1\n",
            "275/275 [==============================] - 4s 8ms/step - loss: 0.4022 - binary_accuracy: 0.8163 - auc_2: 0.8986\n",
            "0.8985990881919861\n",
            "Dataset: 7\n",
            "252/252 [==============================] - 4s 9ms/step - loss: 0.4013 - binary_accuracy: 0.8057 - auc_3: 0.8984\n",
            "0.8984169960021973\n",
            "Dataset: 11\n",
            "246/246 [==============================] - 3s 8ms/step - loss: 0.4108 - binary_accuracy: 0.8093 - auc_4: 0.8963\n",
            "0.8962745666503906\n",
            "Dataset: 14\n",
            "236/236 [==============================] - 4s 10ms/step - loss: 0.4300 - binary_accuracy: 0.8030 - auc_5: 0.8975\n",
            "0.8975381851196289\n",
            "Dataset: 48\n",
            "267/267 [==============================] - 3s 8ms/step - loss: 0.4039 - binary_accuracy: 0.8105 - auc_6: 0.9004\n",
            "0.9004409313201904\n",
            "Dataset: 62\n",
            "244/244 [==============================] - 3s 8ms/step - loss: 0.4626 - binary_accuracy: 0.7783 - auc_7: 0.8660\n",
            "0.8659942150115967\n",
            "Dataset: 88\n",
            "250/250 [==============================] - 4s 11ms/step - loss: 0.4421 - binary_accuracy: 0.7847 - auc_8: 0.8815\n",
            "0.8814924955368042\n",
            "Dataset: 99\n",
            "239/239 [==============================] - 4s 9ms/step - loss: 0.4792 - binary_accuracy: 0.7619 - auc_9: 0.8542\n",
            "0.8542275428771973\n",
            "Dataset: 105\n",
            "280/280 [==============================] - 4s 9ms/step - loss: 0.4310 - binary_accuracy: 0.7998 - auc_10: 0.8906\n",
            "0.8906118869781494\n",
            "Dataset: 112\n",
            "245/245 [==============================] - 3s 7ms/step - loss: 0.4520 - binary_accuracy: 0.7873 - auc_11: 0.8706\n",
            "0.8706396818161011\n",
            "Dataset: 124\n",
            "262/262 [==============================] - 3s 8ms/step - loss: 0.4010 - binary_accuracy: 0.8084 - auc_12: 0.8992\n",
            "0.8992132544517517\n",
            "Dataset: 147\n",
            "265/265 [==============================] - 5s 10ms/step - loss: 0.4409 - binary_accuracy: 0.7879 - auc_13: 0.8786\n",
            "0.8785998225212097\n",
            "Dataset: 183\n",
            "262/262 [==============================] - 3s 8ms/step - loss: 0.4145 - binary_accuracy: 0.8050 - auc_14: 0.8923\n",
            "0.8922933340072632\n",
            "Dataset: 193\n",
            "276/276 [==============================] - 4s 10ms/step - loss: 0.5015 - binary_accuracy: 0.7499 - auc_15: 0.8370\n",
            "0.8370352387428284\n",
            "Dataset: 203\n",
            "297/297 [==============================] - 318s 1s/step - loss: 0.4182 - binary_accuracy: 0.8009 - auc_16: 0.8900\n",
            "0.8899866938591003\n",
            "Dataset: 223\n",
            "302/302 [==============================] - 4s 8ms/step - loss: 0.4048 - binary_accuracy: 0.8111 - auc_17: 0.8975\n",
            "0.8975086808204651\n",
            "Dataset: 229\n",
            "265/265 [==============================] - 4s 8ms/step - loss: 0.4296 - binary_accuracy: 0.7964 - auc_18: 0.8828\n",
            "0.8827935457229614\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "indices=[1,7,11,14,48,62,88,99,105,112,124,147,183,193,203,223,229]\n",
        "for train_label,test_feature,test_label in zip(train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i not in indices:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_large_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(large_train_features[i-1],dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=1024,\n",
        "                              epochs=2,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.01,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([early_stop])\n",
        "\n",
        "                                          )\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  print(data[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medium Datasets"
      ],
      "metadata": {
        "id": "_5cHHVvZuFvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Fine Tuning"
      ],
      "metadata": {
        "id": "nGaJo4PHumvM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVDi-mYl-xVr",
        "outputId": "7fe7b205-67cf-4260-b9e0-dbe92ce8d8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 1\n",
            "2/2 [==============================] - 8s 1s/step - loss: 0.3474 - binary_accuracy: 0.8451 - auc_1: 0.9248\n",
            "Dataset: 2\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3741 - binary_accuracy: 0.8292 - auc_1: 0.9158\n",
            "Dataset: 3\n",
            "2/2 [==============================] - 1s 789ms/step - loss: 0.2989 - binary_accuracy: 0.8672 - auc_1: 0.9458\n",
            "Dataset: 4\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2041 - binary_accuracy: 0.9211 - auc_1: 0.9825\n",
            "Dataset: 5\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2677 - binary_accuracy: 0.8890 - auc_1: 0.9562\n",
            "Dataset: 6\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3065 - binary_accuracy: 0.8645 - auc_1: 0.9419\n",
            "Dataset: 7\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3587 - binary_accuracy: 0.8456 - auc_1: 0.9203\n",
            "Dataset: 8\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3820 - binary_accuracy: 0.8287 - auc_1: 0.9111\n",
            "Dataset: 9\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4909 - binary_accuracy: 0.7691 - auc_1: 0.8706\n",
            "Dataset: 10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2278 - binary_accuracy: 0.9009 - auc_1: 0.9693\n",
            "Dataset: 11\n",
            "2/2 [==============================] - 1s 944ms/step - loss: 0.3444 - binary_accuracy: 0.8459 - auc_1: 0.9274\n",
            "Dataset: 12\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3417 - binary_accuracy: 0.8502 - auc_1: 0.9288\n",
            "Dataset: 13\n",
            "2/2 [==============================] - 1s 571ms/step - loss: 0.2862 - binary_accuracy: 0.8772 - auc_1: 0.9500\n",
            "Dataset: 14\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4481 - binary_accuracy: 0.7968 - auc_1: 0.8933\n",
            "Dataset: 15\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.2864 - binary_accuracy: 0.8826 - auc_1: 0.9506\n",
            "Dataset: 16\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3777 - binary_accuracy: 0.8422 - auc_1: 0.9203\n",
            "Dataset: 17\n",
            "2/2 [==============================] - 1s 792ms/step - loss: 0.2997 - binary_accuracy: 0.8744 - auc_1: 0.9450\n",
            "Dataset: 18\n",
            "2/2 [==============================] - 1s 728ms/step - loss: 0.3516 - binary_accuracy: 0.8468 - auc_1: 0.9257\n",
            "Dataset: 19\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.3135 - binary_accuracy: 0.8707 - auc_1: 0.9409\n",
            "Dataset: 20\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 0.2860 - binary_accuracy: 0.8805 - auc_1: 0.9498\n",
            "Dataset: 21\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3228 - binary_accuracy: 0.8588 - auc_1: 0.9362\n",
            "Dataset: 22\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3921 - binary_accuracy: 0.8277 - auc_1: 0.9068\n",
            "Dataset: 23\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3412 - binary_accuracy: 0.8473 - auc_1: 0.9312\n",
            "Dataset: 24\n",
            "2/2 [==============================] - 1s 717ms/step - loss: 0.3449 - binary_accuracy: 0.8501 - auc_1: 0.9270\n",
            "Dataset: 25\n",
            "2/2 [==============================] - 1s 765ms/step - loss: 0.2884 - binary_accuracy: 0.8759 - auc_1: 0.9491\n",
            "Dataset: 26\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2790 - binary_accuracy: 0.8867 - auc_1: 0.9542\n",
            "Dataset: 27\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 0.2657 - binary_accuracy: 0.8956 - auc_1: 0.9571\n",
            "Dataset: 28\n",
            "2/2 [==============================] - 1s 464ms/step - loss: 0.2520 - binary_accuracy: 0.8987 - auc_1: 0.9642\n",
            "Dataset: 29\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2491 - binary_accuracy: 0.9009 - auc_1: 0.9623\n",
            "Dataset: 30\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5369 - binary_accuracy: 0.7567 - auc_1: 0.8574\n",
            "Dataset: 31\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3985 - binary_accuracy: 0.8166 - auc_1: 0.9067\n",
            "Dataset: 32\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5874 - binary_accuracy: 0.7276 - auc_1: 0.8289\n",
            "Dataset: 33\n",
            "2/2 [==============================] - 1s 565ms/step - loss: 0.4241 - binary_accuracy: 0.8001 - auc_1: 0.8937\n",
            "Dataset: 34\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2934 - binary_accuracy: 0.8728 - auc_1: 0.9472\n",
            "Dataset: 35\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3034 - binary_accuracy: 0.8652 - auc_1: 0.9434\n",
            "Dataset: 36\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3496 - binary_accuracy: 0.8457 - auc_1: 0.9272\n",
            "Dataset: 37\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4139 - binary_accuracy: 0.8169 - auc_1: 0.9055\n",
            "Dataset: 38\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 0.3315 - binary_accuracy: 0.8553 - auc_1: 0.9325\n",
            "Dataset: 39\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.5698 - binary_accuracy: 0.7430 - auc_1: 0.8452\n",
            "Dataset: 40\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.4750 - binary_accuracy: 0.7850 - auc_1: 0.8802\n",
            "Dataset: 41\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4140 - binary_accuracy: 0.8133 - auc_1: 0.9004\n",
            "Dataset: 42\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2870 - binary_accuracy: 0.8799 - auc_1: 0.9496\n",
            "Dataset: 43\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3732 - binary_accuracy: 0.8301 - auc_1: 0.9151\n",
            "Dataset: 44\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.2861 - binary_accuracy: 0.8738 - auc_1: 0.9496\n",
            "Dataset: 45\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.2725 - binary_accuracy: 0.8919 - auc_1: 0.9544\n",
            "Dataset: 46\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.2414 - binary_accuracy: 0.8924 - auc_1: 0.9646\n",
            "Dataset: 47\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.5159 - binary_accuracy: 0.7430 - auc_1: 0.8541\n",
            "Dataset: 48\n",
            "2/2 [==============================] - 0s 252ms/step - loss: 0.2977 - binary_accuracy: 0.8715 - auc_1: 0.9474\n",
            "Dataset: 49\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3400 - binary_accuracy: 0.8593 - auc_1: 0.9291\n",
            "Dataset: 50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3621 - binary_accuracy: 0.8430 - auc_1: 0.9195\n",
            "Dataset: 51\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3087 - binary_accuracy: 0.8608 - auc_1: 0.9412\n",
            "Dataset: 52\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3262 - binary_accuracy: 0.8586 - auc_1: 0.9352\n",
            "Dataset: 53\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4727 - binary_accuracy: 0.7855 - auc_1: 0.8698\n",
            "Dataset: 54\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.2248 - binary_accuracy: 0.9075 - auc_1: 0.9691\n",
            "Dataset: 55\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.2783 - binary_accuracy: 0.8762 - auc_1: 0.9523\n",
            "Dataset: 56\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2246 - binary_accuracy: 0.9117 - auc_1: 0.9755\n",
            "Dataset: 57\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3330 - binary_accuracy: 0.8582 - auc_1: 0.9340\n",
            "Dataset: 58\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 0.4231 - binary_accuracy: 0.7982 - auc_1: 0.8866\n",
            "Dataset: 59\n",
            "2/2 [==============================] - 1s 400ms/step - loss: 0.4776 - binary_accuracy: 0.7887 - auc_1: 0.8788\n",
            "Dataset: 60\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3221 - binary_accuracy: 0.8607 - auc_1: 0.9370\n",
            "Dataset: 61\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3831 - binary_accuracy: 0.8336 - auc_1: 0.9139\n",
            "Dataset: 62\n",
            "2/2 [==============================] - 1s 465ms/step - loss: 0.4489 - binary_accuracy: 0.7892 - auc_1: 0.8810\n",
            "Dataset: 63\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4411 - binary_accuracy: 0.7951 - auc_1: 0.8854\n",
            "Dataset: 64\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2771 - binary_accuracy: 0.8844 - auc_1: 0.9544\n",
            "Dataset: 65\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3710 - binary_accuracy: 0.8342 - auc_1: 0.9141\n",
            "Dataset: 66\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2628 - binary_accuracy: 0.8890 - auc_1: 0.9579\n",
            "Dataset: 67\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.3267 - binary_accuracy: 0.8532 - auc_1: 0.9342\n",
            "Dataset: 68\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3397 - binary_accuracy: 0.8545 - auc_1: 0.9283\n",
            "Dataset: 69\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2977 - binary_accuracy: 0.8744 - auc_1: 0.9461\n",
            "Dataset: 70\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3675 - binary_accuracy: 0.8373 - auc_1: 0.9207\n",
            "Dataset: 71\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4423 - binary_accuracy: 0.7981 - auc_1: 0.8877\n",
            "Dataset: 72\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3480 - binary_accuracy: 0.8440 - auc_1: 0.9252\n",
            "Dataset: 73\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.2708 - binary_accuracy: 0.8801 - auc_1: 0.9549\n",
            "Dataset: 74\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.2295 - binary_accuracy: 0.9050 - auc_1: 0.9690\n",
            "Dataset: 75\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2136 - binary_accuracy: 0.9157 - auc_1: 0.9814\n",
            "Dataset: 76\n",
            "2/2 [==============================] - 1s 427ms/step - loss: 0.3953 - binary_accuracy: 0.8214 - auc_1: 0.9042\n",
            "Dataset: 77\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2862 - binary_accuracy: 0.8788 - auc_1: 0.9512\n",
            "Dataset: 78\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.4263 - binary_accuracy: 0.8095 - auc_1: 0.8988\n",
            "Dataset: 79\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.4410 - binary_accuracy: 0.7981 - auc_1: 0.8905\n",
            "Dataset: 80\n",
            "2/2 [==============================] - 1s 331ms/step - loss: 0.2789 - binary_accuracy: 0.8772 - auc_1: 0.9522\n",
            "Dataset: 81\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3466 - binary_accuracy: 0.8436 - auc_1: 0.9270\n",
            "Dataset: 82\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 0.2655 - binary_accuracy: 0.8903 - auc_1: 0.9551\n",
            "Dataset: 83\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3322 - binary_accuracy: 0.8543 - auc_1: 0.9339\n",
            "Dataset: 84\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3332 - binary_accuracy: 0.8535 - auc_1: 0.9316\n",
            "Dataset: 85\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3777 - binary_accuracy: 0.8334 - auc_1: 0.9163\n",
            "Dataset: 86\n",
            "2/2 [==============================] - 1s 943ms/step - loss: 0.2848 - binary_accuracy: 0.8779 - auc_1: 0.9506\n",
            "Dataset: 87\n",
            "2/2 [==============================] - 1s 405ms/step - loss: 0.2754 - binary_accuracy: 0.8856 - auc_1: 0.9534\n",
            "Dataset: 88\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3616 - binary_accuracy: 0.8368 - auc_1: 0.9194\n",
            "Dataset: 89\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2453 - binary_accuracy: 0.8940 - auc_1: 0.9662\n",
            "Dataset: 90\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.3054 - binary_accuracy: 0.8613 - auc_1: 0.9438\n",
            "Dataset: 91\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.2831 - binary_accuracy: 0.8804 - auc_1: 0.9508\n",
            "Dataset: 92\n",
            "2/2 [==============================] - 1s 541ms/step - loss: 0.2402 - binary_accuracy: 0.9026 - auc_1: 0.9721\n",
            "Dataset: 93\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2820 - binary_accuracy: 0.8766 - auc_1: 0.9514\n",
            "Dataset: 94\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.4067 - binary_accuracy: 0.8161 - auc_1: 0.9018\n",
            "Dataset: 95\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3048 - binary_accuracy: 0.8717 - auc_1: 0.9425\n",
            "Dataset: 96\n",
            "2/2 [==============================] - 0s 259ms/step - loss: 0.3497 - binary_accuracy: 0.8461 - auc_1: 0.9273\n",
            "Dataset: 97\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3052 - binary_accuracy: 0.8687 - auc_1: 0.9428\n",
            "Dataset: 98\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3637 - binary_accuracy: 0.8363 - auc_1: 0.9205\n",
            "Dataset: 99\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2627 - binary_accuracy: 0.8839 - auc_1: 0.9584\n",
            "Dataset: 100\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.1997 - binary_accuracy: 0.9141 - auc_1: 0.9803\n",
            "Dataset: 101\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.4765 - binary_accuracy: 0.7771 - auc_1: 0.8695\n",
            "Dataset: 102\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2772 - binary_accuracy: 0.8829 - auc_1: 0.9550\n",
            "Dataset: 103\n",
            "2/2 [==============================] - 0s 186ms/step - loss: 0.3537 - binary_accuracy: 0.8433 - auc_1: 0.9260\n",
            "Dataset: 104\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3526 - binary_accuracy: 0.8492 - auc_1: 0.9239\n",
            "Dataset: 105\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 0.2913 - binary_accuracy: 0.8758 - auc_1: 0.9521\n",
            "Dataset: 106\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.3101 - binary_accuracy: 0.8605 - auc_1: 0.9426\n",
            "Dataset: 107\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.4287 - binary_accuracy: 0.8034 - auc_1: 0.8923\n",
            "Dataset: 108\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3031 - binary_accuracy: 0.8773 - auc_1: 0.9454\n",
            "Dataset: 109\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2545 - binary_accuracy: 0.9022 - auc_1: 0.9645\n",
            "Dataset: 110\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2892 - binary_accuracy: 0.8766 - auc_1: 0.9487\n",
            "Dataset: 111\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.4566 - binary_accuracy: 0.7923 - auc_1: 0.8800\n",
            "Dataset: 112\n",
            "2/2 [==============================] - 1s 549ms/step - loss: 0.2445 - binary_accuracy: 0.8996 - auc_1: 0.9646\n",
            "Dataset: 113\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4626 - binary_accuracy: 0.7920 - auc_1: 0.8938\n",
            "Dataset: 114\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3760 - binary_accuracy: 0.8254 - auc_1: 0.9162\n",
            "Dataset: 115\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3411 - binary_accuracy: 0.8498 - auc_1: 0.9281\n",
            "Dataset: 116\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3490 - binary_accuracy: 0.8488 - auc_1: 0.9259\n",
            "Dataset: 117\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5417 - binary_accuracy: 0.7658 - auc_1: 0.8586\n",
            "Dataset: 118\n",
            "2/2 [==============================] - 1s 297ms/step - loss: 0.3848 - binary_accuracy: 0.8251 - auc_1: 0.9125\n",
            "Dataset: 119\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.4510 - binary_accuracy: 0.7848 - auc_1: 0.8790\n",
            "Dataset: 120\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2653 - binary_accuracy: 0.8850 - auc_1: 0.9571\n",
            "Dataset: 121\n",
            "2/2 [==============================] - 1s 989ms/step - loss: 0.4120 - binary_accuracy: 0.8158 - auc_1: 0.9045\n",
            "Dataset: 122\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3592 - binary_accuracy: 0.8356 - auc_1: 0.9228\n",
            "Dataset: 123\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.3098 - binary_accuracy: 0.8636 - auc_1: 0.9404\n",
            "Dataset: 124\n",
            "1/1 [==============================] - 1s 606ms/step - loss: 0.3116 - binary_accuracy: 0.8599 - auc_1: 0.9408\n",
            "Dataset: 125\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2451 - binary_accuracy: 0.8998 - auc_1: 0.9708\n",
            "Dataset: 126\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3088 - binary_accuracy: 0.8644 - auc_1: 0.9412\n",
            "Dataset: 127\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3180 - binary_accuracy: 0.8675 - auc_1: 0.9412\n",
            "Dataset: 128\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4698 - binary_accuracy: 0.7841 - auc_1: 0.8739\n",
            "Dataset: 129\n",
            "2/2 [==============================] - 0s 272ms/step - loss: 0.3539 - binary_accuracy: 0.8444 - auc_1: 0.9242\n",
            "Dataset: 130\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6375 - binary_accuracy: 0.6967 - auc_1: 0.7946\n",
            "Dataset: 131\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.2593 - binary_accuracy: 0.8940 - auc_1: 0.9603\n",
            "Dataset: 132\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.2784 - binary_accuracy: 0.8730 - auc_1: 0.9533\n",
            "Dataset: 133\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3403 - binary_accuracy: 0.8492 - auc_1: 0.9315\n",
            "Dataset: 134\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.4492 - binary_accuracy: 0.7858 - auc_1: 0.8867\n",
            "Dataset: 135\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.3346 - binary_accuracy: 0.8487 - auc_1: 0.9299\n",
            "Dataset: 136\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3293 - binary_accuracy: 0.8471 - auc_1: 0.9325\n",
            "Dataset: 137\n",
            "2/2 [==============================] - 1s 332ms/step - loss: 0.4532 - binary_accuracy: 0.7852 - auc_1: 0.8790\n",
            "Dataset: 138\n",
            "2/2 [==============================] - 1s 660ms/step - loss: 0.3593 - binary_accuracy: 0.8393 - auc_1: 0.9226\n",
            "Dataset: 139\n",
            "2/2 [==============================] - 1s 865ms/step - loss: 0.3481 - binary_accuracy: 0.8477 - auc_1: 0.9262\n",
            "Dataset: 140\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.4319 - binary_accuracy: 0.8031 - auc_1: 0.8936\n",
            "Dataset: 141\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3188 - binary_accuracy: 0.8675 - auc_1: 0.9385\n",
            "Dataset: 142\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 0.2422 - binary_accuracy: 0.8996 - auc_1: 0.9652\n",
            "Dataset: 143\n",
            "2/2 [==============================] - 1s 746ms/step - loss: 0.3392 - binary_accuracy: 0.8480 - auc_1: 0.9300\n",
            "Dataset: 144\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3239 - binary_accuracy: 0.8579 - auc_1: 0.9363\n",
            "Dataset: 145\n",
            "2/2 [==============================] - 1s 856ms/step - loss: 0.2510 - binary_accuracy: 0.8942 - auc_1: 0.9621\n",
            "Dataset: 146\n",
            "1/1 [==============================] - 1s 629ms/step - loss: 0.5031 - binary_accuracy: 0.7667 - auc_1: 0.8545\n",
            "Dataset: 147\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3860 - binary_accuracy: 0.8280 - auc_1: 0.9155\n",
            "Dataset: 148\n",
            "2/2 [==============================] - 1s 514ms/step - loss: 0.3319 - binary_accuracy: 0.8550 - auc_1: 0.9335\n",
            "Dataset: 149\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5973 - binary_accuracy: 0.7251 - auc_1: 0.8161\n",
            "Dataset: 150\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.2685 - binary_accuracy: 0.8948 - auc_1: 0.9557\n",
            "Dataset: 151\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4441 - binary_accuracy: 0.7962 - auc_1: 0.8805\n",
            "Dataset: 152\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 0.4742 - binary_accuracy: 0.7738 - auc_1: 0.8632\n",
            "Dataset: 153\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3886 - binary_accuracy: 0.8269 - auc_1: 0.9073\n",
            "Dataset: 154\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2207 - binary_accuracy: 0.9162 - auc_1: 0.9766\n",
            "Dataset: 155\n",
            "2/2 [==============================] - 1s 975ms/step - loss: 0.3493 - binary_accuracy: 0.8405 - auc_1: 0.9240\n",
            "Dataset: 156\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3636 - binary_accuracy: 0.8382 - auc_1: 0.9211\n",
            "Dataset: 157\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3095 - binary_accuracy: 0.8605 - auc_1: 0.9405\n",
            "Dataset: 158\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.2795 - binary_accuracy: 0.8820 - auc_1: 0.9520\n",
            "Dataset: 159\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3936 - binary_accuracy: 0.8217 - auc_1: 0.9086\n",
            "Dataset: 160\n",
            "2/2 [==============================] - 1s 643ms/step - loss: 0.3333 - binary_accuracy: 0.8502 - auc_1: 0.9302\n",
            "Dataset: 161\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3001 - binary_accuracy: 0.8694 - auc_1: 0.9444\n",
            "Dataset: 162\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.2387 - binary_accuracy: 0.9009 - auc_1: 0.9681\n",
            "Dataset: 163\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3135 - binary_accuracy: 0.8651 - auc_1: 0.9392\n",
            "Dataset: 164\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2257 - binary_accuracy: 0.9094 - auc_1: 0.9693\n",
            "Dataset: 165\n",
            "2/2 [==============================] - 1s 410ms/step - loss: 0.2576 - binary_accuracy: 0.8929 - auc_1: 0.9623\n",
            "Dataset: 166\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.5533 - binary_accuracy: 0.7586 - auc_1: 0.8597\n",
            "Dataset: 167\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 0.3227 - binary_accuracy: 0.8596 - auc_1: 0.9378\n",
            "Dataset: 168\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.4262 - binary_accuracy: 0.8073 - auc_1: 0.8965\n",
            "Dataset: 169\n",
            "2/2 [==============================] - 1s 819ms/step - loss: 0.3127 - binary_accuracy: 0.8621 - auc_1: 0.9407\n",
            "Dataset: 170\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2941 - binary_accuracy: 0.8670 - auc_1: 0.9466\n",
            "Dataset: 171\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3755 - binary_accuracy: 0.8316 - auc_1: 0.9154\n",
            "Dataset: 172\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3493 - binary_accuracy: 0.8449 - auc_1: 0.9276\n",
            "Dataset: 173\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.5853 - binary_accuracy: 0.7222 - auc_1: 0.8268\n",
            "Dataset: 174\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.2342 - binary_accuracy: 0.8977 - auc_1: 0.9685\n",
            "Dataset: 175\n",
            "2/2 [==============================] - 1s 687ms/step - loss: 0.2703 - binary_accuracy: 0.8844 - auc_1: 0.9555\n",
            "Dataset: 176\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3070 - binary_accuracy: 0.8698 - auc_1: 0.9425\n",
            "Dataset: 177\n",
            "2/2 [==============================] - 1s 690ms/step - loss: 0.3418 - binary_accuracy: 0.8470 - auc_1: 0.9276\n",
            "Dataset: 178\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2464 - binary_accuracy: 0.8968 - auc_1: 0.9643\n",
            "Dataset: 179\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2233 - binary_accuracy: 0.9081 - auc_1: 0.9732\n",
            "Dataset: 180\n",
            "2/2 [==============================] - 1s 756ms/step - loss: 0.3273 - binary_accuracy: 0.8592 - auc_1: 0.9344\n",
            "Dataset: 181\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3239 - binary_accuracy: 0.8593 - auc_1: 0.9379\n",
            "Dataset: 182\n",
            "2/2 [==============================] - 1s 387ms/step - loss: 0.2876 - binary_accuracy: 0.8736 - auc_1: 0.9489\n",
            "Dataset: 183\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3105 - binary_accuracy: 0.8654 - auc_1: 0.9414\n",
            "Dataset: 184\n",
            "2/2 [==============================] - 0s 175ms/step - loss: 0.4471 - binary_accuracy: 0.7970 - auc_1: 0.8794\n",
            "Dataset: 185\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3009 - binary_accuracy: 0.8756 - auc_1: 0.9454\n",
            "Dataset: 186\n",
            "2/2 [==============================] - 1s 383ms/step - loss: 0.3310 - binary_accuracy: 0.8530 - auc_1: 0.9324\n",
            "Dataset: 187\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2510 - binary_accuracy: 0.8949 - auc_1: 0.9630\n",
            "Dataset: 188\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3729 - binary_accuracy: 0.8354 - auc_1: 0.9190\n",
            "Dataset: 189\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2980 - binary_accuracy: 0.8744 - auc_1: 0.9462\n",
            "Dataset: 190\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2403 - binary_accuracy: 0.9008 - auc_1: 0.9660\n",
            "Dataset: 191\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 0.2617 - binary_accuracy: 0.8909 - auc_1: 0.9610\n",
            "Dataset: 192\n",
            "2/2 [==============================] - 1s 568ms/step - loss: 0.3579 - binary_accuracy: 0.8440 - auc_1: 0.9253\n",
            "Dataset: 193\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3280 - binary_accuracy: 0.8551 - auc_1: 0.9345\n",
            "Dataset: 194\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3655 - binary_accuracy: 0.8340 - auc_1: 0.9184\n",
            "Dataset: 195\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.2927 - binary_accuracy: 0.8759 - auc_1: 0.9483\n",
            "Dataset: 196\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3580 - binary_accuracy: 0.8398 - auc_1: 0.9197\n",
            "Dataset: 197\n",
            "1/1 [==============================] - 1s 568ms/step - loss: 0.2083 - binary_accuracy: 0.9151 - auc_1: 0.9761\n",
            "Dataset: 198\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.2181 - binary_accuracy: 0.9130 - auc_1: 0.9764\n",
            "Dataset: 199\n",
            "2/2 [==============================] - 1s 977ms/step - loss: 0.3764 - binary_accuracy: 0.8288 - auc_1: 0.9176\n",
            "Dataset: 200\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.2995 - binary_accuracy: 0.8732 - auc_1: 0.9466\n",
            "Dataset: 201\n",
            "2/2 [==============================] - 1s 829ms/step - loss: 0.4780 - binary_accuracy: 0.7713 - auc_1: 0.8658\n",
            "Dataset: 202\n",
            "1/1 [==============================] - 1s 511ms/step - loss: 0.3176 - binary_accuracy: 0.8650 - auc_1: 0.9388\n",
            "Dataset: 203\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3536 - binary_accuracy: 0.8464 - auc_1: 0.9239\n",
            "Dataset: 204\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4616 - binary_accuracy: 0.7818 - auc_1: 0.8741\n",
            "Dataset: 205\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2526 - binary_accuracy: 0.8933 - auc_1: 0.9632\n",
            "Dataset: 206\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2379 - binary_accuracy: 0.8956 - auc_1: 0.9658\n",
            "Dataset: 207\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3155 - binary_accuracy: 0.8635 - auc_1: 0.9405\n",
            "Dataset: 208\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.4657 - binary_accuracy: 0.7807 - auc_1: 0.8760\n",
            "Dataset: 209\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3837 - binary_accuracy: 0.8253 - auc_1: 0.9149\n",
            "Dataset: 210\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.3881 - binary_accuracy: 0.8306 - auc_1: 0.9113\n",
            "Dataset: 211\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2600 - binary_accuracy: 0.8869 - auc_1: 0.9585\n",
            "Dataset: 212\n",
            "1/1 [==============================] - 1s 520ms/step - loss: 0.2489 - binary_accuracy: 0.9008 - auc_1: 0.9618\n",
            "Dataset: 213\n",
            "2/2 [==============================] - 1s 536ms/step - loss: 0.2688 - binary_accuracy: 0.8831 - auc_1: 0.9556\n",
            "Dataset: 214\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.3330 - binary_accuracy: 0.8574 - auc_1: 0.9327\n",
            "Dataset: 215\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2386 - binary_accuracy: 0.9048 - auc_1: 0.9665\n",
            "Dataset: 216\n",
            "2/2 [==============================] - 1s 324ms/step - loss: 0.3636 - binary_accuracy: 0.8379 - auc_1: 0.9196\n",
            "Dataset: 217\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.5654 - binary_accuracy: 0.7403 - auc_1: 0.8314\n",
            "Dataset: 218\n",
            "1/1 [==============================] - 1s 549ms/step - loss: 0.2991 - binary_accuracy: 0.8703 - auc_1: 0.9441\n",
            "Dataset: 219\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 0.2848 - binary_accuracy: 0.8823 - auc_1: 0.9504\n",
            "Dataset: 220\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2049 - binary_accuracy: 0.9181 - auc_1: 0.9796\n",
            "Dataset: 221\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4713 - binary_accuracy: 0.8012 - auc_1: 0.8855\n",
            "Dataset: 222\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5272 - binary_accuracy: 0.7556 - auc_1: 0.8488\n",
            "Dataset: 223\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4492 - binary_accuracy: 0.7870 - auc_1: 0.8797\n",
            "Dataset: 224\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2411 - binary_accuracy: 0.9004 - auc_1: 0.9671\n",
            "Dataset: 225\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3053 - binary_accuracy: 0.8686 - auc_1: 0.9426\n",
            "Dataset: 226\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.3270 - binary_accuracy: 0.8541 - auc_1: 0.9359\n",
            "Dataset: 227\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 0.4268 - binary_accuracy: 0.8065 - auc_1: 0.8873\n",
            "Dataset: 228\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2596 - binary_accuracy: 0.8934 - auc_1: 0.9587\n",
            "Dataset: 229\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.6832 - binary_accuracy: 0.6561 - auc_1: 0.7471\n",
            "Dataset: 230\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.5209 - binary_accuracy: 0.7565 - auc_1: 0.8399\n",
            "Dataset: 231\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.3465 - binary_accuracy: 0.8381 - auc_1: 0.9256\n",
            "Dataset: 232\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3537 - binary_accuracy: 0.8438 - auc_1: 0.9236\n",
            "Dataset: 233\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5743 - binary_accuracy: 0.7400 - auc_1: 0.8367\n",
            "Dataset: 234\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6079 - binary_accuracy: 0.7056 - auc_1: 0.8026\n",
            "Dataset: 235\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3532 - binary_accuracy: 0.8441 - auc_1: 0.9262\n",
            "Dataset: 236\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2787 - binary_accuracy: 0.8760 - auc_1: 0.9525\n",
            "Dataset: 237\n",
            "2/2 [==============================] - 1s 732ms/step - loss: 0.3694 - binary_accuracy: 0.8396 - auc_1: 0.9197\n",
            "Dataset: 238\n",
            "2/2 [==============================] - 1s 800ms/step - loss: 0.3473 - binary_accuracy: 0.8460 - auc_1: 0.9288\n",
            "Dataset: 239\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2788 - binary_accuracy: 0.8814 - auc_1: 0.9534\n",
            "Dataset: 240\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5152 - binary_accuracy: 0.7595 - auc_1: 0.8591\n",
            "Dataset: 241\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2302 - binary_accuracy: 0.9036 - auc_1: 0.9683\n",
            "Dataset: 242\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3451 - binary_accuracy: 0.8523 - auc_1: 0.9282\n",
            "Dataset: 243\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.2127 - binary_accuracy: 0.9101 - auc_1: 0.9746\n",
            "Dataset: 244\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.2410 - binary_accuracy: 0.9030 - auc_1: 0.9670\n",
            "Dataset: 245\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3367 - binary_accuracy: 0.8457 - auc_1: 0.9321\n",
            "Dataset: 246\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 0.3213 - binary_accuracy: 0.8636 - auc_1: 0.9367\n",
            "Dataset: 247\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3152 - binary_accuracy: 0.8649 - auc_1: 0.9424\n",
            "Dataset: 248\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.5264 - binary_accuracy: 0.7416 - auc_1: 0.8385\n",
            "Dataset: 249\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2272 - binary_accuracy: 0.9049 - auc_1: 0.9691\n",
            "Dataset: 250\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.2325 - binary_accuracy: 0.8985 - auc_1: 0.9675\n",
            "Dataset: 251\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2492 - binary_accuracy: 0.8975 - auc_1: 0.9618\n",
            "Dataset: 252\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4230 - binary_accuracy: 0.8125 - auc_1: 0.9005\n",
            "Dataset: 253\n",
            "2/2 [==============================] - 1s 907ms/step - loss: 0.2903 - binary_accuracy: 0.8750 - auc_1: 0.9486\n",
            "Dataset: 254\n",
            "2/2 [==============================] - 1s 416ms/step - loss: 0.3032 - binary_accuracy: 0.8647 - auc_1: 0.9436\n",
            "Dataset: 255\n",
            "2/2 [==============================] - 1s 934ms/step - loss: 0.3815 - binary_accuracy: 0.8220 - auc_1: 0.9103\n",
            "Dataset: 256\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3648 - binary_accuracy: 0.8348 - auc_1: 0.9218\n",
            "Dataset: 257\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2781 - binary_accuracy: 0.8813 - auc_1: 0.9532\n",
            "Dataset: 258\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.4129 - binary_accuracy: 0.8098 - auc_1: 0.9033\n",
            "Dataset: 259\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3349 - binary_accuracy: 0.8550 - auc_1: 0.9310\n",
            "Dataset: 260\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2446 - binary_accuracy: 0.9032 - auc_1: 0.9633\n",
            "Dataset: 261\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 0.3330 - binary_accuracy: 0.8585 - auc_1: 0.9316\n",
            "Dataset: 262\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6409 - binary_accuracy: 0.7100 - auc_1: 0.8130\n",
            "Dataset: 263\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3474 - binary_accuracy: 0.8438 - auc_1: 0.9265\n",
            "Dataset: 264\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3159 - binary_accuracy: 0.8646 - auc_1: 0.9405\n",
            "Dataset: 265\n",
            "2/2 [==============================] - 1s 778ms/step - loss: 0.4029 - binary_accuracy: 0.8098 - auc_1: 0.9012\n",
            "Dataset: 266\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2674 - binary_accuracy: 0.8892 - auc_1: 0.9576\n",
            "Dataset: 267\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3565 - binary_accuracy: 0.8415 - auc_1: 0.9252\n",
            "Dataset: 268\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3310 - binary_accuracy: 0.8580 - auc_1: 0.9327\n",
            "Dataset: 269\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2939 - binary_accuracy: 0.8780 - auc_1: 0.9481\n",
            "Dataset: 270\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3205 - binary_accuracy: 0.8598 - auc_1: 0.9368\n",
            "Dataset: 271\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.2684 - binary_accuracy: 0.8879 - auc_1: 0.9568\n",
            "Dataset: 272\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2462 - binary_accuracy: 0.8907 - auc_1: 0.9633\n",
            "Dataset: 273\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3504 - binary_accuracy: 0.8506 - auc_1: 0.9265\n",
            "Dataset: 274\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.3222 - binary_accuracy: 0.8623 - auc_1: 0.9359\n",
            "Dataset: 275\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.2222 - binary_accuracy: 0.8993 - auc_1: 0.9746\n",
            "Dataset: 276\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3111 - binary_accuracy: 0.8592 - auc_1: 0.9390\n",
            "Dataset: 277\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2904 - binary_accuracy: 0.8758 - auc_1: 0.9483\n",
            "Dataset: 278\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3542 - binary_accuracy: 0.8409 - auc_1: 0.9230\n",
            "Dataset: 279\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.4399 - binary_accuracy: 0.8014 - auc_1: 0.8890\n",
            "Dataset: 280\n",
            "2/2 [==============================] - 1s 460ms/step - loss: 0.2749 - binary_accuracy: 0.8809 - auc_1: 0.9548\n",
            "Dataset: 281\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.2222 - binary_accuracy: 0.9046 - auc_1: 0.9712\n",
            "Dataset: 282\n",
            "2/2 [==============================] - 1s 676ms/step - loss: 0.3650 - binary_accuracy: 0.8384 - auc_1: 0.9178\n",
            "Dataset: 283\n",
            "2/2 [==============================] - 1s 949ms/step - loss: 0.2660 - binary_accuracy: 0.8907 - auc_1: 0.9582\n",
            "Dataset: 284\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3171 - binary_accuracy: 0.8582 - auc_1: 0.9390\n",
            "Dataset: 285\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3094 - binary_accuracy: 0.8677 - auc_1: 0.9408\n",
            "Dataset: 286\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.2999 - binary_accuracy: 0.8637 - auc_1: 0.9448\n",
            "Dataset: 287\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3340 - binary_accuracy: 0.8522 - auc_1: 0.9336\n",
            "Dataset: 288\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.2929 - binary_accuracy: 0.8770 - auc_1: 0.9468\n",
            "Dataset: 289\n",
            "1/1 [==============================] - 1s 607ms/step - loss: 0.4068 - binary_accuracy: 0.8251 - auc_1: 0.9020\n",
            "Dataset: 290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2959 - binary_accuracy: 0.8686 - auc_1: 0.9455\n",
            "Dataset: 291\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.4794 - binary_accuracy: 0.7732 - auc_1: 0.8754\n",
            "Dataset: 292\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.5632 - binary_accuracy: 0.7441 - auc_1: 0.8511\n",
            "Dataset: 293\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.2530 - binary_accuracy: 0.8939 - auc_1: 0.9610\n",
            "Dataset: 294\n",
            "1/1 [==============================] - 1s 581ms/step - loss: 0.5618 - binary_accuracy: 0.7271 - auc_1: 0.8266\n",
            "Dataset: 295\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3199 - binary_accuracy: 0.8529 - auc_1: 0.9373\n",
            "Dataset: 296\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4060 - binary_accuracy: 0.8201 - auc_1: 0.9003\n",
            "Dataset: 297\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3361 - binary_accuracy: 0.8605 - auc_1: 0.9306\n",
            "Dataset: 298\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2977 - binary_accuracy: 0.8711 - auc_1: 0.9456\n",
            "Dataset: 299\n",
            "2/2 [==============================] - 1s 389ms/step - loss: 0.3243 - binary_accuracy: 0.8617 - auc_1: 0.9369\n",
            "Dataset: 300\n",
            "2/2 [==============================] - 1s 792ms/step - loss: 0.5350 - binary_accuracy: 0.7478 - auc_1: 0.8423\n",
            "Dataset: 301\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.2775 - binary_accuracy: 0.8824 - auc_1: 0.9519\n",
            "Dataset: 302\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2570 - binary_accuracy: 0.8837 - auc_1: 0.9604\n",
            "Dataset: 303\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3692 - binary_accuracy: 0.8352 - auc_1: 0.9158\n",
            "Dataset: 304\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3363 - binary_accuracy: 0.8553 - auc_1: 0.9307\n",
            "Dataset: 305\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3679 - binary_accuracy: 0.8337 - auc_1: 0.9215\n",
            "Dataset: 306\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.2677 - binary_accuracy: 0.8921 - auc_1: 0.9574\n",
            "Dataset: 307\n",
            "2/2 [==============================] - 1s 396ms/step - loss: 0.2274 - binary_accuracy: 0.9153 - auc_1: 0.9717\n",
            "Dataset: 308\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3600 - binary_accuracy: 0.8354 - auc_1: 0.9235\n",
            "Dataset: 309\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.3019 - binary_accuracy: 0.8650 - auc_1: 0.9443\n",
            "Dataset: 310\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.6679 - binary_accuracy: 0.6828 - auc_1: 0.7788\n",
            "Dataset: 311\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.3351 - binary_accuracy: 0.8546 - auc_1: 0.9317\n",
            "Dataset: 312\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.2932 - binary_accuracy: 0.8786 - auc_1: 0.9489\n",
            "Dataset: 313\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3440 - binary_accuracy: 0.8456 - auc_1: 0.9295\n",
            "Dataset: 314\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3416 - binary_accuracy: 0.8499 - auc_1: 0.9298\n",
            "Dataset: 315\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4165 - binary_accuracy: 0.8105 - auc_1: 0.9001\n",
            "Dataset: 316\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 0.4287 - binary_accuracy: 0.8047 - auc_1: 0.8954\n",
            "Dataset: 317\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2972 - binary_accuracy: 0.8752 - auc_1: 0.9457\n",
            "Dataset: 318\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4646 - binary_accuracy: 0.7807 - auc_1: 0.8703\n",
            "Dataset: 319\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3137 - binary_accuracy: 0.8622 - auc_1: 0.9395\n",
            "Dataset: 320\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.5163 - binary_accuracy: 0.7621 - auc_1: 0.8704\n",
            "Dataset: 321\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.5773 - binary_accuracy: 0.7375 - auc_1: 0.8389\n",
            "Dataset: 322\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4668 - binary_accuracy: 0.7826 - auc_1: 0.8723\n",
            "Dataset: 323\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.2977 - binary_accuracy: 0.8677 - auc_1: 0.9460\n",
            "Dataset: 324\n",
            "2/2 [==============================] - 1s 569ms/step - loss: 0.3191 - binary_accuracy: 0.8654 - auc_1: 0.9379\n",
            "Dataset: 325\n",
            "2/2 [==============================] - 1s 376ms/step - loss: 0.2728 - binary_accuracy: 0.8888 - auc_1: 0.9546\n",
            "Dataset: 326\n",
            "2/2 [==============================] - 0s 189ms/step - loss: 0.3674 - binary_accuracy: 0.8351 - auc_1: 0.9202\n",
            "Dataset: 327\n",
            "2/2 [==============================] - 0s 220ms/step - loss: 0.2867 - binary_accuracy: 0.8798 - auc_1: 0.9498\n",
            "Dataset: 328\n",
            "2/2 [==============================] - 1s 767ms/step - loss: 0.4791 - binary_accuracy: 0.7825 - auc_1: 0.8818\n",
            "Dataset: 329\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2682 - binary_accuracy: 0.8801 - auc_1: 0.9575\n",
            "Dataset: 330\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.3278 - binary_accuracy: 0.8564 - auc_1: 0.9348\n",
            "Dataset: 331\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3423 - binary_accuracy: 0.8496 - auc_1: 0.9275\n",
            "Dataset: 332\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3906 - binary_accuracy: 0.8252 - auc_1: 0.9075\n",
            "Dataset: 333\n",
            "2/2 [==============================] - 1s 561ms/step - loss: 0.3051 - binary_accuracy: 0.8674 - auc_1: 0.9432\n",
            "Dataset: 334\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3569 - binary_accuracy: 0.8450 - auc_1: 0.9219\n",
            "Dataset: 335\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3443 - binary_accuracy: 0.8448 - auc_1: 0.9270\n",
            "Dataset: 336\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4076 - binary_accuracy: 0.8164 - auc_1: 0.9019\n",
            "Dataset: 337\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.2265 - binary_accuracy: 0.9150 - auc_1: 0.9744\n",
            "Dataset: 338\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 0.3034 - binary_accuracy: 0.8819 - auc_1: 0.9439\n",
            "Dataset: 339\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2850 - binary_accuracy: 0.8808 - auc_1: 0.9534\n",
            "Dataset: 340\n",
            "2/2 [==============================] - 1s 947ms/step - loss: 0.3287 - binary_accuracy: 0.8472 - auc_1: 0.9333\n",
            "Dataset: 341\n",
            "2/2 [==============================] - 1s 542ms/step - loss: 0.2945 - binary_accuracy: 0.8726 - auc_1: 0.9464\n",
            "Dataset: 342\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3689 - binary_accuracy: 0.8335 - auc_1: 0.9181\n",
            "Dataset: 343\n",
            "2/2 [==============================] - 1s 909ms/step - loss: 0.3301 - binary_accuracy: 0.8527 - auc_1: 0.9348\n",
            "Dataset: 344\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2215 - binary_accuracy: 0.9031 - auc_1: 0.9720\n",
            "Dataset: 345\n",
            "2/2 [==============================] - 1s 407ms/step - loss: 0.2753 - binary_accuracy: 0.8799 - auc_1: 0.9540\n",
            "Dataset: 346\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3619 - binary_accuracy: 0.8397 - auc_1: 0.9193\n",
            "Dataset: 347\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.4472 - binary_accuracy: 0.7880 - auc_1: 0.8772\n",
            "Dataset: 348\n",
            "2/2 [==============================] - 1s 441ms/step - loss: 0.3773 - binary_accuracy: 0.8301 - auc_1: 0.9116\n",
            "Dataset: 349\n",
            "1/1 [==============================] - 1s 627ms/step - loss: 0.4571 - binary_accuracy: 0.7838 - auc_1: 0.8752\n",
            "Dataset: 350\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3046 - binary_accuracy: 0.8693 - auc_1: 0.9427\n",
            "Dataset: 351\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.3148 - binary_accuracy: 0.8662 - auc_1: 0.9398\n",
            "Dataset: 352\n",
            "2/2 [==============================] - 1s 481ms/step - loss: 0.3410 - binary_accuracy: 0.8533 - auc_1: 0.9309\n",
            "Dataset: 353\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2726 - binary_accuracy: 0.8768 - auc_1: 0.9535\n",
            "Dataset: 354\n",
            "1/1 [==============================] - 1s 619ms/step - loss: 0.2219 - binary_accuracy: 0.9104 - auc_1: 0.9750\n",
            "Dataset: 355\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5068 - binary_accuracy: 0.7655 - auc_1: 0.8479\n",
            "Dataset: 356\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.4906 - binary_accuracy: 0.7768 - auc_1: 0.8732\n",
            "Dataset: 357\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3141 - binary_accuracy: 0.8620 - auc_1: 0.9389\n",
            "Dataset: 358\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3002 - binary_accuracy: 0.8663 - auc_1: 0.9446\n",
            "Dataset: 359\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2648 - binary_accuracy: 0.8969 - auc_1: 0.9596\n",
            "Dataset: 360\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.2055 - binary_accuracy: 0.9168 - auc_1: 0.9784\n",
            "Dataset: 361\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2088 - binary_accuracy: 0.9103 - auc_1: 0.9758\n",
            "Dataset: 362\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.2515 - binary_accuracy: 0.9041 - auc_1: 0.9612\n",
            "Dataset: 363\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.4558 - binary_accuracy: 0.7803 - auc_1: 0.8780\n",
            "Dataset: 364\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 0.3192 - binary_accuracy: 0.8546 - auc_1: 0.9363\n",
            "Dataset: 365\n",
            "1/1 [==============================] - 1s 539ms/step - loss: 0.3591 - binary_accuracy: 0.8580 - auc_1: 0.9220\n",
            "Dataset: 366\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2893 - binary_accuracy: 0.8725 - auc_1: 0.9486\n",
            "Dataset: 367\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3206 - binary_accuracy: 0.8643 - auc_1: 0.9376\n",
            "Dataset: 368\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3342 - binary_accuracy: 0.8552 - auc_1: 0.9302\n",
            "Dataset: 369\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.4243 - binary_accuracy: 0.8066 - auc_1: 0.8972\n",
            "Dataset: 370\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.2420 - binary_accuracy: 0.9043 - auc_1: 0.9661\n",
            "Dataset: 371\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2425 - binary_accuracy: 0.8994 - auc_1: 0.9662\n",
            "Dataset: 372\n",
            "2/2 [==============================] - 1s 470ms/step - loss: 0.3928 - binary_accuracy: 0.8203 - auc_1: 0.9094\n",
            "Dataset: 373\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3197 - binary_accuracy: 0.8557 - auc_1: 0.9366\n",
            "Dataset: 374\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3926 - binary_accuracy: 0.8235 - auc_1: 0.9110\n",
            "Dataset: 375\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.3143 - binary_accuracy: 0.8663 - auc_1: 0.9434\n",
            "Dataset: 376\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3377 - binary_accuracy: 0.8537 - auc_1: 0.9284\n",
            "Dataset: 377\n",
            "2/2 [==============================] - 1s 507ms/step - loss: 0.2288 - binary_accuracy: 0.9051 - auc_1: 0.9692\n",
            "Dataset: 378\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 0.2373 - binary_accuracy: 0.9043 - auc_1: 0.9697\n",
            "Dataset: 379\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2592 - binary_accuracy: 0.8884 - auc_1: 0.9595\n",
            "Dataset: 380\n",
            "1/1 [==============================] - 1s 504ms/step - loss: 0.2799 - binary_accuracy: 0.8899 - auc_1: 0.9553\n",
            "Dataset: 381\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.2922 - binary_accuracy: 0.8756 - auc_1: 0.9479\n",
            "Dataset: 382\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3044 - binary_accuracy: 0.8671 - auc_1: 0.9426\n",
            "Dataset: 383\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2815 - binary_accuracy: 0.8812 - auc_1: 0.9520\n",
            "Dataset: 384\n",
            "2/2 [==============================] - 1s 551ms/step - loss: 0.3570 - binary_accuracy: 0.8393 - auc_1: 0.9238\n",
            "Dataset: 385\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.3284 - binary_accuracy: 0.8576 - auc_1: 0.9323\n",
            "Dataset: 386\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2333 - binary_accuracy: 0.9104 - auc_1: 0.9714\n",
            "Dataset: 387\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.2546 - binary_accuracy: 0.8945 - auc_1: 0.9613\n",
            "Dataset: 388\n",
            "2/2 [==============================] - 1s 1s/step - loss: 0.4240 - binary_accuracy: 0.8065 - auc_1: 0.8958\n",
            "Dataset: 389\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2015 - binary_accuracy: 0.9181 - auc_1: 0.9785\n",
            "0.9276073844696379\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for test_feature,test_label in zip(test_features,test_labels):\n",
        "  i=i+1\n",
        "  print(\"Dataset:\",i)\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1,batch_size=4096)\n",
        "  avg_acc.append(data[2])\n",
        "print(np.mean(avg_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning"
      ],
      "metadata": {
        "id": "hvyeuCc3zTw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pre fine-tuning\n",
        "CBLANE.evaluate(medium_test_features,medium_test_labels,batch_size=4096)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61fdc9c-d754-4bb9-f979-eaa9a057393a",
        "id": "SxjghBJI9FfQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "359/359 [==============================] - 72s 195ms/step - loss: 0.3401 - binary_accuracy: 0.8500 - auc_1: 0.9290\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3400660753250122, 0.8500096797943115, 0.9290493726730347]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f645849-edd6-4cdc-d6ec-b784f92a5a05",
        "id": "J3Hd3mB0eygm"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "   6/5146 [..............................] - ETA: 13:15 - loss: 0.4291 - binary_accuracy: 0.7987 - auc: 0.8830"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0646s vs `on_train_batch_end` time: 0.0742s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5146/5146 [==============================] - 909s 173ms/step - loss: 0.3819 - binary_accuracy: 0.8255 - auc: 0.9080 - val_loss: 0.3548 - val_binary_accuracy: 0.8404 - val_auc: 0.9210 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "5146/5146 [==============================] - 886s 172ms/step - loss: 0.3671 - binary_accuracy: 0.8335 - auc: 0.9154 - val_loss: 0.3475 - val_binary_accuracy: 0.8439 - val_auc: 0.9245 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "5146/5146 [==============================] - 876s 170ms/step - loss: 0.3589 - binary_accuracy: 0.8380 - auc: 0.9194 - val_loss: 0.3431 - val_binary_accuracy: 0.8464 - val_auc: 0.9271 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "5146/5146 [==============================] - 888s 173ms/step - loss: 0.3525 - binary_accuracy: 0.8414 - auc: 0.9224 - val_loss: 0.3371 - val_binary_accuracy: 0.8497 - val_auc: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "5146/5146 [==============================] - 886s 172ms/step - loss: 0.3473 - binary_accuracy: 0.8446 - auc: 0.9249 - val_loss: 0.3337 - val_binary_accuracy: 0.8515 - val_auc: 0.9307 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "5146/5146 [==============================] - 883s 172ms/step - loss: 0.3427 - binary_accuracy: 0.8471 - auc: 0.9269 - val_loss: 0.3316 - val_binary_accuracy: 0.8525 - val_auc: 0.9318 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "5146/5146 [==============================] - 886s 172ms/step - loss: 0.3387 - binary_accuracy: 0.8493 - auc: 0.9287 - val_loss: 0.3291 - val_binary_accuracy: 0.8539 - val_auc: 0.9331 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "5146/5146 [==============================] - 885s 172ms/step - loss: 0.3351 - binary_accuracy: 0.8511 - auc: 0.9303 - val_loss: 0.3270 - val_binary_accuracy: 0.8553 - val_auc: 0.9337 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "5146/5146 [==============================] - 890s 173ms/step - loss: 0.3317 - binary_accuracy: 0.8530 - auc: 0.9318 - val_loss: 0.3244 - val_binary_accuracy: 0.8569 - val_auc: 0.9348 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "5146/5146 [==============================] - 881s 171ms/step - loss: 0.3288 - binary_accuracy: 0.8547 - auc: 0.9330 - val_loss: 0.3219 - val_binary_accuracy: 0.8585 - val_auc: 0.9358 - lr: 1.0000e-04\n",
            "Epoch 11/30\n",
            "5146/5146 [==============================] - 868s 169ms/step - loss: 0.3260 - binary_accuracy: 0.8561 - auc: 0.9342 - val_loss: 0.3219 - val_binary_accuracy: 0.8581 - val_auc: 0.9361 - lr: 1.0000e-04\n",
            "Epoch 12/30\n",
            "5146/5146 [==============================] - 879s 171ms/step - loss: 0.3193 - binary_accuracy: 0.8598 - auc: 0.9369 - val_loss: 0.3193 - val_binary_accuracy: 0.8598 - val_auc: 0.9369 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "4850/5146 [===========================>..] - ETA: 48s - loss: 0.3182 - binary_accuracy: 0.8604 - auc: 0.9374"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "CBLANE = load_model(\"CBLANE.keras\")\n",
        "CBLANE.compile(loss='binary_crossentropy',\n",
        "                             optimizer=Adam(learning_rate=0.0001),\n",
        "                             metrics=[BinaryAccuracy(),\n",
        "                                      # Precision(),\n",
        "                                      # Recall(),\n",
        "                                      AUC(),\n",
        "                                      # SensitivityAtSpecificity(0.5),\n",
        "                                      # SpecificityAtSensitivity(0.5),\n",
        "                                      ]\n",
        "                             )\n",
        "history = CBLANE.fit(tf.constant(medium_train_features,dtype=tf.bool),\n",
        "                             tf.constant(medium_train_labels,dtype=tf.bool),\n",
        "                             batch_size=1024,\n",
        "                             epochs=30,\n",
        "                             verbose=1,\n",
        "                             validation_split=0.1,\n",
        "                             validation_batch_size=4096,\n",
        "                             callbacks=([reduce_lr,\n",
        "                                         SaveSubModels()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Fine-Tuning"
      ],
      "metadata": {
        "id": "BC2UGUhourg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  if i%10==0:\n",
        "    with open('acc.pkl', 'wb') as file:\n",
        "      pickle.dump(avg_acc, file)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scMuEz_r90hf",
        "outputId": "82886386-e731-46e0-f7ad-d085bb5a14a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 1\n",
            "187/187 [==============================] - 5s 13ms/step - loss: 0.3335 - binary_accuracy: 0.8556 - auc: 0.9312\n",
            "Dataset: 2\n",
            "205/205 [==============================] - 5s 13ms/step - loss: 0.3560 - binary_accuracy: 0.8385 - auc_1: 0.9212\n",
            "Dataset: 3\n",
            "173/173 [==============================] - 4s 12ms/step - loss: 0.2800 - binary_accuracy: 0.8806 - auc_2: 0.9550\n",
            "Dataset: 4\n",
            "94/94 [==============================] - 2s 10ms/step - loss: 0.1806 - binary_accuracy: 0.9285 - auc_3: 0.9866\n",
            "Dataset: 5\n",
            "69/69 [==============================] - 2s 8ms/step - loss: 0.2634 - binary_accuracy: 0.8885 - auc_4: 0.9573\n",
            "Dataset: 6\n",
            "191/191 [==============================] - 4s 13ms/step - loss: 0.3010 - binary_accuracy: 0.8714 - auc_5: 0.9442\n",
            "Dataset: 7\n",
            "95/95 [==============================] - 2s 10ms/step - loss: 0.3547 - binary_accuracy: 0.8459 - auc_6: 0.9217\n",
            "Dataset: 8\n",
            "233/233 [==============================] - 3s 9ms/step - loss: 0.3708 - binary_accuracy: 0.8338 - auc_7: 0.9148\n",
            "Dataset: 9\n",
            "82/82 [==============================] - 2s 7ms/step - loss: 0.4674 - binary_accuracy: 0.7774 - auc_8: 0.8716\n",
            "Dataset: 10\n",
            "59/59 [==============================] - 2s 11ms/step - loss: 0.2161 - binary_accuracy: 0.9057 - auc_9: 0.9715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a6256d-7ed6-4c0e-bd99-c1bfc606c084",
        "id": "UbQg4x8gGqfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9312074780464172\n",
            "0.921187162399292\n",
            "0.9549838900566101\n",
            "0.9865534901618958\n",
            "0.9573073387145996\n",
            "0.9442133903503418\n",
            "0.9217252731323242\n",
            "0.9148148894309998\n",
            "0.8716135621070862\n",
            "0.9714758992195129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=10:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  if i%10==0:\n",
        "    with open('acc.pkl', 'wb') as file:\n",
        "      pickle.dump(avg_acc, file)\n",
        "    gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95bde93-bff6-4c0c-c8ea-3acec6b1c948",
        "id": "G0ICVWKYGk4w"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 11\n",
            "181/181 [==============================] - 3s 8ms/step - loss: 0.3374 - binary_accuracy: 0.8502 - auc: 0.9307\n",
            "Dataset: 12\n",
            "55/55 [==============================] - 3s 12ms/step - loss: 0.3401 - binary_accuracy: 0.8513 - auc_1: 0.9297\n",
            "Dataset: 13\n",
            "150/150 [==============================] - 4s 12ms/step - loss: 0.2815 - binary_accuracy: 0.8810 - auc_2: 0.9517\n",
            "Dataset: 14\n",
            "66/66 [==============================] - 2s 11ms/step - loss: 0.4335 - binary_accuracy: 0.8049 - auc_3: 0.8943\n",
            "Dataset: 15\n",
            "223/223 [==============================] - 4s 9ms/step - loss: 0.2414 - binary_accuracy: 0.9057 - auc_4: 0.9662\n",
            "Dataset: 16\n",
            "59/59 [==============================] - 2s 8ms/step - loss: 0.3727 - binary_accuracy: 0.8433 - auc_5: 0.9212\n",
            "Dataset: 17\n",
            "172/172 [==============================] - 4s 9ms/step - loss: 0.2907 - binary_accuracy: 0.8777 - auc_6: 0.9484\n",
            "Dataset: 18\n",
            "168/168 [==============================] - 3s 9ms/step - loss: 0.3495 - binary_accuracy: 0.8473 - auc_7: 0.9275\n",
            "Dataset: 19\n",
            "43/43 [==============================] - 2s 13ms/step - loss: 0.3097 - binary_accuracy: 0.8736 - auc_8: 0.9428\n",
            "Dataset: 20\n",
            "142/142 [==============================] - 2s 8ms/step - loss: 0.2499 - binary_accuracy: 0.8971 - auc_9: 0.9612\n",
            "Dataset: 21\n",
            "232/232 [==============================] - 4s 9ms/step - loss: 0.3149 - binary_accuracy: 0.8627 - auc_10: 0.9393\n",
            "Dataset: 22\n",
            "74/74 [==============================] - 2s 8ms/step - loss: 0.3875 - binary_accuracy: 0.8311 - auc_11: 0.9079\n",
            "Dataset: 23\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.3447 - binary_accuracy: 0.8467 - auc_12: 0.9322\n",
            "Dataset: 24\n",
            "168/168 [==============================] - 3s 8ms/step - loss: 0.3407 - binary_accuracy: 0.8526 - auc_13: 0.9284\n",
            "Dataset: 25\n",
            "172/172 [==============================] - 4s 12ms/step - loss: 0.2854 - binary_accuracy: 0.8766 - auc_14: 0.9503\n",
            "Dataset: 26\n",
            "75/75 [==============================] - 2s 10ms/step - loss: 0.2641 - binary_accuracy: 0.8930 - auc_15: 0.9574\n",
            "Dataset: 27\n",
            "30/30 [==============================] - 2s 16ms/step - loss: 0.2586 - binary_accuracy: 0.8956 - auc_16: 0.9591\n",
            "Dataset: 28\n",
            "151/151 [==============================] - 2s 7ms/step - loss: 0.2415 - binary_accuracy: 0.9058 - auc_17: 0.9674\n",
            "Dataset: 29\n",
            "64/64 [==============================] - 2s 10ms/step - loss: 0.2445 - binary_accuracy: 0.9019 - auc_18: 0.9632\n",
            "Dataset: 30\n",
            "66/66 [==============================] - 2s 10ms/step - loss: 0.5086 - binary_accuracy: 0.7609 - auc_19: 0.8601\n",
            "Dataset: 31\n",
            "204/204 [==============================] - 4s 11ms/step - loss: 0.3855 - binary_accuracy: 0.8242 - auc_20: 0.9087\n",
            "Dataset: 32\n",
            "86/86 [==============================] - 2s 10ms/step - loss: 0.5550 - binary_accuracy: 0.7396 - auc_21: 0.8310\n",
            "Dataset: 33\n",
            "159/159 [==============================] - 2s 7ms/step - loss: 0.4079 - binary_accuracy: 0.8103 - auc_22: 0.8967\n",
            "Dataset: 34\n",
            "116/116 [==============================] - 3s 10ms/step - loss: 0.2939 - binary_accuracy: 0.8736 - auc_23: 0.9486\n",
            "Dataset: 35\n",
            "60/60 [==============================] - 2s 11ms/step - loss: 0.3023 - binary_accuracy: 0.8688 - auc_24: 0.9441\n",
            "Dataset: 36\n",
            "197/197 [==============================] - 3s 7ms/step - loss: 0.3464 - binary_accuracy: 0.8456 - auc_25: 0.9290\n",
            "Dataset: 37\n",
            "89/89 [==============================] - 3s 10ms/step - loss: 0.3977 - binary_accuracy: 0.8172 - auc_26: 0.9026\n",
            "Dataset: 38\n",
            "152/152 [==============================] - 3s 11ms/step - loss: 0.3180 - binary_accuracy: 0.8605 - auc_27: 0.9389\n",
            "Dataset: 39\n",
            "34/34 [==============================] - 2s 8ms/step - loss: 0.5534 - binary_accuracy: 0.7477 - auc_28: 0.8458\n",
            "Dataset: 40\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.4439 - binary_accuracy: 0.7923 - auc_29: 0.8819\n",
            "Dataset: 41\n",
            "66/66 [==============================] - 2s 8ms/step - loss: 0.4062 - binary_accuracy: 0.8114 - auc_30: 0.9004\n",
            "Dataset: 42\n",
            "83/83 [==============================] - 2s 8ms/step - loss: 0.2817 - binary_accuracy: 0.8841 - auc_31: 0.9512\n",
            "Dataset: 43\n",
            "95/95 [==============================] - 2s 7ms/step - loss: 0.3618 - binary_accuracy: 0.8388 - auc_32: 0.9201\n",
            "Dataset: 44\n",
            "58/58 [==============================] - 2s 7ms/step - loss: 0.2821 - binary_accuracy: 0.8781 - auc_33: 0.9510\n",
            "Dataset: 45\n",
            "36/36 [==============================] - 2s 11ms/step - loss: 0.2677 - binary_accuracy: 0.8928 - auc_34: 0.9558\n",
            "Dataset: 46\n",
            "37/37 [==============================] - 2s 8ms/step - loss: 0.2354 - binary_accuracy: 0.8992 - auc_35: 0.9653\n",
            "Dataset: 47\n",
            "27/27 [==============================] - 1s 8ms/step - loss: 0.5056 - binary_accuracy: 0.7465 - auc_36: 0.8547\n",
            "Dataset: 48\n",
            "136/136 [==============================] - 3s 12ms/step - loss: 0.2780 - binary_accuracy: 0.8777 - auc_37: 0.9525\n",
            "Dataset: 49\n",
            "236/236 [==============================] - 3s 8ms/step - loss: 0.3149 - binary_accuracy: 0.8682 - auc_38: 0.9398\n",
            "Dataset: 50\n",
            "91/91 [==============================] - 2s 10ms/step - loss: 0.3572 - binary_accuracy: 0.8444 - auc_39: 0.9211\n",
            "Dataset: 51\n",
            "41/41 [==============================] - 2s 8ms/step - loss: 0.3037 - binary_accuracy: 0.8655 - auc_40: 0.9435\n",
            "Dataset: 52\n",
            "216/216 [==============================] - 3s 7ms/step - loss: 0.3137 - binary_accuracy: 0.8653 - auc_41: 0.9406\n",
            "Dataset: 53\n",
            "107/107 [==============================] - 3s 8ms/step - loss: 0.4615 - binary_accuracy: 0.7881 - auc_42: 0.8709\n",
            "Dataset: 54\n",
            "55/55 [==============================] - 2s 11ms/step - loss: 0.2096 - binary_accuracy: 0.9132 - auc_43: 0.9729\n",
            "Dataset: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs8eYfkTUmP6",
        "outputId": "bd553fa7-ead8-41e5-b7bc-31c4bac43234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9306551814079285\n",
            "0.9296557307243347\n",
            "0.9516918063163757\n",
            "0.894320011138916\n",
            "0.9662401080131531\n",
            "0.9212194085121155\n",
            "0.9484221339225769\n",
            "0.9274718761444092\n",
            "0.9428207874298096\n",
            "0.961245059967041\n",
            "0.9393441677093506\n",
            "0.907924234867096\n",
            "0.9321599006652832\n",
            "0.928375244140625\n",
            "0.9502923488616943\n",
            "0.9573821425437927\n",
            "0.9591288566589355\n",
            "0.9674414992332458\n",
            "0.9632229208946228\n",
            "0.8600559830665588\n",
            "0.9087160229682922\n",
            "0.8309941291809082\n",
            "0.8967456221580505\n",
            "0.9485831260681152\n",
            "0.9441002607345581\n",
            "0.9290468096733093\n",
            "0.9025838971138\n",
            "0.9389432072639465\n",
            "0.8458400368690491\n",
            "0.8819204568862915\n",
            "0.9003790020942688\n",
            "0.9512417316436768\n",
            "0.9200512766838074\n",
            "0.9509711861610413\n",
            "0.9557961821556091\n",
            "0.9653223752975464\n",
            "0.8547034859657288\n",
            "0.9525251984596252\n",
            "0.9397828578948975\n",
            "0.9211435317993164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=50:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  if i%10==0:\n",
        "    with open('acc.pkl', 'wb') as file:\n",
        "      pickle.dump(avg_acc, file)\n",
        "    gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c3e88d-7ecd-4ad7-aa4a-622dbd8bcd3f",
        "id": "q69p7V0TUx50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 51\n",
            "41/41 [==============================] - 2s 13ms/step - loss: 0.3035 - binary_accuracy: 0.8631 - auc: 0.9434\n",
            "Dataset: 52\n",
            "216/216 [==============================] - 3s 8ms/step - loss: 0.3144 - binary_accuracy: 0.8666 - auc_1: 0.9407\n",
            "Dataset: 53\n",
            "107/107 [==============================] - 3s 10ms/step - loss: 0.4609 - binary_accuracy: 0.7884 - auc_2: 0.8709\n",
            "Dataset: 54\n",
            "55/55 [==============================] - 2s 8ms/step - loss: 0.2094 - binary_accuracy: 0.9138 - auc_3: 0.9731\n",
            "Dataset: 55\n",
            "54/54 [==============================] - 2s 13ms/step - loss: 0.2771 - binary_accuracy: 0.8820 - auc_4: 0.9533\n",
            "Dataset: 56\n",
            "126/126 [==============================] - 2s 9ms/step - loss: 0.2121 - binary_accuracy: 0.9181 - auc_5: 0.9792\n",
            "Dataset: 57\n",
            "215/215 [==============================] - 3s 8ms/step - loss: 0.3380 - binary_accuracy: 0.8500 - auc_6: 0.9304\n",
            "Dataset: 58\n",
            "31/31 [==============================] - 2s 11ms/step - loss: 0.4193 - binary_accuracy: 0.8002 - auc_7: 0.8873\n",
            "Dataset: 59\n",
            "147/147 [==============================] - 3s 9ms/step - loss: 0.4477 - binary_accuracy: 0.7943 - auc_8: 0.8799\n",
            "Dataset: 60\n",
            "109/109 [==============================] - 3s 12ms/step - loss: 0.3136 - binary_accuracy: 0.8691 - auc_9: 0.9405\n",
            "Dataset: 61\n",
            "60/60 [==============================] - 2s 11ms/step - loss: 0.3772 - binary_accuracy: 0.8357 - auc_10: 0.9152\n",
            "Dataset: 62\n",
            "149/149 [==============================] - 3s 9ms/step - loss: 0.4332 - binary_accuracy: 0.7966 - auc_11: 0.8851\n",
            "Dataset: 63\n",
            "115/115 [==============================] - 3s 12ms/step - loss: 0.4230 - binary_accuracy: 0.8006 - auc_12: 0.8894\n",
            "Dataset: 64\n",
            "85/85 [==============================] - 2s 11ms/step - loss: 0.2602 - binary_accuracy: 0.8958 - auc_13: 0.9585\n",
            "Dataset: 65\n",
            "197/197 [==============================] - 3s 9ms/step - loss: 0.3567 - binary_accuracy: 0.8398 - auc_14: 0.9202\n",
            "Dataset: 66\n",
            "123/123 [==============================] - 3s 10ms/step - loss: 0.2567 - binary_accuracy: 0.8938 - auc_15: 0.9597\n",
            "Dataset: 67\n",
            "53/53 [==============================] - 2s 8ms/step - loss: 0.3184 - binary_accuracy: 0.8603 - auc_16: 0.9373\n",
            "Dataset: 68\n",
            "215/215 [==============================] - 3s 10ms/step - loss: 0.3315 - binary_accuracy: 0.8554 - auc_17: 0.9326\n",
            "Dataset: 69\n",
            "119/119 [==============================] - 3s 12ms/step - loss: 0.3101 - binary_accuracy: 0.8699 - auc_18: 0.9414\n",
            "Dataset: 70\n",
            "189/189 [==============================] - 4s 11ms/step - loss: 0.3607 - binary_accuracy: 0.8418 - auc_19: 0.9222\n",
            "Dataset: 71\n",
            "63/63 [==============================] - 2s 9ms/step - loss: 0.4349 - binary_accuracy: 0.7961 - auc_20: 0.8896\n",
            "Dataset: 72\n",
            "225/225 [==============================] - 4s 10ms/step - loss: 0.3411 - binary_accuracy: 0.8432 - auc_21: 0.9277\n",
            "Dataset: 73\n",
            "25/25 [==============================] - 2s 9ms/step - loss: 0.2658 - binary_accuracy: 0.8801 - auc_22: 0.9564\n",
            "Dataset: 74\n",
            "38/38 [==============================] - 2s 15ms/step - loss: 0.2225 - binary_accuracy: 0.9099 - auc_23: 0.9709\n",
            "Dataset: 75\n",
            "121/121 [==============================] - 2s 8ms/step - loss: 0.1978 - binary_accuracy: 0.9247 - auc_24: 0.9841\n",
            "Dataset: 76\n",
            "147/147 [==============================] - 2s 8ms/step - loss: 0.3860 - binary_accuracy: 0.8224 - auc_25: 0.9068\n",
            "Dataset: 77\n",
            "103/103 [==============================] - 2s 8ms/step - loss: 0.2766 - binary_accuracy: 0.8831 - auc_26: 0.9538\n",
            "Dataset: 78\n",
            "221/221 [==============================] - 3s 9ms/step - loss: 0.4078 - binary_accuracy: 0.8173 - auc_27: 0.9006\n",
            "Dataset: 79\n",
            "88/88 [==============================] - 2s 8ms/step - loss: 0.4256 - binary_accuracy: 0.8016 - auc_28: 0.8919\n",
            "Dataset: 80\n",
            "142/142 [==============================] - 2s 7ms/step - loss: 0.2687 - binary_accuracy: 0.8845 - auc_29: 0.9558\n",
            "Dataset: 81\n",
            "195/195 [==============================] - 4s 11ms/step - loss: 0.3463 - binary_accuracy: 0.8452 - auc_30: 0.9283\n",
            "Dataset: 82\n",
            "33/33 [==============================] - 2s 11ms/step - loss: 0.2590 - binary_accuracy: 0.8913 - auc_31: 0.9562\n",
            "Dataset: 83\n",
            "215/215 [==============================] - 4s 10ms/step - loss: 0.3457 - binary_accuracy: 0.8445 - auc_32: 0.9271\n",
            "Dataset: 84\n",
            "83/83 [==============================] - 3s 10ms/step - loss: 0.3266 - binary_accuracy: 0.8565 - auc_33: 0.9345\n",
            "Dataset: 85\n",
            "122/122 [==============================] - 3s 12ms/step - loss: 0.3578 - binary_accuracy: 0.8427 - auc_34: 0.9229\n",
            "Dataset: 86\n",
            "184/184 [==============================] - 3s 9ms/step - loss: 0.2866 - binary_accuracy: 0.8769 - auc_35: 0.9510\n",
            "Dataset: 87\n",
            "147/147 [==============================] - 3s 10ms/step - loss: 0.2674 - binary_accuracy: 0.8916 - auc_36: 0.9561\n",
            "Dataset: 88\n",
            "63/63 [==============================] - 2s 7ms/step - loss: 0.3615 - binary_accuracy: 0.8383 - auc_37: 0.9196\n",
            "Dataset: 89\n",
            "206/206 [==============================] - 3s 9ms/step - loss: 0.1905 - binary_accuracy: 0.9267 - auc_38: 0.9783\n",
            "Dataset: 90\n",
            "35/35 [==============================] - 2s 8ms/step - loss: 0.3032 - binary_accuracy: 0.8613 - auc_39: 0.9448\n",
            "Dataset: 91\n",
            "37/37 [==============================] - 2s 12ms/step - loss: 0.2810 - binary_accuracy: 0.8812 - auc_40: 0.9521\n",
            "Dataset: 92\n",
            "157/157 [==============================] - 2s 7ms/step - loss: 0.2144 - binary_accuracy: 0.9140 - auc_41: 0.9796\n",
            "Dataset: 93\n",
            "85/85 [==============================] - 2s 8ms/step - loss: 0.2751 - binary_accuracy: 0.8818 - auc_42: 0.9536\n",
            "Dataset: 94\n",
            "232/232 [==============================] - 3s 7ms/step - loss: 0.3859 - binary_accuracy: 0.8289 - auc_43: 0.9076\n",
            "Dataset: 95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ijtxjXJfibw",
        "outputId": "6690a5ea-5d56-46d0-d29b-f4c2735ea839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9434425830841064\n",
            "0.9407087564468384\n",
            "0.8709458708763123\n",
            "0.9731247425079346\n",
            "0.9532525539398193\n",
            "0.9792302250862122\n",
            "0.9304027557373047\n",
            "0.8872883915901184\n",
            "0.8798696994781494\n",
            "0.940461277961731\n",
            "0.9152224659919739\n",
            "0.8850703835487366\n",
            "0.8894384503364563\n",
            "0.9584742784500122\n",
            "0.9201711416244507\n",
            "0.9596551656723022\n",
            "0.9373490810394287\n",
            "0.9325723648071289\n",
            "0.9414169788360596\n",
            "0.9222031235694885\n",
            "0.8896247744560242\n",
            "0.9276741743087769\n",
            "0.9564241170883179\n",
            "0.970929741859436\n",
            "0.9840898513793945\n",
            "0.9068130850791931\n",
            "0.9538402557373047\n",
            "0.900589644908905\n",
            "0.8918517231941223\n",
            "0.955828845500946\n",
            "0.9283287525177002\n",
            "0.9561659097671509\n",
            "0.9270933866500854\n",
            "0.934490978717804\n",
            "0.9228633642196655\n",
            "0.9510050415992737\n",
            "0.956079363822937\n",
            "0.9196365475654602\n",
            "0.9782773852348328\n",
            "0.9447871446609497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=90:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8db269c-76ab-400d-ceb0-fffec0feb67c",
        "id": "RJB-7N1OfsTN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 91\n",
            "37/37 [==============================] - 2s 13ms/step - loss: 0.2810 - binary_accuracy: 0.8821 - auc: 0.9521\n",
            "Dataset: 92\n",
            "157/157 [==============================] - 3s 9ms/step - loss: 0.2151 - binary_accuracy: 0.9142 - auc_1: 0.9795\n",
            "Dataset: 93\n",
            "85/85 [==============================] - 2s 9ms/step - loss: 0.2749 - binary_accuracy: 0.8815 - auc_2: 0.9536\n",
            "Dataset: 94\n",
            "232/232 [==============================] - 3s 8ms/step - loss: 0.3856 - binary_accuracy: 0.8291 - auc_3: 0.9077\n",
            "Dataset: 95\n",
            "224/224 [==============================] - 3s 7ms/step - loss: 0.2897 - binary_accuracy: 0.8793 - auc_4: 0.9492\n",
            "Dataset: 96\n",
            "136/136 [==============================] - 3s 9ms/step - loss: 0.3499 - binary_accuracy: 0.8452 - auc_5: 0.9292\n",
            "Dataset: 97\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.3017 - binary_accuracy: 0.8722 - auc_6: 0.9440\n",
            "Dataset: 98\n",
            "74/74 [==============================] - 2s 10ms/step - loss: 0.3571 - binary_accuracy: 0.8367 - auc_7: 0.9216\n",
            "Dataset: 99\n",
            "72/72 [==============================] - 2s 12ms/step - loss: 0.2583 - binary_accuracy: 0.8861 - auc_8: 0.9597\n",
            "Dataset: 100\n",
            "41/41 [==============================] - 2s 13ms/step - loss: 0.1885 - binary_accuracy: 0.9233 - auc_9: 0.9814\n",
            "Dataset: 101\n",
            "199/199 [==============================] - 3s 9ms/step - loss: 0.4454 - binary_accuracy: 0.7938 - auc_10: 0.8769\n",
            "Dataset: 102\n",
            "126/126 [==============================] - 3s 11ms/step - loss: 0.2499 - binary_accuracy: 0.8961 - auc_11: 0.9621\n",
            "Dataset: 103\n",
            "129/129 [==============================] - 2s 8ms/step - loss: 0.3501 - binary_accuracy: 0.8465 - auc_12: 0.9264\n",
            "Dataset: 104\n",
            "72/72 [==============================] - 2s 13ms/step - loss: 0.3610 - binary_accuracy: 0.8492 - auc_13: 0.9203\n",
            "Dataset: 105\n",
            "31/31 [==============================] - 2s 16ms/step - loss: 0.2896 - binary_accuracy: 0.8758 - auc_14: 0.9527\n",
            "Dataset: 106\n",
            "140/140 [==============================] - 3s 9ms/step - loss: 0.3265 - binary_accuracy: 0.8576 - auc_15: 0.9350\n",
            "Dataset: 107\n",
            "39/39 [==============================] - 2s 8ms/step - loss: 0.4233 - binary_accuracy: 0.8034 - auc_16: 0.8937\n",
            "Dataset: 108\n",
            "65/65 [==============================] - 3s 15ms/step - loss: 0.2953 - binary_accuracy: 0.8835 - auc_17: 0.9485\n",
            "Dataset: 109\n",
            "81/81 [==============================] - 2s 10ms/step - loss: 0.2489 - binary_accuracy: 0.9053 - auc_18: 0.9662\n",
            "Dataset: 110\n",
            "219/219 [==============================] - 3s 7ms/step - loss: 0.2868 - binary_accuracy: 0.8800 - auc_19: 0.9508\n",
            "Dataset: 111\n",
            "38/38 [==============================] - 2s 7ms/step - loss: 0.4442 - binary_accuracy: 0.7948 - auc_20: 0.8822\n",
            "Dataset: 112\n",
            "157/157 [==============================] - 3s 8ms/step - loss: 0.2333 - binary_accuracy: 0.9046 - auc_21: 0.9669\n",
            "Dataset: 113\n",
            "60/60 [==============================] - 2s 11ms/step - loss: 0.4442 - binary_accuracy: 0.7946 - auc_22: 0.8958\n",
            "Dataset: 114\n",
            "123/123 [==============================] - 3s 10ms/step - loss: 0.3744 - binary_accuracy: 0.8267 - auc_23: 0.9181\n",
            "Dataset: 115\n",
            "211/211 [==============================] - 3s 7ms/step - loss: 0.3208 - binary_accuracy: 0.8642 - auc_24: 0.9372\n",
            "Dataset: 116\n",
            "111/111 [==============================] - 3s 8ms/step - loss: 0.3479 - binary_accuracy: 0.8471 - auc_25: 0.9275\n",
            "Dataset: 117\n",
            "67/67 [==============================] - 2s 11ms/step - loss: 0.5177 - binary_accuracy: 0.7677 - auc_26: 0.8604\n",
            "Dataset: 118\n",
            "139/139 [==============================] - 2s 8ms/step - loss: 0.3807 - binary_accuracy: 0.8269 - auc_27: 0.9141\n",
            "Dataset: 119\n",
            "129/129 [==============================] - 2s 8ms/step - loss: 0.4347 - binary_accuracy: 0.7948 - auc_28: 0.8843\n",
            "Dataset: 120\n",
            "99/99 [==============================] - 2s 7ms/step - loss: 0.2586 - binary_accuracy: 0.8866 - auc_29: 0.9590\n",
            "Dataset: 121\n",
            "185/185 [==============================] - 4s 10ms/step - loss: 0.3988 - binary_accuracy: 0.8207 - auc_30: 0.9060\n",
            "Dataset: 122\n",
            "127/127 [==============================] - 2s 9ms/step - loss: 0.3569 - binary_accuracy: 0.8373 - auc_31: 0.9236\n",
            "Dataset: 123\n",
            "191/191 [==============================] - 3s 8ms/step - loss: 0.2991 - binary_accuracy: 0.8711 - auc_32: 0.9455\n",
            "Dataset: 124\n",
            "32/32 [==============================] - 2s 15ms/step - loss: 0.3091 - binary_accuracy: 0.8619 - auc_33: 0.9418\n",
            "Dataset: 125\n",
            "114/114 [==============================] - 2s 8ms/step - loss: 0.2277 - binary_accuracy: 0.9084 - auc_34: 0.9753\n",
            "Dataset: 126\n",
            "214/214 [==============================] - 3s 9ms/step - loss: 0.3088 - binary_accuracy: 0.8641 - auc_35: 0.9426\n",
            "Dataset: 127\n",
            "63/63 [==============================] - 2s 8ms/step - loss: 0.3203 - binary_accuracy: 0.8645 - auc_36: 0.9380\n",
            "Dataset: 128\n",
            "124/124 [==============================] - 2s 8ms/step - loss: 0.4510 - binary_accuracy: 0.7879 - auc_37: 0.8751\n",
            "Dataset: 129\n",
            "138/138 [==============================] - 2s 8ms/step - loss: 0.3414 - binary_accuracy: 0.8510 - auc_38: 0.9297\n",
            "Dataset: 130\n",
            "27/27 [==============================] - 2s 8ms/step - loss: 0.6255 - binary_accuracy: 0.7014 - auc_39: 0.7945\n",
            "Dataset: 131\n",
            "87/87 [==============================] - 2s 9ms/step - loss: 0.2503 - binary_accuracy: 0.8962 - auc_40: 0.9616\n",
            "Dataset: 132\n",
            "27/27 [==============================] - 2s 8ms/step - loss: 0.2743 - binary_accuracy: 0.8776 - auc_41: 0.9545\n",
            "Dataset: 133\n",
            "207/207 [==============================] - 3s 8ms/step - loss: 0.3484 - binary_accuracy: 0.8501 - auc_42: 0.9259\n",
            "Dataset: 134\n",
            "38/38 [==============================] - 2s 15ms/step - loss: 0.4447 - binary_accuracy: 0.7933 - auc_43: 0.8871\n",
            "Dataset: 135\n",
            "32/32 [==============================] - 2s 9ms/step - loss: 0.3287 - binary_accuracy: 0.8536 - auc_44: 0.9312\n",
            "Dataset: 136\n",
            "83/83 [==============================] - 2s 8ms/step - loss: 0.3233 - binary_accuracy: 0.8493 - auc_45: 0.9349\n",
            "Dataset: 137\n",
            "142/142 [==============================] - 2s 7ms/step - loss: 0.4343 - binary_accuracy: 0.7916 - auc_46: 0.8835\n",
            "Dataset: 138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2qU6-o8tGYY",
        "outputId": "ef28525e-1179-45b7-f03d-0ba0cd9c27b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.952144980430603\n",
            "0.9794921875\n",
            "0.9536312222480774\n",
            "0.9077019691467285\n",
            "0.9491674900054932\n",
            "0.9291517734527588\n",
            "0.9439911842346191\n",
            "0.921553909778595\n",
            "0.9596505165100098\n",
            "0.981364369392395\n",
            "0.876914918422699\n",
            "0.9620929956436157\n",
            "0.9263676404953003\n",
            "0.9202947020530701\n",
            "0.9526789784431458\n",
            "0.9349732995033264\n",
            "0.8937196135520935\n",
            "0.9485183954238892\n",
            "0.9661709070205688\n",
            "0.9507594704627991\n",
            "0.8821559548377991\n",
            "0.9669102430343628\n",
            "0.8957704305648804\n",
            "0.9181241989135742\n",
            "0.9371542930603027\n",
            "0.9275383353233337\n",
            "0.860419750213623\n",
            "0.9141083359718323\n",
            "0.8843063116073608\n",
            "0.9590222239494324\n",
            "0.906002938747406\n",
            "0.9235966205596924\n",
            "0.945484459400177\n",
            "0.9417846202850342\n",
            "0.9752907752990723\n",
            "0.9426071047782898\n",
            "0.9380014538764954\n",
            "0.8750603199005127\n",
            "0.9296598434448242\n",
            "0.7945277690887451\n",
            "0.9615758061408997\n",
            "0.9544819593429565\n",
            "0.9258757829666138\n",
            "0.8871482610702515\n",
            "0.9312261939048767\n",
            "0.9349220395088196\n",
            "0.8834552764892578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=137:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8badf90-c397-49af-b041-9b952bc643e3",
        "id": "s-xmEE5LtQnx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 138\n",
            "165/165 [==============================] - 3s 8ms/step - loss: 0.3558 - binary_accuracy: 0.8422 - auc: 0.9243\n",
            "Dataset: 139\n",
            "131/131 [==============================] - 3s 9ms/step - loss: 0.3331 - binary_accuracy: 0.8554 - auc_1: 0.9326\n",
            "Dataset: 140\n",
            "193/193 [==============================] - 4s 12ms/step - loss: 0.4199 - binary_accuracy: 0.8070 - auc_2: 0.8963\n",
            "Dataset: 141\n",
            "108/108 [==============================] - 3s 12ms/step - loss: 0.3146 - binary_accuracy: 0.8643 - auc_3: 0.9399\n",
            "Dataset: 142\n",
            "36/36 [==============================] - 2s 14ms/step - loss: 0.2330 - binary_accuracy: 0.9085 - auc_4: 0.9679\n",
            "Dataset: 143\n",
            "170/170 [==============================] - 3s 7ms/step - loss: 0.3422 - binary_accuracy: 0.8450 - auc_5: 0.9315\n",
            "Dataset: 144\n",
            "230/230 [==============================] - 3s 9ms/step - loss: 0.3263 - binary_accuracy: 0.8579 - auc_6: 0.9349\n",
            "Dataset: 145\n",
            "175/175 [==============================] - 3s 9ms/step - loss: 0.2397 - binary_accuracy: 0.8992 - auc_7: 0.9649\n",
            "Dataset: 146\n",
            "31/31 [==============================] - 2s 16ms/step - loss: 0.4990 - binary_accuracy: 0.7657 - auc_8: 0.8560\n",
            "Dataset: 147\n",
            "212/212 [==============================] - 3s 8ms/step - loss: 0.3744 - binary_accuracy: 0.8320 - auc_9: 0.9138\n",
            "Dataset: 148\n",
            "155/155 [==============================] - 3s 10ms/step - loss: 0.3314 - binary_accuracy: 0.8548 - auc_10: 0.9342\n",
            "Dataset: 149\n",
            "89/89 [==============================] - 2s 8ms/step - loss: 0.5667 - binary_accuracy: 0.7318 - auc_11: 0.8168\n",
            "Dataset: 150\n",
            "57/57 [==============================] - 3s 16ms/step - loss: 0.2663 - binary_accuracy: 0.8920 - auc_12: 0.9571\n",
            "Dataset: 151\n",
            "80/80 [==============================] - 2s 10ms/step - loss: 0.4359 - binary_accuracy: 0.8017 - auc_13: 0.8820\n",
            "Dataset: 152\n",
            "33/33 [==============================] - 2s 16ms/step - loss: 0.4729 - binary_accuracy: 0.7738 - auc_14: 0.8639\n",
            "Dataset: 153\n",
            "126/126 [==============================] - 2s 9ms/step - loss: 0.3785 - binary_accuracy: 0.8304 - auc_15: 0.9115\n",
            "Dataset: 154\n",
            "65/65 [==============================] - 2s 10ms/step - loss: 0.2157 - binary_accuracy: 0.9181 - auc_16: 0.9778\n",
            "Dataset: 155\n",
            "185/185 [==============================] - 3s 8ms/step - loss: 0.3362 - binary_accuracy: 0.8451 - auc_17: 0.9304\n",
            "Dataset: 156\n",
            "125/125 [==============================] - 2s 7ms/step - loss: 0.3628 - binary_accuracy: 0.8372 - auc_18: 0.9226\n",
            "Dataset: 157\n",
            "81/81 [==============================] - 2s 9ms/step - loss: 0.3054 - binary_accuracy: 0.8628 - auc_19: 0.9419\n",
            "Dataset: 158\n",
            "190/190 [==============================] - 3s 10ms/step - loss: 0.2659 - binary_accuracy: 0.8881 - auc_20: 0.9566\n",
            "Dataset: 159\n",
            "229/229 [==============================] - 3s 7ms/step - loss: 0.3805 - binary_accuracy: 0.8284 - auc_21: 0.9119\n",
            "Dataset: 160\n",
            "163/163 [==============================] - 3s 8ms/step - loss: 0.2984 - binary_accuracy: 0.8685 - auc_22: 0.9441\n",
            "Dataset: 161\n",
            "87/87 [==============================] - 2s 9ms/step - loss: 0.2963 - binary_accuracy: 0.8683 - auc_23: 0.9457\n",
            "Dataset: 162\n",
            "52/52 [==============================] - 2s 7ms/step - loss: 0.2303 - binary_accuracy: 0.9046 - auc_24: 0.9688\n",
            "Dataset: 163\n",
            "38/38 [==============================] - 2s 8ms/step - loss: 0.3116 - binary_accuracy: 0.8651 - auc_25: 0.9399\n",
            "Dataset: 164\n",
            "60/60 [==============================] - 2s 11ms/step - loss: 0.2142 - binary_accuracy: 0.9126 - auc_26: 0.9714\n",
            "Dataset: 165\n",
            "147/147 [==============================] - 2s 7ms/step - loss: 0.2411 - binary_accuracy: 0.8992 - auc_27: 0.9661\n",
            "Dataset: 166\n",
            "57/57 [==============================] - 2s 7ms/step - loss: 0.5214 - binary_accuracy: 0.7658 - auc_28: 0.8616\n",
            "Dataset: 167\n",
            "211/211 [==============================] - 3s 8ms/step - loss: 0.3185 - binary_accuracy: 0.8595 - auc_29: 0.9388\n",
            "Dataset: 168\n",
            "193/193 [==============================] - 3s 8ms/step - loss: 0.4114 - binary_accuracy: 0.8129 - auc_30: 0.8981\n",
            "Dataset: 169\n",
            "175/175 [==============================] - 3s 7ms/step - loss: 0.3115 - binary_accuracy: 0.8643 - auc_31: 0.9420\n",
            "Dataset: 170\n",
            "68/68 [==============================] - 3s 11ms/step - loss: 0.2956 - binary_accuracy: 0.8748 - auc_32: 0.9463\n",
            "Dataset: 171\n",
            "197/197 [==============================] - 3s 7ms/step - loss: 0.3680 - binary_accuracy: 0.8358 - auc_33: 0.9181\n",
            "Dataset: 172\n",
            "201/201 [==============================] - 3s 8ms/step - loss: 0.3480 - binary_accuracy: 0.8449 - auc_34: 0.9290\n",
            "Dataset: 173\n",
            "42/42 [==============================] - 2s 11ms/step - loss: 0.5687 - binary_accuracy: 0.7260 - auc_35: 0.8274\n",
            "Dataset: 174\n",
            "51/51 [==============================] - 2s 7ms/step - loss: 0.2312 - binary_accuracy: 0.9069 - auc_36: 0.9675\n",
            "Dataset: 175\n",
            "167/167 [==============================] - 3s 7ms/step - loss: 0.2628 - binary_accuracy: 0.8882 - auc_37: 0.9583\n",
            "Dataset: 176\n",
            "96/96 [==============================] - 2s 9ms/step - loss: 0.2969 - binary_accuracy: 0.8776 - auc_38: 0.9462\n",
            "Dataset: 177\n",
            "167/167 [==============================] - 3s 7ms/step - loss: 0.3334 - binary_accuracy: 0.8521 - auc_39: 0.9319\n",
            "Dataset: 178\n",
            "89/89 [==============================] - 2s 7ms/step - loss: 0.2373 - binary_accuracy: 0.9039 - auc_40: 0.9661\n",
            "Dataset: 179\n",
            "109/109 [==============================] - 3s 10ms/step - loss: 0.2100 - binary_accuracy: 0.9121 - auc_41: 0.9747\n",
            "Dataset: 180\n",
            "169/169 [==============================] - 3s 8ms/step - loss: 0.3182 - binary_accuracy: 0.8664 - auc_42: 0.9383\n",
            "Dataset: 181\n",
            "128/128 [==============================] - 2s 7ms/step - loss: 0.3290 - binary_accuracy: 0.8563 - auc_43: 0.9383\n",
            "Dataset: 182\n",
            "146/146 [==============================] - 2s 8ms/step - loss: 0.2877 - binary_accuracy: 0.8779 - auc_44: 0.9514\n",
            "Dataset: 183\n",
            "120/120 [==============================] - 2s 7ms/step - loss: 0.2986 - binary_accuracy: 0.8709 - auc_45: 0.9458\n",
            "Dataset: 184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv3Zd6b35Yfd",
        "outputId": "630985fe-7abe-4ef2-9997-90b86d2d06e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9243074059486389\n",
            "0.9325570464134216\n",
            "0.8963478207588196\n",
            "0.9398764967918396\n",
            "0.9678941965103149\n",
            "0.9315146207809448\n",
            "0.9349467158317566\n",
            "0.9649478197097778\n",
            "0.8560346364974976\n",
            "0.9137784838676453\n",
            "0.9342442750930786\n",
            "0.816816508769989\n",
            "0.957145094871521\n",
            "0.881974458694458\n",
            "0.8638526201248169\n",
            "0.9115430116653442\n",
            "0.9777678847312927\n",
            "0.9303597807884216\n",
            "0.9226472973823547\n",
            "0.9419198036193848\n",
            "0.9565771222114563\n",
            "0.9118928909301758\n",
            "0.9441162943840027\n",
            "0.9456779956817627\n",
            "0.9687814116477966\n",
            "0.9398624897003174\n",
            "0.9714159369468689\n",
            "0.9661412239074707\n",
            "0.8615740537643433\n",
            "0.9387581944465637\n",
            "0.8981323838233948\n",
            "0.942013680934906\n",
            "0.9463198781013489\n",
            "0.9180708527565002\n",
            "0.9289506673812866\n",
            "0.8273903727531433\n",
            "0.967467725276947\n",
            "0.9582687616348267\n",
            "0.9462282657623291\n",
            "0.9318883419036865\n",
            "0.966103732585907\n",
            "0.9747071862220764\n",
            "0.9383089542388916\n",
            "0.9382795691490173\n",
            "0.9514319896697998\n",
            "0.9458338022232056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=183:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473e145c-e2e5-4c67-9e88-6d8cfd577da5",
        "id": "PHe-aBHs5g2A"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 184\n",
            "130/130 [==============================] - 3s 9ms/step - loss: 0.4320 - binary_accuracy: 0.8026 - auc: 0.8847\n",
            "Dataset: 185\n",
            "38/38 [==============================] - 2s 14ms/step - loss: 0.2946 - binary_accuracy: 0.8748 - auc_1: 0.9471\n",
            "Dataset: 186\n",
            "146/146 [==============================] - 3s 12ms/step - loss: 0.3262 - binary_accuracy: 0.8543 - auc_2: 0.9353\n",
            "Dataset: 187\n",
            "222/222 [==============================] - 4s 9ms/step - loss: 0.2284 - binary_accuracy: 0.9052 - auc_3: 0.9683\n",
            "Dataset: 188\n",
            "221/221 [==============================] - 3s 8ms/step - loss: 0.3692 - binary_accuracy: 0.8377 - auc_4: 0.9202\n",
            "Dataset: 189\n",
            "101/101 [==============================] - 2s 9ms/step - loss: 0.2903 - binary_accuracy: 0.8785 - auc_5: 0.9488\n",
            "Dataset: 190\n",
            "62/62 [==============================] - 2s 11ms/step - loss: 0.2382 - binary_accuracy: 0.8993 - auc_6: 0.9662\n",
            "Dataset: 191\n",
            "29/29 [==============================] - 2s 13ms/step - loss: 0.2592 - binary_accuracy: 0.8866 - auc_7: 0.9616\n",
            "Dataset: 192\n",
            "158/158 [==============================] - 3s 10ms/step - loss: 0.3538 - binary_accuracy: 0.8450 - auc_8: 0.9267\n",
            "Dataset: 193\n",
            "197/197 [==============================] - 4s 11ms/step - loss: 0.3218 - binary_accuracy: 0.8581 - auc_9: 0.9363\n",
            "Dataset: 194\n",
            "97/97 [==============================] - 2s 10ms/step - loss: 0.3564 - binary_accuracy: 0.8375 - auc_10: 0.9220\n",
            "Dataset: 195\n",
            "195/195 [==============================] - 3s 9ms/step - loss: 0.2768 - binary_accuracy: 0.8851 - auc_11: 0.9536\n",
            "Dataset: 196\n",
            "112/112 [==============================] - 3s 11ms/step - loss: 0.3552 - binary_accuracy: 0.8437 - auc_12: 0.9222\n",
            "Dataset: 197\n",
            "28/28 [==============================] - 2s 9ms/step - loss: 0.2023 - binary_accuracy: 0.9186 - auc_13: 0.9782\n",
            "Dataset: 198\n",
            "138/138 [==============================] - 3s 9ms/step - loss: 0.2021 - binary_accuracy: 0.9210 - auc_14: 0.9799\n",
            "Dataset: 199\n",
            "184/184 [==============================] - 3s 8ms/step - loss: 0.3727 - binary_accuracy: 0.8293 - auc_15: 0.9190\n",
            "Dataset: 200\n",
            "192/192 [==============================] - 3s 8ms/step - loss: 0.2460 - binary_accuracy: 0.9050 - auc_16: 0.9651\n",
            "Dataset: 201\n",
            "176/176 [==============================] - 3s 8ms/step - loss: 0.4622 - binary_accuracy: 0.7784 - auc_17: 0.8670\n",
            "Dataset: 202\n",
            "26/26 [==============================] - 2s 9ms/step - loss: 0.3142 - binary_accuracy: 0.8686 - auc_18: 0.9400\n",
            "Dataset: 203\n",
            "190/190 [==============================] - 3s 8ms/step - loss: 0.3448 - binary_accuracy: 0.8467 - auc_19: 0.9265\n",
            "Dataset: 204\n",
            "126/126 [==============================] - 2s 9ms/step - loss: 0.4437 - binary_accuracy: 0.7933 - auc_20: 0.8782\n",
            "Dataset: 205\n",
            "99/99 [==============================] - 2s 9ms/step - loss: 0.2415 - binary_accuracy: 0.8997 - auc_21: 0.9660\n",
            "Dataset: 206\n",
            "101/101 [==============================] - 2s 9ms/step - loss: 0.2332 - binary_accuracy: 0.8978 - auc_22: 0.9668\n",
            "Dataset: 207\n",
            "199/199 [==============================] - 3s 8ms/step - loss: 0.3356 - binary_accuracy: 0.8499 - auc_23: 0.9309\n",
            "Dataset: 208\n",
            "25/25 [==============================] - 2s 18ms/step - loss: 0.4585 - binary_accuracy: 0.7832 - auc_24: 0.8783\n",
            "Dataset: 209\n",
            "115/115 [==============================] - 2s 9ms/step - loss: 0.3827 - binary_accuracy: 0.8239 - auc_25: 0.9173\n",
            "Dataset: 210\n",
            "42/42 [==============================] - 2s 8ms/step - loss: 0.3836 - binary_accuracy: 0.8299 - auc_26: 0.9131\n",
            "Dataset: 211\n",
            "47/47 [==============================] - 2s 9ms/step - loss: 0.2532 - binary_accuracy: 0.8896 - auc_27: 0.9601\n",
            "Dataset: 212\n",
            "27/27 [==============================] - 2s 8ms/step - loss: 0.2472 - binary_accuracy: 0.9020 - auc_28: 0.9621\n",
            "Dataset: 213\n",
            "157/157 [==============================] - 3s 8ms/step - loss: 0.2632 - binary_accuracy: 0.8941 - auc_29: 0.9577\n",
            "Dataset: 214\n",
            "56/56 [==============================] - 2s 8ms/step - loss: 0.3273 - binary_accuracy: 0.8585 - auc_30: 0.9353\n",
            "Dataset: 215\n",
            "113/113 [==============================] - 3s 12ms/step - loss: 0.2256 - binary_accuracy: 0.9145 - auc_31: 0.9691\n",
            "Dataset: 216\n",
            "138/138 [==============================] - 3s 8ms/step - loss: 0.3401 - binary_accuracy: 0.8556 - auc_32: 0.9295\n",
            "Dataset: 217\n",
            "41/41 [==============================] - 3s 16ms/step - loss: 0.5469 - binary_accuracy: 0.7395 - auc_33: 0.8320\n",
            "Dataset: 218\n",
            "27/27 [==============================] - 2s 14ms/step - loss: 0.2949 - binary_accuracy: 0.8750 - auc_34: 0.9460\n",
            "Dataset: 219\n",
            "164/164 [==============================] - 3s 8ms/step - loss: 0.2801 - binary_accuracy: 0.8844 - auc_35: 0.9522\n",
            "Dataset: 220\n",
            "78/78 [==============================] - 2s 10ms/step - loss: 0.1890 - binary_accuracy: 0.9266 - auc_36: 0.9829\n",
            "Dataset: 221\n",
            "121/121 [==============================] - 2s 8ms/step - loss: 0.4452 - binary_accuracy: 0.8070 - auc_37: 0.8865\n",
            "Dataset: 222\n",
            "67/67 [==============================] - 2s 8ms/step - loss: 0.5134 - binary_accuracy: 0.7598 - auc_38: 0.8530\n",
            "Dataset: 223\n",
            "106/106 [==============================] - 3s 8ms/step - loss: 0.4372 - binary_accuracy: 0.7959 - auc_39: 0.8833\n",
            "Dataset: 224\n",
            "86/86 [==============================] - 3s 11ms/step - loss: 0.2230 - binary_accuracy: 0.9139 - auc_40: 0.9713\n",
            "Dataset: 225\n",
            "105/105 [==============================] - 2s 8ms/step - loss: 0.3019 - binary_accuracy: 0.8695 - auc_41: 0.9442\n",
            "Dataset: 226\n",
            "45/45 [==============================] - 2s 8ms/step - loss: 0.3331 - binary_accuracy: 0.8492 - auc_42: 0.9343\n",
            "Dataset: 227\n",
            "141/141 [==============================] - 3s 8ms/step - loss: 0.4168 - binary_accuracy: 0.8099 - auc_43: 0.8906\n",
            "Dataset: 228\n",
            "123/123 [==============================] - 3s 10ms/step - loss: 0.2263 - binary_accuracy: 0.9113 - auc_44: 0.9671\n",
            "Dataset: 229\n",
            "51/51 [==============================] - 2s 12ms/step - loss: 0.6701 - binary_accuracy: 0.6561 - auc_45: 0.7486\n",
            "Dataset: 230\n",
            "25/25 [==============================] - 7s 143ms/step - loss: 0.5150 - binary_accuracy: 0.7617 - auc_46: 0.8403\n",
            "Dataset: 231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('acc.pkl', 'rb') as file:\n",
        "  avg_acc = pickle.load(file)\n",
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOd6u-SiJwgt",
        "outputId": "82f6031f-9b60-41bc-8d17-6081f53c6c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8846648931503296\n",
            "0.9471480846405029\n",
            "0.9352574348449707\n",
            "0.9683359265327454\n",
            "0.920158326625824\n",
            "0.9488080739974976\n",
            "0.9661758542060852\n",
            "0.961597740650177\n",
            "0.9267008304595947\n",
            "0.9363128542900085\n",
            "0.9219815731048584\n",
            "0.9535526037216187\n",
            "0.9221689105033875\n",
            "0.9781924486160278\n",
            "0.9798941612243652\n",
            "0.9190000295639038\n",
            "0.9650973081588745\n",
            "0.8669565916061401\n",
            "0.9399836659431458\n",
            "0.9265304803848267\n",
            "0.8781782388687134\n",
            "0.9659824967384338\n",
            "0.9668212532997131\n",
            "0.9308528900146484\n",
            "0.8783012628555298\n",
            "0.9172869920730591\n",
            "0.91311115026474\n",
            "0.9601110219955444\n",
            "0.962104320526123\n",
            "0.957688570022583\n",
            "0.9353210926055908\n",
            "0.969108521938324\n",
            "0.929503858089447\n",
            "0.8320202231407166\n",
            "0.9460240602493286\n",
            "0.952167809009552\n",
            "0.9828872680664062\n",
            "0.8864848017692566\n",
            "0.8529946804046631\n",
            "0.8832821249961853\n",
            "0.9712824821472168\n",
            "0.9442206025123596\n",
            "0.9343276619911194\n",
            "0.8906334638595581\n",
            "0.9671363830566406\n",
            "0.7485958337783813\n",
            "0.8402615189552307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<230:\n",
        "    continue\n",
        "  if i==241:\n",
        "    break\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54abe8e-87c9-4d43-fcba-2658d3dc6202",
        "id": "Q7U_u9CALxtQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 230\n",
            "25/25 [==============================] - 2s 15ms/step - loss: 0.5152 - binary_accuracy: 0.7617 - auc: 0.8405\n",
            "Dataset: 231\n",
            "51/51 [==============================] - 2s 12ms/step - loss: 0.3436 - binary_accuracy: 0.8411 - auc_1: 0.9277\n",
            "Dataset: 232\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.3487 - binary_accuracy: 0.8466 - auc_2: 0.9251\n",
            "Dataset: 233\n",
            "116/116 [==============================] - 3s 13ms/step - loss: 0.5305 - binary_accuracy: 0.7555 - auc_3: 0.8386\n",
            "Dataset: 234\n",
            "67/67 [==============================] - 3s 10ms/step - loss: 0.5884 - binary_accuracy: 0.7108 - auc_4: 0.8055\n",
            "Dataset: 235\n",
            "197/197 [==============================] - 3s 9ms/step - loss: 0.3478 - binary_accuracy: 0.8439 - auc_5: 0.9286\n",
            "Dataset: 236\n",
            "64/64 [==============================] - 2s 11ms/step - loss: 0.2765 - binary_accuracy: 0.8755 - auc_6: 0.9538\n",
            "Dataset: 237\n",
            "170/170 [==============================] - 3s 8ms/step - loss: 0.3603 - binary_accuracy: 0.8418 - auc_7: 0.9210\n",
            "Dataset: 238\n",
            "174/174 [==============================] - 3s 9ms/step - loss: 0.3488 - binary_accuracy: 0.8447 - auc_8: 0.9302\n",
            "Dataset: 239\n",
            "111/111 [==============================] - 2s 8ms/step - loss: 0.2642 - binary_accuracy: 0.8868 - auc_9: 0.9590\n",
            "Dataset: 240\n",
            "71/71 [==============================] - 2s 7ms/step - loss: 0.5043 - binary_accuracy: 0.7622 - auc_10: 0.8596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open('acc.pkl', 'rb') as file:\n",
        "#   avg_acc = pickle.load(file)\n",
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZQWH0oQO6vX",
        "outputId": "3b27374e-31ab-44f7-b577-33c4cce0b363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8405270576477051\n",
            "0.927676260471344\n",
            "0.9250666499137878\n",
            "0.8385700583457947\n",
            "0.8054885268211365\n",
            "0.9286465048789978\n",
            "0.9538219571113586\n",
            "0.9210497736930847\n",
            "0.9301666021347046\n",
            "0.9589602947235107\n",
            "0.8596146702766418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=240:\n",
        "    continue\n",
        "  if i>=290:\n",
        "    break\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58e1d77-718a-4a5b-ef79-9ec8d21f3895",
        "id": "HlO3Vfr0WYDt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 241\n",
            "80/80 [==============================] - 3s 9ms/step - loss: 0.2215 - binary_accuracy: 0.9091 - auc: 0.9698\n",
            "Dataset: 242\n",
            "218/218 [==============================] - 4s 9ms/step - loss: 0.3404 - binary_accuracy: 0.8517 - auc_1: 0.9300\n",
            "Dataset: 243\n",
            "82/82 [==============================] - 2s 9ms/step - loss: 0.1987 - binary_accuracy: 0.9173 - auc_2: 0.9767\n",
            "Dataset: 244\n",
            "227/227 [==============================] - 3s 8ms/step - loss: 0.2041 - binary_accuracy: 0.9200 - auc_3: 0.9764\n",
            "Dataset: 245\n",
            "199/199 [==============================] - 3s 8ms/step - loss: 0.3348 - binary_accuracy: 0.8506 - auc_4: 0.9333\n",
            "Dataset: 246\n",
            "218/218 [==============================] - 3s 7ms/step - loss: 0.3085 - binary_accuracy: 0.8697 - auc_5: 0.9420\n",
            "Dataset: 247\n",
            "125/125 [==============================] - 2s 9ms/step - loss: 0.3087 - binary_accuracy: 0.8667 - auc_6: 0.9434\n",
            "Dataset: 248\n",
            "195/195 [==============================] - 3s 7ms/step - loss: 0.4998 - binary_accuracy: 0.7568 - auc_7: 0.8483\n",
            "Dataset: 249\n",
            "70/70 [==============================] - 2s 14ms/step - loss: 0.2134 - binary_accuracy: 0.9086 - auc_8: 0.9724\n",
            "Dataset: 250\n",
            "52/52 [==============================] - 2s 12ms/step - loss: 0.2183 - binary_accuracy: 0.9071 - auc_9: 0.9714\n",
            "Dataset: 251\n",
            "154/154 [==============================] - 3s 8ms/step - loss: 0.2350 - binary_accuracy: 0.9006 - auc_10: 0.9658\n",
            "Dataset: 252\n",
            "96/96 [==============================] - 2s 9ms/step - loss: 0.4133 - binary_accuracy: 0.8168 - auc_11: 0.9016\n",
            "Dataset: 253\n",
            "181/181 [==============================] - 3s 8ms/step - loss: 0.2804 - binary_accuracy: 0.8834 - auc_12: 0.9520\n",
            "Dataset: 254\n",
            "148/148 [==============================] - 2s 8ms/step - loss: 0.3056 - binary_accuracy: 0.8630 - auc_13: 0.9444\n",
            "Dataset: 255\n",
            "182/182 [==============================] - 3s 7ms/step - loss: 0.3732 - binary_accuracy: 0.8254 - auc_14: 0.9128\n",
            "Dataset: 256\n",
            "218/218 [==============================] - 3s 8ms/step - loss: 0.3581 - binary_accuracy: 0.8382 - auc_15: 0.9212\n",
            "Dataset: 257\n",
            "68/68 [==============================] - 2s 8ms/step - loss: 0.2668 - binary_accuracy: 0.8901 - auc_16: 0.9557\n",
            "Dataset: 258\n",
            "229/229 [==============================] - 3s 7ms/step - loss: 0.3980 - binary_accuracy: 0.8166 - auc_17: 0.9057\n",
            "Dataset: 259\n",
            "79/79 [==============================] - 2s 7ms/step - loss: 0.3322 - binary_accuracy: 0.8562 - auc_18: 0.9326\n",
            "Dataset: 260\n",
            "43/43 [==============================] - 2s 8ms/step - loss: 0.2469 - binary_accuracy: 0.8981 - auc_19: 0.9637\n",
            "Dataset: 261\n",
            "142/142 [==============================] - 2s 8ms/step - loss: 0.3193 - binary_accuracy: 0.8638 - auc_20: 0.9369\n",
            "Dataset: 262\n",
            "57/57 [==============================] - 2s 7ms/step - loss: 0.6074 - binary_accuracy: 0.7155 - auc_21: 0.8147\n",
            "Dataset: 263\n",
            "234/234 [==============================] - 4s 10ms/step - loss: 0.3509 - binary_accuracy: 0.8430 - auc_22: 0.9285\n",
            "Dataset: 264\n",
            "36/36 [==============================] - 2s 8ms/step - loss: 0.3203 - binary_accuracy: 0.8629 - auc_23: 0.9395\n",
            "Dataset: 265\n",
            "172/172 [==============================] - 3s 9ms/step - loss: 0.3882 - binary_accuracy: 0.8180 - auc_24: 0.9058\n",
            "Dataset: 266\n",
            "118/118 [==============================] - 2s 9ms/step - loss: 0.2555 - binary_accuracy: 0.8927 - auc_25: 0.9604\n",
            "Dataset: 267\n",
            "197/197 [==============================] - 4s 10ms/step - loss: 0.3450 - binary_accuracy: 0.8446 - auc_26: 0.9283\n",
            "Dataset: 268\n",
            "234/234 [==============================] - 3s 8ms/step - loss: 0.3147 - binary_accuracy: 0.8662 - auc_27: 0.9402\n",
            "Dataset: 269\n",
            "106/106 [==============================] - 2s 9ms/step - loss: 0.2869 - binary_accuracy: 0.8803 - auc_28: 0.9498\n",
            "Dataset: 270\n",
            "114/114 [==============================] - 2s 7ms/step - loss: 0.3100 - binary_accuracy: 0.8620 - auc_29: 0.9409\n",
            "Dataset: 271\n",
            "36/36 [==============================] - 2s 14ms/step - loss: 0.2642 - binary_accuracy: 0.8932 - auc_30: 0.9583\n",
            "Dataset: 272\n",
            "71/71 [==============================] - 2s 9ms/step - loss: 0.2402 - binary_accuracy: 0.8956 - auc_31: 0.9649\n",
            "Dataset: 273\n",
            "75/75 [==============================] - 2s 7ms/step - loss: 0.3412 - binary_accuracy: 0.8514 - auc_32: 0.9284\n",
            "Dataset: 274\n",
            "227/227 [==============================] - 4s 10ms/step - loss: 0.2745 - binary_accuracy: 0.8885 - auc_33: 0.9546\n",
            "Dataset: 275\n",
            "36/36 [==============================] - 2s 7ms/step - loss: 0.2073 - binary_accuracy: 0.9089 - auc_34: 0.9770\n",
            "Dataset: 276\n",
            "87/87 [==============================] - 2s 8ms/step - loss: 0.2934 - binary_accuracy: 0.8667 - auc_35: 0.9455\n",
            "Dataset: 277\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 0.2881 - binary_accuracy: 0.8755 - auc_36: 0.9491\n",
            "Dataset: 278\n",
            "219/219 [==============================] - 3s 9ms/step - loss: 0.3394 - binary_accuracy: 0.8511 - auc_37: 0.9296\n",
            "Dataset: 279\n",
            "53/53 [==============================] - 2s 7ms/step - loss: 0.4302 - binary_accuracy: 0.8044 - auc_38: 0.8907\n",
            "Dataset: 280\n",
            "151/151 [==============================] - 2s 7ms/step - loss: 0.2596 - binary_accuracy: 0.8903 - auc_39: 0.9601\n",
            "Dataset: 281\n",
            "38/38 [==============================] - 2s 10ms/step - loss: 0.2102 - binary_accuracy: 0.9128 - auc_40: 0.9739\n",
            "Dataset: 282\n",
            "132/132 [==============================] - 2s 9ms/step - loss: 0.3742 - binary_accuracy: 0.8353 - auc_41: 0.9128\n",
            "Dataset: 283\n",
            "182/182 [==============================] - 3s 7ms/step - loss: 0.2504 - binary_accuracy: 0.8969 - auc_42: 0.9622\n",
            "Dataset: 284\n",
            "114/114 [==============================] - 2s 7ms/step - loss: 0.3099 - binary_accuracy: 0.8684 - auc_43: 0.9423\n",
            "Dataset: 285\n",
            "127/127 [==============================] - 2s 7ms/step - loss: 0.3059 - binary_accuracy: 0.8689 - auc_44: 0.9423\n",
            "Dataset: 286\n",
            "194/194 [==============================] - 3s 9ms/step - loss: 0.2847 - binary_accuracy: 0.8717 - auc_45: 0.9510\n",
            "Dataset: 287\n",
            "213/213 [==============================] - 175s 802ms/step - loss: 0.3395 - binary_accuracy: 0.8472 - auc_46: 0.9292\n",
            "Dataset: 288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('acc.pkl', 'rb') as file:\n",
        "  avg_acc = pickle.load(file)\n",
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUyR60vXJvRA",
        "outputId": "1f6aff73-b574-480a-83fa-d5f90754278b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9698153734207153\n",
            "0.929977536201477\n",
            "0.9766781330108643\n",
            "0.9764435887336731\n",
            "0.9333206415176392\n",
            "0.9420354962348938\n",
            "0.9434300661087036\n",
            "0.848273515701294\n",
            "0.9723823070526123\n",
            "0.9713690280914307\n",
            "0.9657667279243469\n",
            "0.9016256332397461\n",
            "0.9519780874252319\n",
            "0.9444025754928589\n",
            "0.912808895111084\n",
            "0.9212120175361633\n",
            "0.9556626677513123\n",
            "0.9057461619377136\n",
            "0.9325785040855408\n",
            "0.9636701941490173\n",
            "0.9369425177574158\n",
            "0.8146703839302063\n",
            "0.9284705519676208\n",
            "0.9394945502281189\n",
            "0.9058265089988708\n",
            "0.9603830575942993\n",
            "0.928296685218811\n",
            "0.940176248550415\n",
            "0.9498319029808044\n",
            "0.9409414529800415\n",
            "0.9582990407943726\n",
            "0.9648569226264954\n",
            "0.9284125566482544\n",
            "0.954596757888794\n",
            "0.9770355224609375\n",
            "0.9454697370529175\n",
            "0.9491232633590698\n",
            "0.9296199679374695\n",
            "0.8906521201133728\n",
            "0.9601134657859802\n",
            "0.9738634824752808\n",
            "0.9127882719039917\n",
            "0.9622238874435425\n",
            "0.9423323273658752\n",
            "0.9422839879989624\n",
            "0.9509872794151306\n",
            "0.9292495846748352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=287:\n",
        "    continue\n",
        "  if i>=290:\n",
        "    break\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc99398b-0033-47e1-fa73-f197e66004ab",
        "id": "eyKXhbfYOX6u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 288\n",
            "140/140 [==============================] - 3s 10ms/step - loss: 0.2734 - binary_accuracy: 0.8886 - auc: 0.9528\n",
            "Dataset: 289\n",
            "33/33 [==============================] - 2s 16ms/step - loss: 0.4055 - binary_accuracy: 0.8261 - auc_1: 0.9023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "id": "eev9Cd5hPGVa",
        "outputId": "fd0235f2-cb59-4c9a-e9d5-b53af70719a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9527779221534729\n",
            "0.902341365814209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=289:\n",
        "    continue\n",
        "  if i>340:\n",
        "    break\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488c0c1e-ec62-4ca4-b724-d7581944529d",
        "id": "6FmYuyxKZeZx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 290\n",
            "72/72 [==============================] - 3s 13ms/step - loss: 0.3021 - binary_accuracy: 0.8603 - auc: 0.9441\n",
            "Dataset: 291\n",
            "51/51 [==============================] - 3s 14ms/step - loss: 0.4701 - binary_accuracy: 0.7781 - auc_1: 0.8774\n",
            "Dataset: 292\n",
            "41/41 [==============================] - 2s 13ms/step - loss: 0.5359 - binary_accuracy: 0.7543 - auc_2: 0.8526\n",
            "Dataset: 293\n",
            "195/195 [==============================] - 3s 8ms/step - loss: 0.2544 - binary_accuracy: 0.8927 - auc_3: 0.9608\n",
            "Dataset: 294\n",
            "31/31 [==============================] - 2s 12ms/step - loss: 0.5521 - binary_accuracy: 0.7322 - auc_4: 0.8269\n",
            "Dataset: 295\n",
            "66/66 [==============================] - 2s 10ms/step - loss: 0.3135 - binary_accuracy: 0.8567 - auc_5: 0.9401\n",
            "Dataset: 296\n",
            "39/39 [==============================] - 2s 11ms/step - loss: 0.4011 - binary_accuracy: 0.8225 - auc_6: 0.9019\n",
            "Dataset: 297\n",
            "63/63 [==============================] - 2s 10ms/step - loss: 0.3321 - binary_accuracy: 0.8620 - auc_7: 0.9323\n",
            "Dataset: 298\n",
            "122/122 [==============================] - 3s 11ms/step - loss: 0.2915 - binary_accuracy: 0.8794 - auc_8: 0.9479\n",
            "Dataset: 299\n",
            "146/146 [==============================] - 3s 8ms/step - loss: 0.3255 - binary_accuracy: 0.8619 - auc_9: 0.9384\n",
            "Dataset: 300\n",
            "174/174 [==============================] - 3s 8ms/step - loss: 0.5115 - binary_accuracy: 0.7520 - auc_10: 0.8436\n",
            "Dataset: 301\n",
            "27/27 [==============================] - 2s 13ms/step - loss: 0.2737 - binary_accuracy: 0.8847 - auc_11: 0.9532\n",
            "Dataset: 302\n",
            "96/96 [==============================] - 2s 9ms/step - loss: 0.2463 - binary_accuracy: 0.8932 - auc_12: 0.9627\n",
            "Dataset: 303\n",
            "221/221 [==============================] - 3s 7ms/step - loss: 0.3564 - binary_accuracy: 0.8424 - auc_13: 0.9207\n",
            "Dataset: 304\n",
            "192/192 [==============================] - 3s 9ms/step - loss: 0.3318 - binary_accuracy: 0.8548 - auc_14: 0.9329\n",
            "Dataset: 305\n",
            "191/191 [==============================] - 3s 8ms/step - loss: 0.3618 - binary_accuracy: 0.8363 - auc_15: 0.9229\n",
            "Dataset: 306\n",
            "35/35 [==============================] - 2s 10ms/step - loss: 0.2647 - binary_accuracy: 0.8948 - auc_16: 0.9582\n",
            "Dataset: 307\n",
            "147/147 [==============================] - 2s 8ms/step - loss: 0.2054 - binary_accuracy: 0.9217 - auc_17: 0.9758\n",
            "Dataset: 308\n",
            "199/199 [==============================] - 3s 7ms/step - loss: 0.3544 - binary_accuracy: 0.8371 - auc_18: 0.9253\n",
            "Dataset: 309\n",
            "44/44 [==============================] - 2s 13ms/step - loss: 0.3104 - binary_accuracy: 0.8614 - auc_19: 0.9431\n",
            "Dataset: 310\n",
            "37/37 [==============================] - 2s 14ms/step - loss: 0.6473 - binary_accuracy: 0.6853 - auc_20: 0.7797\n",
            "Dataset: 311\n",
            "193/193 [==============================] - 3s 7ms/step - loss: 0.3309 - binary_accuracy: 0.8550 - auc_21: 0.9345\n",
            "Dataset: 312\n",
            "140/140 [==============================] - 2s 8ms/step - loss: 0.2766 - binary_accuracy: 0.8873 - auc_22: 0.9571\n",
            "Dataset: 313\n",
            "211/211 [==============================] - 3s 7ms/step - loss: 0.3472 - binary_accuracy: 0.8437 - auc_23: 0.9301\n",
            "Dataset: 314\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.3308 - binary_accuracy: 0.8568 - auc_24: 0.9334\n",
            "Dataset: 315\n",
            "114/114 [==============================] - 2s 7ms/step - loss: 0.3963 - binary_accuracy: 0.8218 - auc_25: 0.9040\n",
            "Dataset: 316\n",
            "234/234 [==============================] - 3s 7ms/step - loss: 0.4174 - binary_accuracy: 0.8082 - auc_26: 0.8985\n",
            "Dataset: 317\n",
            "96/96 [==============================] - 2s 7ms/step - loss: 0.2935 - binary_accuracy: 0.8756 - auc_27: 0.9471\n",
            "Dataset: 318\n",
            "123/123 [==============================] - 2s 9ms/step - loss: 0.4520 - binary_accuracy: 0.7866 - auc_28: 0.8723\n",
            "Dataset: 319\n",
            "122/122 [==============================] - 2s 7ms/step - loss: 0.3113 - binary_accuracy: 0.8633 - auc_29: 0.9416\n",
            "Dataset: 320\n",
            "54/54 [==============================] - 2s 7ms/step - loss: 0.4934 - binary_accuracy: 0.7733 - auc_30: 0.8715\n",
            "Dataset: 321\n",
            "94/94 [==============================] - 2s 10ms/step - loss: 0.5410 - binary_accuracy: 0.7513 - auc_31: 0.8403\n",
            "Dataset: 322\n",
            "111/111 [==============================] - 2s 7ms/step - loss: 0.4552 - binary_accuracy: 0.7879 - auc_32: 0.8741\n",
            "Dataset: 323\n",
            "201/201 [==============================] - 3s 7ms/step - loss: 0.2912 - binary_accuracy: 0.8664 - auc_33: 0.9501\n",
            "Dataset: 324\n",
            "158/158 [==============================] - 2s 7ms/step - loss: 0.3156 - binary_accuracy: 0.8634 - auc_34: 0.9397\n",
            "Dataset: 325\n",
            "145/145 [==============================] - 2s 7ms/step - loss: 0.2672 - binary_accuracy: 0.8894 - auc_35: 0.9566\n",
            "Dataset: 326\n",
            "129/129 [==============================] - 3s 11ms/step - loss: 0.3646 - binary_accuracy: 0.8356 - auc_36: 0.9216\n",
            "Dataset: 327\n",
            "133/133 [==============================] - 2s 7ms/step - loss: 0.2875 - binary_accuracy: 0.8810 - auc_37: 0.9501\n",
            "Dataset: 328\n",
            "172/172 [==============================] - 3s 7ms/step - loss: 0.4482 - binary_accuracy: 0.7904 - auc_38: 0.8837\n",
            "Dataset: 329\n",
            "42/42 [==============================] - 2s 7ms/step - loss: 0.2582 - binary_accuracy: 0.8831 - auc_39: 0.9589\n",
            "Dataset: 330\n",
            "204/204 [==============================] - 3s 8ms/step - loss: 0.3288 - binary_accuracy: 0.8574 - auc_40: 0.9352\n",
            "Dataset: 331\n",
            "73/73 [==============================] - 2s 7ms/step - loss: 0.3352 - binary_accuracy: 0.8552 - auc_41: 0.9312\n",
            "Dataset: 332\n",
            "75/75 [==============================] - 2s 8ms/step - loss: 0.3867 - binary_accuracy: 0.8252 - auc_42: 0.9079\n",
            "Dataset: 333\n",
            "157/157 [==============================] - 2s 7ms/step - loss: 0.3047 - binary_accuracy: 0.8682 - auc_43: 0.9436\n",
            "Dataset: 334\n",
            "209/209 [==============================] - 3s 9ms/step - loss: 0.3421 - binary_accuracy: 0.8528 - auc_44: 0.9285\n",
            "Dataset: 335\n",
            "204/204 [==============================] - 3s 7ms/step - loss: 0.3297 - binary_accuracy: 0.8528 - auc_45: 0.9332\n",
            "Dataset: 336\n",
            "70/70 [==============================] - 80s 1s/step - loss: 0.3986 - binary_accuracy: 0.8191 - auc_46: 0.9046\n",
            "Dataset: 337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('acc.pkl', 'rb') as file:\n",
        "  avg_acc = pickle.load(file)\n",
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "outputId": "463957a1-4f33-421f-dd73-e08f879b60b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSvwCc9KZeaB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9440526962280273\n",
            "0.8774194717407227\n",
            "0.8526272773742676\n",
            "0.9607831835746765\n",
            "0.8269167542457581\n",
            "0.9401288032531738\n",
            "0.9019421339035034\n",
            "0.9323328733444214\n",
            "0.9479165077209473\n",
            "0.9384163022041321\n",
            "0.843609094619751\n",
            "0.953217089176178\n",
            "0.9627081155776978\n",
            "0.9207045435905457\n",
            "0.9328941702842712\n",
            "0.9229215979576111\n",
            "0.9581671953201294\n",
            "0.9758070707321167\n",
            "0.9253115057945251\n",
            "0.9430683851242065\n",
            "0.7797423601150513\n",
            "0.9345324635505676\n",
            "0.9570850729942322\n",
            "0.9301390051841736\n",
            "0.9333649277687073\n",
            "0.9039618372917175\n",
            "0.8984732031822205\n",
            "0.9470553398132324\n",
            "0.872264564037323\n",
            "0.941552460193634\n",
            "0.8714865446090698\n",
            "0.8403075337409973\n",
            "0.8741443157196045\n",
            "0.9501305818557739\n",
            "0.9396620988845825\n",
            "0.956638514995575\n",
            "0.9216238260269165\n",
            "0.9500912427902222\n",
            "0.8836885690689087\n",
            "0.9588618278503418\n",
            "0.9352270364761353\n",
            "0.9311678409576416\n",
            "0.9079235196113586\n",
            "0.9435986876487732\n",
            "0.9285023808479309\n",
            "0.9332229495048523\n",
            "0.9045760035514832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=336:\n",
        "    continue\n",
        "  if i>340:\n",
        "    break\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe2cf8c-6d37-43d0-ff3d-42503eff305d",
        "id": "2c9NVmJfX0gQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 337\n",
            "33/33 [==============================] - 2s 17ms/step - loss: 0.2215 - binary_accuracy: 0.9179 - auc: 0.9757\n",
            "Dataset: 338\n",
            "29/29 [==============================] - 3s 16ms/step - loss: 0.3018 - binary_accuracy: 0.8830 - auc_1: 0.9445\n",
            "Dataset: 339\n",
            "70/70 [==============================] - 2s 10ms/step - loss: 0.2783 - binary_accuracy: 0.8862 - auc_2: 0.9558\n",
            "Dataset: 340\n",
            "182/182 [==============================] - 3s 8ms/step - loss: 0.3183 - binary_accuracy: 0.8553 - auc_3: 0.9373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "id": "OyLJ9He9Y895",
        "outputId": "142aa979-e1fa-40a7-f699-939dac94f689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9756680130958557\n",
            "0.9444981217384338\n",
            "0.9558305740356445\n",
            "0.9373381733894348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<=340:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac7c7ef-0ae6-4f0a-9531-8b7f2b1c857e",
        "id": "TOia4_VaMcw4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 341\n",
            "130/130 [==============================] - 3s 9ms/step - loss: 0.2906 - binary_accuracy: 0.8774 - auc: 0.9484\n",
            "Dataset: 342\n",
            "74/74 [==============================] - 3s 10ms/step - loss: 0.3678 - binary_accuracy: 0.8364 - auc_1: 0.9194\n",
            "Dataset: 343\n",
            "180/180 [==============================] - 3s 8ms/step - loss: 0.3359 - binary_accuracy: 0.8513 - auc_2: 0.9308\n",
            "Dataset: 344\n",
            "59/59 [==============================] - 2s 14ms/step - loss: 0.2140 - binary_accuracy: 0.9073 - auc_3: 0.9727\n",
            "Dataset: 345\n",
            "144/144 [==============================] - 2s 8ms/step - loss: 0.2703 - binary_accuracy: 0.8834 - auc_4: 0.9556\n",
            "Dataset: 346\n",
            "214/214 [==============================] - 3s 8ms/step - loss: 0.3617 - binary_accuracy: 0.8403 - auc_5: 0.9188\n",
            "Dataset: 347\n",
            "48/48 [==============================] - 2s 12ms/step - loss: 0.4382 - binary_accuracy: 0.7906 - auc_6: 0.8797\n",
            "Dataset: 348\n",
            "149/149 [==============================] - 2s 8ms/step - loss: 0.3666 - binary_accuracy: 0.8351 - auc_7: 0.9159\n",
            "Dataset: 349\n",
            "34/34 [==============================] - 2s 11ms/step - loss: 0.4529 - binary_accuracy: 0.7866 - auc_8: 0.8765\n",
            "Dataset: 350\n",
            "75/75 [==============================] - 2s 8ms/step - loss: 0.2966 - binary_accuracy: 0.8705 - auc_9: 0.9462\n",
            "Dataset: 351\n",
            "50/50 [==============================] - 2s 7ms/step - loss: 0.3053 - binary_accuracy: 0.8694 - auc_10: 0.9438\n",
            "Dataset: 352\n",
            "152/152 [==============================] - 2s 8ms/step - loss: 0.3426 - binary_accuracy: 0.8535 - auc_11: 0.9319\n",
            "Dataset: 353\n",
            "73/73 [==============================] - 2s 9ms/step - loss: 0.2589 - binary_accuracy: 0.8885 - auc_12: 0.9582\n",
            "Dataset: 354\n",
            "33/33 [==============================] - 2s 14ms/step - loss: 0.2116 - binary_accuracy: 0.9133 - auc_13: 0.9761\n",
            "Dataset: 355\n",
            "75/75 [==============================] - 2s 9ms/step - loss: 0.4974 - binary_accuracy: 0.7693 - auc_14: 0.8497\n",
            "Dataset: 356\n",
            "48/48 [==============================] - 2s 8ms/step - loss: 0.4889 - binary_accuracy: 0.7762 - auc_15: 0.8751\n",
            "Dataset: 357\n",
            "76/76 [==============================] - 2s 9ms/step - loss: 0.3176 - binary_accuracy: 0.8579 - auc_16: 0.9396\n",
            "Dataset: 358\n",
            "79/79 [==============================] - 2s 7ms/step - loss: 0.3043 - binary_accuracy: 0.8711 - auc_17: 0.9460\n",
            "Dataset: 359\n",
            "105/105 [==============================] - 2s 8ms/step - loss: 0.2550 - binary_accuracy: 0.9004 - auc_18: 0.9621\n",
            "Dataset: 360\n",
            "197/197 [==============================] - 3s 8ms/step - loss: 0.1843 - binary_accuracy: 0.9283 - auc_19: 0.9801\n",
            "Dataset: 361\n",
            "60/60 [==============================] - 2s 10ms/step - loss: 0.1998 - binary_accuracy: 0.9177 - auc_20: 0.9766\n",
            "Dataset: 362\n",
            "39/39 [==============================] - 2s 8ms/step - loss: 0.2466 - binary_accuracy: 0.9089 - auc_21: 0.9628\n",
            "Dataset: 363\n",
            "49/49 [==============================] - 2s 8ms/step - loss: 0.4444 - binary_accuracy: 0.7886 - auc_22: 0.8819\n",
            "Dataset: 364\n",
            "162/162 [==============================] - 2s 7ms/step - loss: 0.2925 - binary_accuracy: 0.8719 - auc_23: 0.9459\n",
            "Dataset: 365\n",
            "26/26 [==============================] - 1s 8ms/step - loss: 0.3557 - binary_accuracy: 0.8580 - auc_24: 0.9235\n",
            "Dataset: 366\n",
            "224/224 [==============================] - 3s 7ms/step - loss: 0.2852 - binary_accuracy: 0.8789 - auc_25: 0.9505\n",
            "Dataset: 367\n",
            "76/76 [==============================] - 2s 8ms/step - loss: 0.3170 - binary_accuracy: 0.8639 - auc_26: 0.9395\n",
            "Dataset: 368\n",
            "144/144 [==============================] - 2s 7ms/step - loss: 0.3389 - binary_accuracy: 0.8541 - auc_27: 0.9302\n",
            "Dataset: 369\n",
            "202/202 [==============================] - 3s 8ms/step - loss: 0.4091 - binary_accuracy: 0.8149 - auc_28: 0.8995\n",
            "Dataset: 370\n",
            "53/53 [==============================] - 2s 8ms/step - loss: 0.2277 - binary_accuracy: 0.9043 - auc_29: 0.9699\n",
            "Dataset: 371\n",
            "120/120 [==============================] - 2s 9ms/step - loss: 0.2218 - binary_accuracy: 0.9098 - auc_30: 0.9714\n",
            "Dataset: 372\n",
            "150/150 [==============================] - 2s 7ms/step - loss: 0.3846 - binary_accuracy: 0.8209 - auc_31: 0.9117\n",
            "Dataset: 373\n",
            "63/63 [==============================] - 2s 12ms/step - loss: 0.3123 - binary_accuracy: 0.8637 - auc_32: 0.9400\n",
            "Dataset: 374\n",
            "87/87 [==============================] - 2s 7ms/step - loss: 0.3848 - binary_accuracy: 0.8235 - auc_33: 0.9125\n",
            "Dataset: 375\n",
            "46/46 [==============================] - 2s 12ms/step - loss: 0.3111 - binary_accuracy: 0.8704 - auc_34: 0.9441\n",
            "Dataset: 376\n",
            "218/218 [==============================] - 3s 7ms/step - loss: 0.3248 - binary_accuracy: 0.8599 - auc_35: 0.9343\n",
            "Dataset: 377\n",
            "154/154 [==============================] - 3s 12ms/step - loss: 0.2198 - binary_accuracy: 0.9088 - auc_36: 0.9708\n",
            "Dataset: 378\n",
            "214/214 [==============================] - 3s 10ms/step - loss: 0.1832 - binary_accuracy: 0.9326 - auc_37: 0.9808\n",
            "Dataset: 379\n",
            "126/126 [==============================] - 2s 7ms/step - loss: 0.2575 - binary_accuracy: 0.8932 - auc_38: 0.9600\n",
            "Dataset: 380\n",
            "24/24 [==============================] - 1s 8ms/step - loss: 0.2772 - binary_accuracy: 0.8899 - auc_39: 0.9561\n",
            "Dataset: 381\n",
            "72/72 [==============================] - 2s 9ms/step - loss: 0.2897 - binary_accuracy: 0.8752 - auc_40: 0.9486\n",
            "Dataset: 382\n",
            "67/67 [==============================] - 2s 7ms/step - loss: 0.3033 - binary_accuracy: 0.8713 - auc_41: 0.9432\n",
            "Dataset: 383\n",
            "223/223 [==============================] - 3s 8ms/step - loss: 0.2702 - binary_accuracy: 0.8847 - auc_42: 0.9554\n",
            "Dataset: 384\n",
            "158/158 [==============================] - 2s 7ms/step - loss: 0.3504 - binary_accuracy: 0.8431 - auc_43: 0.9254\n",
            "Dataset: 385\n",
            "27/27 [==============================] - 1s 8ms/step - loss: 0.3247 - binary_accuracy: 0.8588 - auc_44: 0.9337\n",
            "Dataset: 386\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 0.2241 - binary_accuracy: 0.9145 - auc_45: 0.9734\n",
            "Dataset: 387\n",
            "55/55 [==============================] - 2s 8ms/step - loss: 0.2502 - binary_accuracy: 0.8951 - auc_46: 0.9621\n",
            "Dataset: 388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('acc.pkl', 'rb') as file:\n",
        "  avg_acc = pickle.load(file)\n",
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "id": "flyBnT_4Jp_E",
        "outputId": "1938f091-9447-4dda-dc1d-b06875c39422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9483782052993774\n",
            "0.9194276928901672\n",
            "0.9308078289031982\n",
            "0.9726541042327881\n",
            "0.9556204080581665\n",
            "0.9187718033790588\n",
            "0.8797110319137573\n",
            "0.9158514142036438\n",
            "0.8764652013778687\n",
            "0.9462387561798096\n",
            "0.9437766075134277\n",
            "0.9319170117378235\n",
            "0.9581570029258728\n",
            "0.9761252403259277\n",
            "0.8497235178947449\n",
            "0.8750702142715454\n",
            "0.9396313428878784\n",
            "0.9459580779075623\n",
            "0.9620512127876282\n",
            "0.9800726771354675\n",
            "0.9765676259994507\n",
            "0.9628422856330872\n",
            "0.8818608522415161\n",
            "0.9459258913993835\n",
            "0.9234911799430847\n",
            "0.9504748582839966\n",
            "0.9395356774330139\n",
            "0.9301621913909912\n",
            "0.899476945400238\n",
            "0.9699118137359619\n",
            "0.971352219581604\n",
            "0.9116626381874084\n",
            "0.9400287866592407\n",
            "0.9124937653541565\n",
            "0.9440792798995972\n",
            "0.9342581033706665\n",
            "0.9707627892494202\n",
            "0.980764627456665\n",
            "0.9600120186805725\n",
            "0.9560553431510925\n",
            "0.948648989200592\n",
            "0.9432477951049805\n",
            "0.9553588628768921\n",
            "0.9253710508346558\n",
            "0.9336678385734558\n",
            "0.973364531993866\n",
            "0.9620975852012634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras.models import load_model\n",
        "i = 0\n",
        "avg_acc = []\n",
        "for train_feature,train_label,test_feature,test_label in zip(train_features,train_labels,test_features,test_labels):\n",
        "  i=i+1\n",
        "  if i<388:\n",
        "    continue\n",
        "  print(\"Dataset:\",i)\n",
        "  CBLANE = load_model(\"CBLANE_medium_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.0001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC(),\n",
        "                                        ]\n",
        "                              )\n",
        "  history = CBLANE.fit(tf.constant(train_feature,dtype=tf.bool),\n",
        "                              tf.constant(train_label,dtype=tf.bool),\n",
        "                              batch_size=4096,\n",
        "                              epochs=30,\n",
        "                              verbose=0,\n",
        "                              validation_split=0.1,\n",
        "                              validation_batch_size=4096,\n",
        "                              callbacks=([reduce_lr,\n",
        "                                          early_stop]))\n",
        "  data = CBLANE.evaluate(test_feature,test_label,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "  with open('acc.pkl', 'wb') as file:\n",
        "    pickle.dump(avg_acc, file)\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a85a4f-ef45-490f-e085-84214b78b899",
        "id": "IjjVJ8jJKu2S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 388\n",
            "198/198 [==============================] - 4s 10ms/step - loss: 0.4095 - binary_accuracy: 0.8118 - auc: 0.8984\n",
            "Dataset: 389\n",
            "60/60 [==============================] - 2s 10ms/step - loss: 0.1889 - binary_accuracy: 0.9212 - auc_1: 0.9799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('acc.pkl', 'rb') as file:\n",
        "  avg_acc = pickle.load(file)\n",
        "for acc in avg_acc:\n",
        "  print(acc)"
      ],
      "metadata": {
        "id": "uM7UNiDpLehI",
        "outputId": "844ce2ce-c32f-48cc-906d-4ac6a4b5d2cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8984125852584839\n",
            "0.9798734784126282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Small Dataset"
      ],
      "metadata": {
        "id": "OC8HM0gNu5ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Fine-Tuning"
      ],
      "metadata": {
        "id": "86BPvM97vArD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SE1AjAONQD3",
        "outputId": "37fddbea-e38f-43b2-e6ea-a4d075fcb269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 1\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3396 - binary_accuracy: 0.8526 - precision: 0.8269 - recall: 0.8699 - auc: 0.9334 - sensitivity_at_specificity: 0.9777 - specificity_at_sensitivity: 0.9801\n",
            "0.9333571791648865\n",
            "iteration 2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3898 - binary_accuracy: 0.8147 - precision: 0.8080 - recall: 0.8080 - auc: 0.9038 - sensitivity_at_specificity: 0.9440 - specificity_at_sensitivity: 0.9851\n",
            "0.9185741245746613\n",
            "iteration 3\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3760 - binary_accuracy: 0.8100 - precision: 0.8361 - recall: 0.7669 - auc: 0.9106 - sensitivity_at_specificity: 0.9693 - specificity_at_sensitivity: 0.9849\n",
            "0.9159220655759176\n",
            "iteration 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7ab40456a200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.4942 - binary_accuracy: 0.7646 - precision: 0.8308 - recall: 0.6486 - auc: 0.8575 - sensitivity_at_specificity: 0.9129 - specificity_at_sensitivity: 0.9402\n",
            "0.9013119041919708\n",
            "iteration 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7ab3cbac8430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.3360 - binary_accuracy: 0.8732 - precision: 0.8727 - recall: 0.8807 - auc: 0.9329 - sensitivity_at_specificity: 0.9358 - specificity_at_sensitivity: 0.9712\n",
            "0.9076321005821228\n",
            "iteration 6\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3472 - binary_accuracy: 0.8463 - precision: 0.8680 - recall: 0.8251 - auc: 0.9233 - sensitivity_at_specificity: 0.9696 - specificity_at_sensitivity: 0.9960\n",
            "0.9102464516957601\n",
            "iteration 7\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4259 - binary_accuracy: 0.8068 - precision: 0.8857 - recall: 0.7045 - auc: 0.8967 - sensitivity_at_specificity: 0.9545 - specificity_at_sensitivity: 0.9773\n",
            "0.908310421875545\n",
            "iteration 8\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5617 - binary_accuracy: 0.7419 - precision: 0.8227 - recall: 0.6013 - auc: 0.8335 - sensitivity_at_specificity: 0.9037 - specificity_at_sensitivity: 0.9333\n",
            "0.8989574015140533\n",
            "iteration 9\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4045 - binary_accuracy: 0.8184 - precision: 0.8571 - recall: 0.7721 - auc: 0.9039 - sensitivity_at_specificity: 0.9596 - specificity_at_sensitivity: 0.9809\n",
            "0.8995057543118795\n",
            "iteration 10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2579 - binary_accuracy: 0.8782 - precision: 0.8898 - recall: 0.8678 - auc: 0.9613 - sensitivity_at_specificity: 0.9917 - specificity_at_sensitivity: 0.9915\n",
            "0.9056878328323364\n",
            "iteration 11\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3527 - binary_accuracy: 0.8580 - precision: 0.8571 - recall: 0.8638 - auc: 0.9299 - sensitivity_at_specificity: 0.9650 - specificity_at_sensitivity: 0.9960\n",
            "0.9078860011967745\n",
            "iteration 12\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3327 - binary_accuracy: 0.8571 - precision: 0.8182 - recall: 0.9474 - auc: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000\n",
            "0.9122726966937383\n",
            "iteration 13\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5728 - binary_accuracy: 0.7381 - precision: 0.7857 - recall: 0.5994 - auc: 0.8160 - sensitivity_at_specificity: 0.9038 - specificity_at_sensitivity: 0.8889\n",
            "0.9048660030731788\n",
            "iteration 14\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4905 - binary_accuracy: 0.7744 - precision: 0.7871 - recall: 0.6737 - auc: 0.8546 - sensitivity_at_specificity: 0.9364 - specificity_at_sensitivity: 0.9324\n",
            "0.9012751281261444\n",
            "iteration 15\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3691 - binary_accuracy: 0.8424 - precision: 0.8610 - recall: 0.7964 - auc: 0.9174 - sensitivity_at_specificity: 0.9679 - specificity_at_sensitivity: 0.9871\n",
            "0.9023533264795939\n",
            "iteration 16\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6349 - binary_accuracy: 0.7107 - precision: 0.7857 - recall: 0.5593 - auc: 0.7500 - sensitivity_at_specificity: 0.8136 - specificity_at_sensitivity: 0.8710\n",
            "0.8928312435746193\n",
            "iteration 17\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6388 - binary_accuracy: 0.6943 - precision: 0.7935 - recall: 0.5491 - auc: 0.7697 - sensitivity_at_specificity: 0.8259 - specificity_at_sensitivity: 0.8863\n",
            "0.8855905918514028\n",
            "iteration 18\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4273 - binary_accuracy: 0.8129 - precision: 0.8750 - recall: 0.7510 - auc: 0.8974 - sensitivity_at_specificity: 0.9540 - specificity_at_sensitivity: 0.9831\n",
            "0.8862473467985789\n",
            "iteration 19\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4097 - binary_accuracy: 0.8355 - precision: 0.8174 - recall: 0.8430 - auc: 0.9027 - sensitivity_at_specificity: 0.9417 - specificity_at_sensitivity: 0.9755\n",
            "0.8871137468438399\n",
            "iteration 20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4509 - binary_accuracy: 0.8091 - precision: 0.8431 - recall: 0.7679 - auc: 0.8885 - sensitivity_at_specificity: 0.9420 - specificity_at_sensitivity: 0.9676\n",
            "0.8871828645467759\n",
            "iteration 21\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3756 - binary_accuracy: 0.8328 - precision: 0.8188 - recall: 0.8443 - auc: 0.9143 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9868\n",
            "0.888475239276886\n",
            "iteration 22\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2838 - binary_accuracy: 0.8893 - precision: 0.8797 - recall: 0.8931 - auc: 0.9510 - sensitivity_at_specificity: 0.9847 - specificity_at_sensitivity: 1.0000\n",
            "0.891318909146569\n",
            "iteration 23\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2656 - binary_accuracy: 0.8992 - precision: 0.9020 - recall: 0.8961 - auc: 0.9564 - sensitivity_at_specificity: 0.9838 - specificity_at_sensitivity: 0.9967\n",
            "0.8941504281500111\n",
            "iteration 24\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3657 - binary_accuracy: 0.8690 - precision: 0.7955 - recall: 0.9459 - auc: 0.9344 - sensitivity_at_specificity: 0.9459 - specificity_at_sensitivity: 0.9787\n",
            "0.8958293745915095\n",
            "iteration 25\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3982 - binary_accuracy: 0.8430 - precision: 0.8599 - recall: 0.8073 - auc: 0.9036 - sensitivity_at_specificity: 0.9572 - specificity_at_sensitivity: 0.9684\n",
            "0.8961392974853516\n",
            "iteration 26\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4013 - binary_accuracy: 0.8095 - precision: 0.8299 - recall: 0.7462 - auc: 0.8981 - sensitivity_at_specificity: 0.9664 - specificity_at_sensitivity: 0.9757\n",
            "0.8962130294396327\n",
            "iteration 27\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2791 - binary_accuracy: 0.8832 - precision: 0.8719 - recall: 0.8867 - auc: 0.9516 - sensitivity_at_specificity: 0.9745 - specificity_at_sensitivity: 1.0000\n",
            "0.89826292903335\n",
            "iteration 28\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3158 - binary_accuracy: 0.8645 - precision: 0.8608 - recall: 0.8514 - auc: 0.9376 - sensitivity_at_specificity: 0.9855 - specificity_at_sensitivity: 0.9967\n",
            "0.8996673056057521\n",
            "iteration 29\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1797 - binary_accuracy: 0.9262 - precision: 0.9044 - recall: 0.9511 - auc: 0.9842 - sensitivity_at_specificity: 0.9973 - specificity_at_sensitivity: 1.0000\n",
            "0.9025814882640181\n",
            "iteration 30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2782 - binary_accuracy: 0.8913 - precision: 0.8800 - recall: 0.9167 - auc: 0.9519 - sensitivity_at_specificity: 0.9583 - specificity_at_sensitivity: 1.0000\n",
            "0.904226815700531\n",
            "iteration 31\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4339 - binary_accuracy: 0.8060 - precision: 0.8266 - recall: 0.7526 - auc: 0.8863 - sensitivity_at_specificity: 0.9632 - specificity_at_sensitivity: 0.9614\n",
            "0.9036492051616791\n",
            "iteration 32\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2875 - binary_accuracy: 0.8889 - precision: 0.8803 - recall: 0.8879 - auc: 0.9505 - sensitivity_at_specificity: 0.9784 - specificity_at_sensitivity: 1.0000\n",
            "0.9051121976226568\n",
            "iteration 33\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5558 - binary_accuracy: 0.7222 - precision: 0.7903 - recall: 0.5698 - auc: 0.8245 - sensitivity_at_specificity: 0.9186 - specificity_at_sensitivity: 0.9043\n",
            "0.9026684345621051\n",
            "iteration 34\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4832 - binary_accuracy: 0.7596 - precision: 0.8270 - recall: 0.6711 - auc: 0.8672 - sensitivity_at_specificity: 0.9298 - specificity_at_sensitivity: 0.9309\n",
            "0.9016263800508836\n",
            "iteration 35\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5725 - binary_accuracy: 0.6753 - precision: 0.7419 - recall: 0.5750 - auc: 0.8017 - sensitivity_at_specificity: 0.8750 - specificity_at_sensitivity: 0.9459\n",
            "0.8987710322652545\n",
            "iteration 36\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4725 - binary_accuracy: 0.8062 - precision: 0.8571 - recall: 0.7368 - auc: 0.8621 - sensitivity_at_specificity: 0.9298 - specificity_at_sensitivity: 0.9469\n",
            "0.8977533148394691\n",
            "iteration 37\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2485 - binary_accuracy: 0.8878 - precision: 0.8528 - recall: 0.9329 - auc: 0.9665 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9935\n",
            "0.8996115584631224\n",
            "iteration 38\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3328 - binary_accuracy: 0.8087 - precision: 0.7917 - recall: 0.7600 - auc: 0.9294 - sensitivity_at_specificity: 0.9800 - specificity_at_sensitivity: 0.9846\n",
            "0.9003950577033194\n",
            "iteration 39\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4774 - binary_accuracy: 0.7811 - precision: 0.8351 - recall: 0.7147 - auc: 0.8635 - sensitivity_at_specificity: 0.9172 - specificity_at_sensitivity: 0.9676\n",
            "0.8994490779363192\n",
            "iteration 40\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4300 - binary_accuracy: 0.8043 - precision: 0.8367 - recall: 0.7707 - auc: 0.8870 - sensitivity_at_specificity: 0.9398 - specificity_at_sensitivity: 0.9720\n",
            "0.8991386026144028\n",
            "iteration 41\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3210 - binary_accuracy: 0.8524 - precision: 0.9130 - recall: 0.7778 - auc: 0.9334 - sensitivity_at_specificity: 0.9704 - specificity_at_sensitivity: 0.9926\n",
            "0.8999752780286278\n",
            "iteration 42\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3070 - binary_accuracy: 0.8925 - precision: 0.8491 - recall: 0.9574 - auc: 0.9572 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9783\n",
            "0.9013381415889377\n",
            "iteration 43\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4622 - binary_accuracy: 0.7878 - precision: 0.8622 - recall: 0.6844 - auc: 0.8848 - sensitivity_at_specificity: 0.9531 - specificity_at_sensitivity: 0.9470\n",
            "0.9009531583896903\n",
            "iteration 44\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3644 - binary_accuracy: 0.8327 - precision: 0.8313 - recall: 0.8054 - auc: 0.9184 - sensitivity_at_specificity: 0.9728 - specificity_at_sensitivity: 0.9898\n",
            "0.9013498479669745\n",
            "iteration 45\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4923 - binary_accuracy: 0.7802 - precision: 0.8673 - recall: 0.7313 - auc: 0.8714 - sensitivity_at_specificity: 0.9328 - specificity_at_sensitivity: 0.9694\n",
            "0.9006839169396295\n",
            "iteration 46\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5302 - binary_accuracy: 0.7541 - precision: 0.8704 - recall: 0.6178 - auc: 0.8590 - sensitivity_at_specificity: 0.9195 - specificity_at_sensitivity: 0.9474\n",
            "0.8997767710167429\n",
            "iteration 47\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4503 - binary_accuracy: 0.7912 - precision: 0.8436 - recall: 0.7428 - auc: 0.8734 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.9634\n",
            "0.899216390670614\n",
            "iteration 48\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4978 - binary_accuracy: 0.7550 - precision: 0.8171 - recall: 0.6634 - auc: 0.8504 - sensitivity_at_specificity: 0.9109 - specificity_at_sensitivity: 0.9293\n",
            "0.898199071486791\n",
            "iteration 49\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4094 - binary_accuracy: 0.8149 - precision: 0.8277 - recall: 0.7912 - auc: 0.8939 - sensitivity_at_specificity: 0.9647 - specificity_at_sensitivity: 0.9855\n",
            "0.8981106609714274\n",
            "iteration 50\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4999 - binary_accuracy: 0.7464 - precision: 0.8073 - recall: 0.6432 - auc: 0.8534 - sensitivity_at_specificity: 0.9336 - specificity_at_sensitivity: 0.9508\n",
            "0.8972158229351044\n",
            "iteration 51\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3157 - binary_accuracy: 0.8542 - precision: 0.8634 - recall: 0.8366 - auc: 0.9360 - sensitivity_at_specificity: 0.9549 - specificity_at_sensitivity: 1.0000\n",
            "0.8979765691009223\n",
            "iteration 52\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2567 - binary_accuracy: 0.8896 - precision: 0.8838 - recall: 0.8920 - auc: 0.9608 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 0.9941\n",
            "0.8991850946958249\n",
            "iteration 53\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2838 - binary_accuracy: 0.8710 - precision: 0.8780 - recall: 0.8372 - auc: 0.9458 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000\n",
            "0.9000648833670706\n",
            "iteration 54\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3455 - binary_accuracy: 0.8479 - precision: 0.8426 - recall: 0.8505 - auc: 0.9210 - sensitivity_at_specificity: 0.9439 - specificity_at_sensitivity: 0.9909\n",
            "0.9004530884601452\n",
            "iteration 55\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6181 - binary_accuracy: 0.6972 - precision: 0.7932 - recall: 0.5687 - auc: 0.7900 - sensitivity_at_specificity: 0.8652 - specificity_at_sensitivity: 0.8732\n",
            "0.8984445604411039\n",
            "iteration 56\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3735 - binary_accuracy: 0.8415 - precision: 0.8140 - recall: 0.8750 - auc: 0.8973 - sensitivity_at_specificity: 0.8750 - specificity_at_sensitivity: 1.0000\n",
            "0.898424502994333\n"
          ]
        }
      ],
      "source": [
        "avg_acc = []\n",
        "i=0\n",
        "for trainset,testset in train_test:\n",
        "  i+=1\n",
        "  print(\"iteration\",i)\n",
        "  train_features = np.unpackbits(trainset[0],axis=2,count=4)\n",
        "  train_labels = np.unpackbits(trainset[1],axis=-1,count=train_features.shape[0])\n",
        "  test_features =  np.unpackbits(testset[0],axis=2,count=4)\n",
        "  test_labels = np.unpackbits(testset[1],axis=-1,count=test_features.shape[0])\n",
        "  CBLANE = load_model(\"CBLANE_small_dataset.keras\")\n",
        "  data = CBLANE.evaluate(test_features,test_labels,verbose=1,batch_size=1024)\n",
        "  avg_acc.append(data[4])\n",
        "  print(np.mean(avg_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning"
      ],
      "metadata": {
        "id": "L0wswARgzMj5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa10078b-aa94-47c4-d581-f1460f35acc0",
        "id": "C8quCq44DW0M"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "741/741 [==============================] - 43s 32ms/step - loss: 0.4211 - binary_accuracy: 0.8013 - precision: 0.8181 - recall: 0.7728 - auc: 0.8854 - sensitivity_at_specificity: 0.9429 - specificity_at_sensitivity: 0.9695 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "741/741 [==============================] - 23s 31ms/step - loss: 0.3845 - binary_accuracy: 0.8221 - precision: 0.8404 - recall: 0.7934 - auc: 0.9052 - sensitivity_at_specificity: 0.9568 - specificity_at_sensitivity: 0.9820 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "741/741 [==============================] - 23s 31ms/step - loss: 0.3597 - binary_accuracy: 0.8353 - precision: 0.8533 - recall: 0.8083 - auc: 0.9175 - sensitivity_at_specificity: 0.9656 - specificity_at_sensitivity: 0.9874 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "741/741 [==============================] - 23s 31ms/step - loss: 0.3370 - binary_accuracy: 0.8479 - precision: 0.8643 - recall: 0.8237 - auc: 0.9280 - sensitivity_at_specificity: 0.9714 - specificity_at_sensitivity: 0.9912 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "741/741 [==============================] - 22s 30ms/step - loss: 0.3102 - binary_accuracy: 0.8629 - precision: 0.8893 - recall: 0.8276 - auc: 0.9402 - sensitivity_at_specificity: 0.9788 - specificity_at_sensitivity: 0.9952 - lr: 1.0000e-06\n",
            "Epoch 6/10\n",
            "741/741 [==============================] - 22s 30ms/step - loss: 0.3093 - binary_accuracy: 0.8633 - precision: 0.8855 - recall: 0.8331 - auc: 0.9401 - sensitivity_at_specificity: 0.9779 - specificity_at_sensitivity: 0.9952 - lr: 1.0000e-06\n",
            "Epoch 7/10\n",
            "741/741 [==============================] - 22s 30ms/step - loss: 0.3090 - binary_accuracy: 0.8630 - precision: 0.8821 - recall: 0.8366 - auc: 0.9400 - sensitivity_at_specificity: 0.9780 - specificity_at_sensitivity: 0.9951 - lr: 1.0000e-06\n",
            "Epoch 8/10\n",
            "741/741 [==============================] - 22s 30ms/step - loss: 0.3081 - binary_accuracy: 0.8636 - precision: 0.8825 - recall: 0.8377 - auc: 0.9403 - sensitivity_at_specificity: 0.9780 - specificity_at_sensitivity: 0.9954 - lr: 1.0000e-08\n",
            "Epoch 9/10\n",
            "741/741 [==============================] - 22s 30ms/step - loss: 0.3071 - binary_accuracy: 0.8645 - precision: 0.8836 - recall: 0.8383 - auc: 0.9409 - sensitivity_at_specificity: 0.9779 - specificity_at_sensitivity: 0.9951 - lr: 1.0000e-08\n",
            "Epoch 10/10\n",
            "741/741 [==============================] - 22s 30ms/step - loss: 0.3076 - binary_accuracy: 0.8641 - precision: 0.8834 - recall: 0.8376 - auc: 0.9406 - sensitivity_at_specificity: 0.9788 - specificity_at_sensitivity: 0.9952 - lr: 1.0000e-08\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "CBLANE = load_model(\"CBLANE.keras\")\n",
        "CBLANE.compile(loss='binary_crossentropy',\n",
        "                             optimizer=Adam(learning_rate=0.0001),\n",
        "                             metrics=[BinaryAccuracy(),\n",
        "                                      Precision(),\n",
        "                                      Recall(),\n",
        "                                      AUC(),\n",
        "                                      SensitivityAtSpecificity(0.5),\n",
        "                                      SpecificityAtSensitivity(0.5),\n",
        "                                      ]\n",
        "                             )\n",
        "history = CBLANE.fit(tf.constant(small_train_features,dtype=tf.bool),\n",
        "                             tf.constant(small_train_labels,dtype=tf.bool),\n",
        "                             batch_size=128,\n",
        "                             epochs=10,\n",
        "                             verbose=1,\n",
        "                            #  validation_split=0.1,\n",
        "                            #  validation_batch_size=4096,\n",
        "                             callbacks=([reduce_lr]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Fine-Tuning"
      ],
      "metadata": {
        "id": "P5lzNACDvFBA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg0dIhbRCBO2",
        "outputId": "34c0208f-edfb-44f4-f0ab-9e215c8eacff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: 1\n",
            "18/18 [==============================] - 2s 7ms/step - loss: 0.3328 - binary_accuracy: 0.8649 - auc_4: 0.9456\n",
            "Dataset: 2\n",
            "9/9 [==============================] - 2s 11ms/step - loss: 0.3224 - binary_accuracy: 0.8456 - auc_5: 0.9328\n",
            "Dataset: 3\n",
            "21/21 [==============================] - 1s 8ms/step - loss: 0.3291 - binary_accuracy: 0.8511 - auc_6: 0.9328\n",
            "Dataset: 4\n",
            "22/22 [==============================] - 1s 7ms/step - loss: 0.5061 - binary_accuracy: 0.7558 - auc_7: 0.8394\n",
            "Dataset: 5\n",
            "7/7 [==============================] - 2s 49ms/step - loss: 0.3345 - binary_accuracy: 0.9108 - auc_8: 0.9586\n",
            "Dataset: 6\n",
            "17/17 [==============================] - 2s 17ms/step - loss: 0.3945 - binary_accuracy: 0.8502 - auc_9: 0.9255\n",
            "Dataset: 7\n",
            "3/3 [==============================] - 1s 127ms/step - loss: 0.4743 - binary_accuracy: 0.7614 - auc_10: 0.8920\n",
            "Dataset: 8\n",
            "20/20 [==============================] - 2s 23ms/step - loss: 0.5171 - binary_accuracy: 0.7500 - auc_11: 0.8337\n",
            "Dataset: 9\n",
            "17/17 [==============================] - 2s 24ms/step - loss: 0.4202 - binary_accuracy: 0.8109 - auc_12: 0.9050\n",
            "Dataset: 10\n",
            "8/8 [==============================] - 2s 41ms/step - loss: 0.2416 - binary_accuracy: 0.9034 - auc_13: 0.9656\n",
            "Dataset: 11\n",
            "16/16 [==============================] - 2s 24ms/step - loss: 0.3361 - binary_accuracy: 0.8817 - auc_14: 0.9437\n",
            "Dataset: 12\n",
            "2/2 [==============================] - 1s 17ms/step - loss: 0.2622 - binary_accuracy: 0.8571 - auc_15: 0.9720\n",
            "Dataset: 13\n",
            "21/21 [==============================] - 2s 10ms/step - loss: 0.5748 - binary_accuracy: 0.7232 - auc_16: 0.8044\n",
            "Dataset: 14\n",
            "17/17 [==============================] - 2s 17ms/step - loss: 0.5240 - binary_accuracy: 0.7669 - auc_17: 0.8464\n",
            "Dataset: 15\n",
            "19/19 [==============================] - 1s 7ms/step - loss: 0.3895 - binary_accuracy: 0.8441 - auc_18: 0.9260\n",
            "Dataset: 16\n",
            "4/4 [==============================] - 1s 65ms/step - loss: 0.6355 - binary_accuracy: 0.6777 - auc_19: 0.7306\n",
            "Dataset: 17\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 0.5929 - binary_accuracy: 0.6989 - auc_20: 0.7554\n",
            "Dataset: 18\n",
            "16/16 [==============================] - 2s 28ms/step - loss: 0.4735 - binary_accuracy: 0.7726 - auc_21: 0.8685\n",
            "Dataset: 19\n",
            "15/15 [==============================] - 1s 9ms/step - loss: 0.4311 - binary_accuracy: 0.8355 - auc_22: 0.9249\n",
            "Dataset: 20\n",
            "14/14 [==============================] - 1s 9ms/step - loss: 0.4608 - binary_accuracy: 0.8182 - auc_23: 0.8943\n",
            "Dataset: 21\n",
            "19/19 [==============================] - 2s 21ms/step - loss: 0.3555 - binary_accuracy: 0.8378 - auc_24: 0.9237\n",
            "Dataset: 22\n",
            "9/9 [==============================] - 2s 38ms/step - loss: 0.3178 - binary_accuracy: 0.8893 - auc_25: 0.9544\n",
            "Dataset: 23\n",
            "20/20 [==============================] - 4s 9ms/step - loss: 0.3170 - binary_accuracy: 0.8894 - auc_26: 0.9606\n",
            "Dataset: 24\n",
            "3/3 [==============================] - 1s 14ms/step - loss: 0.2646 - binary_accuracy: 0.9167 - auc_27: 0.9572\n",
            "Dataset: 25\n",
            "22/22 [==============================] - 1s 7ms/step - loss: 0.4174 - binary_accuracy: 0.8222 - auc_28: 0.9090\n",
            "Dataset: 26\n",
            "22/22 [==============================] - 1s 7ms/step - loss: 0.4185 - binary_accuracy: 0.7994 - auc_29: 0.8868\n",
            "Dataset: 27\n",
            "23/23 [==============================] - 4s 8ms/step - loss: 0.2466 - binary_accuracy: 0.9185 - auc_30: 0.9711\n",
            "Dataset: 28\n",
            "19/19 [==============================] - 2s 11ms/step - loss: 0.3141 - binary_accuracy: 0.8696 - auc_31: 0.9432\n",
            "Dataset: 29\n",
            "24/24 [==============================] - 1s 8ms/step - loss: 0.2987 - binary_accuracy: 0.8980 - auc_32: 0.9750\n",
            "Dataset: 30\n",
            "3/3 [==============================] - 2s 14ms/step - loss: 0.2242 - binary_accuracy: 0.9130 - auc_33: 0.9645\n",
            "Dataset: 31\n",
            "13/13 [==============================] - 1s 9ms/step - loss: 0.4188 - binary_accuracy: 0.8237 - auc_34: 0.9016\n",
            "Dataset: 32\n",
            "16/16 [==============================] - 2s 18ms/step - loss: 0.2613 - binary_accuracy: 0.8971 - auc_35: 0.9590\n",
            "Dataset: 33\n",
            "6/6 [==============================] - 1s 9ms/step - loss: 0.5116 - binary_accuracy: 0.7278 - auc_36: 0.8314\n",
            "Dataset: 34\n",
            "14/14 [==============================] - 2s 24ms/step - loss: 0.4717 - binary_accuracy: 0.7596 - auc_37: 0.8607\n",
            "Dataset: 35\n",
            "3/3 [==============================] - 1s 12ms/step - loss: 0.5774 - binary_accuracy: 0.7013 - auc_38: 0.7946\n",
            "Dataset: 36\n",
            "8/8 [==============================] - 1s 9ms/step - loss: 0.4778 - binary_accuracy: 0.7930 - auc_39: 0.8655\n",
            "Dataset: 37\n",
            "10/10 [==============================] - 1s 8ms/step - loss: 0.3397 - binary_accuracy: 0.9076 - auc_40: 0.9581\n",
            "Dataset: 38\n",
            "4/4 [==============================] - 1s 11ms/step - loss: 0.2760 - binary_accuracy: 0.8609 - auc_41: 0.9466\n",
            "Dataset: 39\n",
            "20/20 [==============================] - 2s 9ms/step - loss: 0.4712 - binary_accuracy: 0.7953 - auc_42: 0.8712\n",
            "Dataset: 40\n",
            "17/17 [==============================] - 2s 22ms/step - loss: 0.4366 - binary_accuracy: 0.8004 - auc_43: 0.8930\n",
            "Dataset: 41\n",
            "9/9 [==============================] - 1s 9ms/step - loss: 0.6459 - binary_accuracy: 0.7565 - auc_44: 0.8777\n",
            "Dataset: 42\n",
            "3/3 [==============================] - 1s 12ms/step - loss: 0.2356 - binary_accuracy: 0.9140 - auc_45: 0.9683\n",
            "Dataset: 43\n",
            "21/21 [==============================] - 1s 8ms/step - loss: 0.4800 - binary_accuracy: 0.7691 - auc_46: 0.8936\n",
            "Dataset: 44\n",
            "18/18 [==============================] - 2s 11ms/step - loss: 0.3475 - binary_accuracy: 0.8418 - auc_47: 0.9269\n",
            "Dataset: 45\n",
            "8/8 [==============================] - 1s 8ms/step - loss: 0.4610 - binary_accuracy: 0.7845 - auc_48: 0.8793\n",
            "Dataset: 46\n",
            "21/21 [==============================] - 1s 7ms/step - loss: 0.4762 - binary_accuracy: 0.7869 - auc_49: 0.8703\n",
            "Dataset: 47\n",
            "17/17 [==============================] - 2s 24ms/step - loss: 0.4778 - binary_accuracy: 0.7701 - auc_50: 0.8616\n",
            "Dataset: 48\n",
            "7/7 [==============================] - 1s 8ms/step - loss: 0.4914 - binary_accuracy: 0.7450 - auc_51: 0.8509\n",
            "Dataset: 49\n",
            "22/22 [==============================] - 2s 9ms/step - loss: 0.4095 - binary_accuracy: 0.7799 - auc_52: 0.8926\n",
            "Dataset: 50\n",
            "16/16 [==============================] - 2s 23ms/step - loss: 0.5043 - binary_accuracy: 0.7567 - auc_53: 0.8328\n",
            "Dataset: 51\n",
            "23/23 [==============================] - 1s 8ms/step - loss: 0.3277 - binary_accuracy: 0.8847 - auc_54: 0.9518\n",
            "Dataset: 52\n",
            "21/21 [==============================] - 1s 7ms/step - loss: 0.2947 - binary_accuracy: 0.8896 - auc_55: 0.9603\n",
            "Dataset: 53\n",
            "3/3 [==============================] - 1s 13ms/step - loss: 0.6664 - binary_accuracy: 0.7097 - auc_56: 0.8998\n",
            "Dataset: 54\n",
            "7/7 [==============================] - 2s 9ms/step - loss: 0.3210 - binary_accuracy: 0.8479 - auc_57: 0.9320\n",
            "Dataset: 55\n",
            "23/23 [==============================] - 1s 8ms/step - loss: 0.5557 - binary_accuracy: 0.7085 - auc_58: 0.7936\n",
            "Dataset: 56\n",
            "3/3 [==============================] - 1s 13ms/step - loss: 0.3240 - binary_accuracy: 0.8537 - auc_59: 0.9146\n",
            "0.9005453969751086\n"
          ]
        }
      ],
      "source": [
        "avg_acc = []\n",
        "i=0\n",
        "\n",
        "for trainset,testset in train_test:\n",
        "  i+=1\n",
        "  print(\"Dataset:\",i)\n",
        "  train_features = np.unpackbits(trainset[0],axis=2,count=4)\n",
        "  train_labels = np.unpackbits(trainset[1],axis=-1,count=train_features.shape[0])\n",
        "  test_features =  np.unpackbits(testset[0],axis=2,count=4)\n",
        "  test_labels = np.unpackbits(testset[1],axis=-1,count=test_features.shape[0])\n",
        "  CBLANE=load_model(\"CBLANE_small_dataset.keras\")\n",
        "  CBLANE.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(learning_rate=0.001),\n",
        "                              metrics=[BinaryAccuracy(),\n",
        "                                        AUC()])\n",
        "  history = CBLANE.fit(tf.constant(train_features,dtype=tf.bool),\n",
        "                   tf.constant(train_labels,dtype=tf.bool),\n",
        "                   batch_size=128,\n",
        "                   epochs=20,\n",
        "                   verbose=0,\n",
        "                   validation_split=0.1,\n",
        "                   callbacks=[reduce_lr,\n",
        "                              early_stop]\n",
        "                         )\n",
        "  data = CBLANE.evaluate(test_features,test_labels,verbose=1)\n",
        "  avg_acc.append(data[2])\n",
        "print(np.mean(avg_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAY1TWgX513p",
        "outputId": "0d8ca827-b1ce-4934-cd4f-a14d1fa60420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9455779790878296\n",
            "0.9328060150146484\n",
            "0.9327787160873413\n",
            "0.839433491230011\n",
            "0.9586274027824402\n",
            "0.9255146980285645\n",
            "0.8920454978942871\n",
            "0.8337130546569824\n",
            "0.905036211013794\n",
            "0.965635359287262\n",
            "0.9437276124954224\n",
            "0.9720394611358643\n",
            "0.8044293522834778\n",
            "0.8463839888572693\n",
            "0.9259503483772278\n",
            "0.7305905222892761\n",
            "0.755374014377594\n",
            "0.8684654831886292\n",
            "0.9248650074005127\n",
            "0.8942936062812805\n",
            "0.9236869812011719\n",
            "0.9544438719749451\n",
            "0.9606000185012817\n",
            "0.9571592807769775\n",
            "0.9089686870574951\n",
            "0.8868129849433899\n",
            "0.9710796475410461\n",
            "0.9432327747344971\n",
            "0.9750210046768188\n",
            "0.964488685131073\n",
            "0.9016019105911255\n",
            "0.958983838558197\n",
            "0.8313953876495361\n",
            "0.8606799840927124\n",
            "0.7945946455001831\n",
            "0.8654711246490479\n",
            "0.9581191539764404\n",
            "0.9466153979301453\n",
            "0.8712252974510193\n",
            "0.8930299878120422\n",
            "0.8776687979698181\n",
            "0.968316376209259\n",
            "0.8935844302177429\n",
            "0.9268602728843689\n",
            "0.879302442073822\n",
            "0.8703249096870422\n",
            "0.8615824580192566\n",
            "0.8509351015090942\n",
            "0.8925833702087402\n",
            "0.8328174948692322\n",
            "0.9518271088600159\n",
            "0.9602565765380859\n",
            "0.8997674584388733\n",
            "0.9319881200790405\n",
            "0.793645441532135\n",
            "0.9145833849906921\n"
          ]
        }
      ],
      "source": []
    }
  ]
}