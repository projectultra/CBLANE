{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b3VNLQAp1nw5",
        "Tn0-1eum4WvE",
        "_fekdO4FD4Jg",
        "KYSxLMRictbV",
        "rVWaUPDe8BBc",
        "TphA8W0F8cHp",
        "J4sO5y7UaYAr",
        "I9j0noDq-f99",
        "d7Hur2BsKard",
        "-pdgkhJFYnNm",
        "2iS8xsfwYi4y"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture"
      ],
      "metadata": {
        "id": "b3VNLQAp1nw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "CBLANE = load_model(\"/content/CBLANE_global_dataset.keras\")"
      ],
      "metadata": {
        "id": "hn5OenWUHcwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv1D, BatchNormalization, LSTM, Flatten, MultiHeadAttention, MaxPooling1D\n",
        "from tensorflow.keras.layers import PReLU, SpatialDropout1D, Bidirectional, Multiply\n",
        "from tensorflow.keras.layers import ZeroPadding1D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_shape_conv = (101, 4)\n",
        "input_layer = Input(shape=input_shape_conv, name='Input_Layer')\n",
        "padding_layer = ZeroPadding1D(padding=3, input_shape=(101,4),name=\"zero_padding_layer\")(input_layer)\n",
        "convolution_layer_1 = Conv1D(filters = 256,kernel_size=8,padding=\"valid\",name='Conv_0')(padding_layer)\n",
        "convolution_layer_1 = PReLU(name='PReLU_0')(convolution_layer_1)\n",
        "convolution_layer_1 = SpatialDropout1D(0.01, name='SpatialDropout_0')(convolution_layer_1)\n",
        "convolution_layer_1 = MaxPooling1D(pool_size=1, name='MaxPooling_0')(convolution_layer_1)\n",
        "convolution_layer_1 = BatchNormalization(name='BatchNormalization_0')(convolution_layer_1)\n",
        "\n",
        "Convolutional_Block_0 = Sequential([Model(inputs=input_layer,outputs=convolution_layer_1)],name='Convolutional_Block_0')\n",
        "\n",
        "convolution_layer_2 = Conv1D(filters=128, kernel_size=4, padding=\"same\", name='Conv_1')(convolution_layer_1)\n",
        "convolution_layer_2 = PReLU(name='PReLU_1')(convolution_layer_2)\n",
        "convolution_layer_2 = SpatialDropout1D(0.01, name='SpatialDropout_1')(convolution_layer_2)\n",
        "convolution_layer_2 = MaxPooling1D(pool_size=1, name='MaxPooling_1')(convolution_layer_2)\n",
        "convolution_layer_2 = BatchNormalization(name='BatchNormalization_1')(convolution_layer_2)\n",
        "\n",
        "Convolutional_Block_1 = Sequential([Model(inputs=convolution_layer_1,outputs=convolution_layer_2)],name='Convolutional_Block_1')\n",
        "\n",
        "convolution_layer_3 = Conv1D(filters=64, kernel_size=2, padding=\"same\", name='Conv_2')(convolution_layer_2)\n",
        "convolution_layer_3 = PReLU(name='PReLU_2')(convolution_layer_3)\n",
        "convolution_layer_3 = SpatialDropout1D(0.01, name='SpatialDropout_2')(convolution_layer_3)\n",
        "convolution_layer_3 = MaxPooling1D(pool_size=2, name='MaxPooling_2')(convolution_layer_3)\n",
        "convolution_layer_3 = BatchNormalization(name='BatchNormalization_2')(convolution_layer_3)\n",
        "\n",
        "Convolutional_Block_2 = Sequential([Model(inputs=convolution_layer_2,outputs=convolution_layer_3)],name='Convolutional_Block_2')\n",
        "\n",
        "convolution_layer_4 = Conv1D(filters=64, kernel_size=2, padding=\"same\", name='Conv_3')(convolution_layer_3)\n",
        "convolution_layer_4 = PReLU(name='PReLU_3')(convolution_layer_4)\n",
        "convolution_layer_4 = SpatialDropout1D(0.01, name='SpatialDropout_3')(convolution_layer_4)\n",
        "convolution_layer_4 = MaxPooling1D(pool_size=2, name='MaxPooling_3')(convolution_layer_4)\n",
        "convolution_layer_4 = BatchNormalization(name='BatchNormalization_3')(convolution_layer_4)\n",
        "\n",
        "Convolutional_Block_3 = Sequential([Model(inputs=convolution_layer_3,outputs=convolution_layer_4)],name='Convolutional_Block_3')\n",
        "\n",
        "Convolutional_Block = Sequential([Convolutional_Block_0,Convolutional_Block_1,Convolutional_Block_2,Convolutional_Block_3],name='Convolutional_Block')\n",
        "\n",
        "Query = Conv1D(filters=64, padding=\"same\", kernel_size=8, name=f'Query')(convolution_layer_4)\n",
        "\n",
        "heads = 8\n",
        "self_attention_layer,attention_scores = MultiHeadAttention(num_heads=heads,key_dim=64,name=f'MultiHeadAttention')(query=Query ,value=convolution_layer_4,return_attention_scores=True)\n",
        "\n",
        "self_attention_layer = Multiply()([self_attention_layer,convolution_layer_4])\n",
        "\n",
        "Attention_Block = Sequential([Model(inputs=convolution_layer_4,outputs=self_attention_layer)],name='Attention_Layer')\n",
        "Attention_scores = Sequential([Model(inputs=input_layer,outputs=attention_scores)],name='Attention_scores')\n",
        "\n",
        "bilstm_layer = Bidirectional(LSTM(64, return_sequences=True), merge_mode=\"sum\", name='Bidirectional_LSTM')(self_attention_layer)\n",
        "lstm_layer = LSTM(64, dropout=0.1, name='LSTM')(bilstm_layer)\n",
        "\n",
        "Recurrent_Block = Sequential([Model(inputs=convolution_layer_4,outputs=lstm_layer)],name='Recurrent_Block')\n",
        "Ensemble = Model(inputs=convolution_layer_4,outputs=lstm_layer)\n",
        "Encoder = Sequential([Convolutional_Block,Ensemble],name='CEBLANE')\n",
        "output_layer = Dense(1, activation=\"sigmoid\", name='finalOutput')(Flatten(name='flattenOutput')(lstm_layer))\n",
        "\n",
        "Output_block = Sequential([Model(inputs=lstm_layer,outputs=output_layer)],name='Output_block')\n",
        "CBLANE = Sequential([Encoder,Output_block],name='CBLANE')"
      ],
      "metadata": {
        "id": "Y3N-Akuc1rBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2LMB1oLrPGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CBLANE.summary(expand_nested=True,show_trainable=True)"
      ],
      "metadata": {
        "id": "lO6ZHV1kYtY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(CBLANE,\n",
        "           to_file=\"Horizontal_model.png\",\n",
        "           show_shapes=True,\n",
        "           show_dtype=True,\n",
        "           show_layer_names=True,\n",
        "           rankdir=\"LR\",\n",
        "           expand_nested=True,\n",
        "           dpi=300,\n",
        "           show_layer_activations=True,\n",
        "           show_trainable=True,\n",
        ")"
      ],
      "metadata": {
        "id": "1403fMpzXsi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(CBLANE,\n",
        "           to_file=\"Vertical_model.png\",\n",
        "           show_shapes=True,\n",
        "           show_dtype=True,\n",
        "           show_layer_names=True,\n",
        "           rankdir=\"TB\",\n",
        "           expand_nested=True,\n",
        "           dpi=300,\n",
        "           show_layer_activations=True,\n",
        "           show_trainable=True,\n",
        ")"
      ],
      "metadata": {
        "id": "3ZaFz1Tj3tQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Tn0-1eum4WvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def save_or_load_numpy(option,file,labels=None,sequences=None):\n",
        "  if option==\"save\":\n",
        "    np.savez(file,labels = labels,sequences = sequences)\n",
        "    return None,None\n",
        "  if option == \"load\":\n",
        "    loaded_array = np.load(file)\n",
        "    sequences = loaded_array['sequences']\n",
        "    labels = loaded_array['labels']\n",
        "    return sequences,labels\n",
        "\n",
        "train_labels,train_features = save_or_load_numpy(\"load\",\"train.npz\")\n",
        "test_labels,test_features = save_or_load_numpy(\"load\",\"test.npz\")\n",
        "validation_labels,validation_features = save_or_load_numpy(\"load\",\"validation.npz\")"
      ],
      "metadata": {
        "id": "253Dlpi99cxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDCv_Fhx83t1"
      },
      "outputs": [],
      "source": [
        "CBLANE.compile(loss='binary_crossentropy',\n",
        "                             optimizer=Adam(learning_rate=0.001),\n",
        "                             metrics=[BinaryAccuracy(),\n",
        "                                      Precision(),\n",
        "                                      Recall(),\n",
        "                                      AUC(),\n",
        "                                      SensitivityAtSpecificity(0.5),\n",
        "                                      SpecificityAtSensitivity(0.5),\n",
        "                                      ]\n",
        "                             )\n",
        "history = CBLANE.fit(tf.constant(train_features,dtype=tf.bool),\n",
        "                                   tf.constant(train_labels,dtype=tf.bool),\n",
        "                                   batch_size=4096,\n",
        "                                   epochs=20,\n",
        "                                   verbose=1,\n",
        "                                   validation_data=(tf.constant(validation_features,dtype = tf.bool),\n",
        "                                                    tf.constant(validation_labels,dtype = tf.bool)),\n",
        "                                   callbacks=([SaveSubModels()]),\n",
        "                                  validation_batch_size=4096)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CBLANE.evaluate(test_features,test_labels,batch_size=4096)"
      ],
      "metadata": {
        "id": "rg8qYv6e9hiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics\n"
      ],
      "metadata": {
        "id": "_fekdO4FD4Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prob = CBLANE.predict(test_features,batch_size=4096)\n",
        "test_pred = (test_prob>0.5).astype(int)"
      ],
      "metadata": {
        "id": "uTF_xSTq_BvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    matthews_corrcoef, cohen_kappa_score,\n",
        "    hamming_loss, roc_auc_score,brier_score_loss, jaccard_score,\n",
        "    average_precision_score,\n",
        ")\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(test_labels, test_pred)  # Accuracy\n",
        "f1 = f1_score(test_labels, test_pred)  # F1 Score\n",
        "precision = precision_score(test_labels, test_pred)  # Precision\n",
        "recall = recall_score(test_labels, test_pred)  # Recall\n",
        "matthews_corr = matthews_corrcoef(test_labels, test_pred)  # Matthews Correlation Coefficient\n",
        "hamming = hamming_loss(test_labels, test_pred)  # Hamming Loss\n",
        "auc = roc_auc_score(test_labels, test_prob)  # ROC AUC Score\n",
        "auc_pr = average_precision_score(test_labels, test_prob) # PR AUC Score\n",
        "brier_score = brier_score_loss(test_labels, test_prob) # Brier Score Loss\n",
        "jacc_score = jaccard_score(test_labels,test_pred) # Jaccard Score\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1-score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Matthews Correlation Coefficient: {matthews_corr:.4f}')\n",
        "print(f'Hamming Loss: {hamming:.4f}')\n",
        "print(f'ROC AUC: {auc:.4f}')\n",
        "print(f'PR AUC: {auc_pr:.4f}')\n",
        "print(f'Brier Score Loss: {brier_score:.4f}')\n",
        "print(f'Jaccard Score: {jacc_score:.4f}')"
      ],
      "metadata": {
        "id": "IkcxU7K0-7Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Display confusion matrix\n",
        "confusion_mat = confusion_matrix(test_labels, test_pred)\n",
        "\n",
        "#Convert to percentage labels\n",
        "row_sums = confusion_mat.sum()\n",
        "confusion_mat_percentage = confusion_mat / row_sums * 100\n",
        "\n",
        "# Display the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat_percentage, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TGn1-vRGDrkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "validation_prob = CBLANE.predict(validation_features,batch_size=1024)\n",
        "validation_pred = (validation_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics for testing and validation sets\n",
        "metrics = {\n",
        "    'Accuracy': [accuracy_score(test_labels, test_pred), accuracy_score(validation_labels, validation_pred)],\n",
        "    'Precision': [precision_score(test_labels, test_pred), precision_score(validation_labels, validation_pred)],\n",
        "    'Recall': [recall_score(test_labels, test_pred), recall_score(validation_labels, validation_pred)],\n",
        "    'F1-Score': [f1_score(test_labels, test_pred), f1_score(validation_labels, validation_pred)],\n",
        "    'ROC AUC': [roc_auc_score(test_labels, test_prob), roc_auc_score(validation_labels, validation_prob)],\n",
        "}\n",
        "\n",
        "# Create a DataFrame for Plotly bar graph\n",
        "data = {\n",
        "    'Metric': [],\n",
        "    'Set': [],\n",
        "    'Score': [],\n",
        "}\n",
        "\n",
        "for metric, scores in metrics.items():\n",
        "    data['Metric'].extend([metric] * 2)\n",
        "    data['Set'].extend(['Testing', 'Validation'])\n",
        "    data['Score'].extend(scores)\n",
        "\n",
        "# Create bar graph using Plotly Express with grouped bars\n",
        "fig_bar = px.bar(\n",
        "    data, x='Metric', y='Score', color='Set', barmode='group',\n",
        "    labels={'Metric': 'Metrics', 'Score': 'Score'}\n",
        ")\n",
        "fig_bar.update_layout(title='Metric Scores for Testing and Validation Sets',\n",
        "                      xaxis={'categoryorder': 'total descending'},\n",
        "                      yaxis=dict(range=[0, 1]),  # Set y-axis range from 0 to 1\n",
        "                      width=1000,\n",
        "                      height=600)\n",
        "fig_bar.update_yaxes(type='linear')\n",
        "\n",
        "# Show the bar graph\n",
        "fig_bar.show()\n",
        "\n",
        "# Save the bar graph as an HTML file\n",
        "fig_bar.write_html(\"metric_scores.html\")"
      ],
      "metadata": {
        "id": "6epP90dACHQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(test_labels, test_prob)\n",
        "precision, recall, thresholds = precision_recall_curve(test_labels, test_prob)\n",
        "\n",
        "fig = px.area(\n",
        "    x=recall, y=precision,\n",
        "    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n",
        "    labels=dict(x='Recall', y='Precision'),\n",
        "    width=700, height=700\n",
        ")\n",
        "fig.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=1, y1=0\n",
        ")\n",
        "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "fig.update_xaxes(constrain='domain')\n",
        "\n",
        "fig.show()\n",
        "\n",
        "fig.write_html(\"PR.html\", auto_open=False)"
      ],
      "metadata": {
        "id": "20_23IkVFoEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.area(\n",
        "    x=fpr, y=tpr,\n",
        "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
        "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
        "    width=700, height=700\n",
        ")\n",
        "fig.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "\n",
        "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "fig.update_xaxes(constrain='domain')\n",
        "fig.show()\n",
        "fig.write_html(\"ROC.html\", auto_open=False)"
      ],
      "metadata": {
        "id": "w5EiB91_GbIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Cell Line Dataset"
      ],
      "metadata": {
        "id": "KYSxLMRictbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A549 Cell Line Dataset"
      ],
      "metadata": {
        "id": "rVWaUPDe8BBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the data\n",
        "loaded_data = np.load('a549.npz')\n",
        "\n",
        "# Extract the arrays\n",
        "train_sequences = loaded_data['train_sequences']\n",
        "train_labels = loaded_data['train_labels']\n",
        "test_sequences = loaded_data['test_sequences']\n",
        "test_labels = loaded_data['test_labels']\n",
        "validation_sequences = loaded_data['validation_sequences']\n",
        "validation_labels = loaded_data['validation_labels']\n",
        "\n",
        "# Optionally, you can print the shapes of the loaded arrays\n",
        "print(\"Train Sequences Shape:\", train_sequences.shape)\n",
        "print(\"Train Labels Shape:\", train_labels.shape)\n",
        "print(\"Test Sequences Shape:\", test_sequences.shape)\n",
        "print(\"Test Labels Shape:\", test_labels.shape)\n",
        "print(\"Validation Sequences Shape:\", validation_sequences.shape)\n",
        "print(\"Validation Labels Shape:\", validation_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Nu31LSv-dy",
        "outputId": "dc0f0a32-e8e4-4333-9224-f15cb115d47e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sequences Shape: (735370, 101, 4)\n",
            "Train Labels Shape: (735370,)\n",
            "Test Sequences Shape: (229822, 101, 4)\n",
            "Test Labels Shape: (229822,)\n",
            "Validation Sequences Shape: (183842, 101, 4)\n",
            "Validation Labels Shape: (183842,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "import os\n",
        "from keras.models import save_model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',mode=\"min\", factor=0.1, patience=2, min_lr=1e-20)\n",
        "early_stop = EarlyStopping(monitor='val_loss',mode=\"min\", patience=10, restore_best_weights=True)\n",
        "\n",
        "class SaveSubModels(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        model_directories = [f'model/{epoch}/CBLANE_A549.keras']\n",
        "\n",
        "        for directory in set(os.path.dirname(model_path) for model_path in model_directories):\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "        save_model(CBLANE, model_directories[0])"
      ],
      "metadata": {
        "id": "-tYUtGIix5lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import BinaryAccuracy, Precision, Recall, AUC, SensitivityAtSpecificity, SpecificityAtSensitivity\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "CBLANE = load_model(\"CBLANE_global_dataset.keras\")\n",
        "\n",
        "CBLANE.compile(loss='binary_crossentropy',\n",
        "                             optimizer=Adam(learning_rate=0.0001),\n",
        "                             metrics=[BinaryAccuracy(),\n",
        "                                      Precision(),\n",
        "                                      Recall(),\n",
        "                                      AUC(),\n",
        "                                      SensitivityAtSpecificity(0.5),\n",
        "                                      SpecificityAtSensitivity(0.5),\n",
        "                                      ]\n",
        "                             )\n",
        "history = CBLANE.fit(tf.constant(train_sequences,dtype=tf.bool),\n",
        "                                   tf.constant(train_labels,dtype=tf.bool),\n",
        "                                   batch_size=128,\n",
        "                                   epochs=20,\n",
        "                                   verbose=1,\n",
        "                                   validation_data=(tf.constant(validation_sequences,dtype = tf.bool),\n",
        "                                                    tf.constant(validation_labels,dtype = tf.bool)),\n",
        "                                  validation_batch_size=4096,\n",
        "                                  callbacks=[reduce_lr,\n",
        "                                             SaveSubModels()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b4defb-29be-4551-c3ad-700bb05fda92",
        "id": "ISaD1Nb0DY0r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5746/5746 [==============================] - 215s 34ms/step - loss: 0.3151 - binary_accuracy: 0.8630 - precision: 0.8790 - recall: 0.8422 - auc: 0.9379 - sensitivity_at_specificity: 0.9770 - specificity_at_sensitivity: 0.9915 - val_loss: 0.2980 - val_binary_accuracy: 0.8712 - val_precision: 0.8835 - val_recall: 0.8546 - val_auc: 0.9447 - val_sensitivity_at_specificity: 0.9812 - val_specificity_at_sensitivity: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 2/20\n",
            "5746/5746 [==============================] - 176s 31ms/step - loss: 0.2994 - binary_accuracy: 0.8713 - precision: 0.8869 - recall: 0.8515 - auc: 0.9440 - sensitivity_at_specificity: 0.9795 - specificity_at_sensitivity: 0.9940 - val_loss: 0.2927 - val_binary_accuracy: 0.8739 - val_precision: 0.8888 - val_recall: 0.8542 - val_auc: 0.9466 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9947 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "5746/5746 [==============================] - 175s 30ms/step - loss: 0.2897 - binary_accuracy: 0.8762 - precision: 0.8914 - recall: 0.8569 - auc: 0.9476 - sensitivity_at_specificity: 0.9822 - specificity_at_sensitivity: 0.9947 - val_loss: 0.2903 - val_binary_accuracy: 0.8745 - val_precision: 0.8935 - val_recall: 0.8497 - val_auc: 0.9475 - val_sensitivity_at_specificity: 0.9823 - val_specificity_at_sensitivity: 0.9946 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "5746/5746 [==============================] - 173s 30ms/step - loss: 0.2823 - binary_accuracy: 0.8796 - precision: 0.8947 - recall: 0.8608 - auc: 0.9503 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9953 - val_loss: 0.2894 - val_binary_accuracy: 0.8754 - val_precision: 0.8939 - val_recall: 0.8513 - val_auc: 0.9479 - val_sensitivity_at_specificity: 0.9817 - val_specificity_at_sensitivity: 0.9952 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "5746/5746 [==============================] - 172s 30ms/step - loss: 0.2757 - binary_accuracy: 0.8829 - precision: 0.8977 - recall: 0.8646 - auc: 0.9526 - sensitivity_at_specificity: 0.9846 - specificity_at_sensitivity: 0.9952 - val_loss: 0.2885 - val_binary_accuracy: 0.8764 - val_precision: 0.8934 - val_recall: 0.8541 - val_auc: 0.9483 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9951 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "5746/5746 [==============================] - 173s 30ms/step - loss: 0.2694 - binary_accuracy: 0.8862 - precision: 0.9002 - recall: 0.8690 - auc: 0.9547 - sensitivity_at_specificity: 0.9844 - specificity_at_sensitivity: 0.9960 - val_loss: 0.2901 - val_binary_accuracy: 0.8756 - val_precision: 0.9013 - val_recall: 0.8428 - val_auc: 0.9483 - val_sensitivity_at_specificity: 0.9822 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "5746/5746 [==============================] - 172s 30ms/step - loss: 0.2638 - binary_accuracy: 0.8889 - precision: 0.9025 - recall: 0.8722 - auc: 0.9567 - sensitivity_at_specificity: 0.9858 - specificity_at_sensitivity: 0.9960 - val_loss: 0.2910 - val_binary_accuracy: 0.8762 - val_precision: 0.8974 - val_recall: 0.8488 - val_auc: 0.9483 - val_sensitivity_at_specificity: 0.9810 - val_specificity_at_sensitivity: 0.9950 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "5746/5746 [==============================] - 173s 30ms/step - loss: 0.2552 - binary_accuracy: 0.8931 - precision: 0.9065 - recall: 0.8768 - auc: 0.9594 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9966 - val_loss: 0.2905 - val_binary_accuracy: 0.8764 - val_precision: 0.8908 - val_recall: 0.8573 - val_auc: 0.9484 - val_sensitivity_at_specificity: 0.9823 - val_specificity_at_sensitivity: 0.9951 - lr: 1.0000e-05\n",
            "Epoch 9/20\n",
            "5746/5746 [==============================] - 172s 30ms/step - loss: 0.2538 - binary_accuracy: 0.8936 - precision: 0.9067 - recall: 0.8777 - auc: 0.9598 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9967 - val_loss: 0.2907 - val_binary_accuracy: 0.8764 - val_precision: 0.8893 - val_recall: 0.8592 - val_auc: 0.9484 - val_sensitivity_at_specificity: 0.9828 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-05\n",
            "Epoch 10/20\n",
            "5746/5746 [==============================] - 174s 30ms/step - loss: 0.2529 - binary_accuracy: 0.8941 - precision: 0.9069 - recall: 0.8785 - auc: 0.9601 - sensitivity_at_specificity: 0.9869 - specificity_at_sensitivity: 0.9966 - val_loss: 0.2909 - val_binary_accuracy: 0.8765 - val_precision: 0.8898 - val_recall: 0.8587 - val_auc: 0.9484 - val_sensitivity_at_specificity: 0.9823 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-06\n",
            "Epoch 11/20\n",
            "5746/5746 [==============================] - 176s 31ms/step - loss: 0.2529 - binary_accuracy: 0.8940 - precision: 0.9070 - recall: 0.8784 - auc: 0.9601 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9966 - val_loss: 0.2911 - val_binary_accuracy: 0.8764 - val_precision: 0.8920 - val_recall: 0.8559 - val_auc: 0.9484 - val_sensitivity_at_specificity: 0.9819 - val_specificity_at_sensitivity: 0.9950 - lr: 1.0000e-06\n",
            "Epoch 12/20\n",
            "5746/5746 [==============================] - 176s 31ms/step - loss: 0.2523 - binary_accuracy: 0.8943 - precision: 0.9072 - recall: 0.8787 - auc: 0.9603 - sensitivity_at_specificity: 0.9869 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2910 - val_binary_accuracy: 0.8766 - val_precision: 0.8927 - val_recall: 0.8554 - val_auc: 0.9484 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9951 - lr: 1.0000e-07\n",
            "Epoch 13/20\n",
            "5746/5746 [==============================] - 175s 31ms/step - loss: 0.2529 - binary_accuracy: 0.8943 - precision: 0.9074 - recall: 0.8784 - auc: 0.9601 - sensitivity_at_specificity: 0.9869 - specificity_at_sensitivity: 0.9972 - val_loss: 0.2911 - val_binary_accuracy: 0.8764 - val_precision: 0.8919 - val_recall: 0.8561 - val_auc: 0.9483 - val_sensitivity_at_specificity: 0.9819 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-07\n",
            "Epoch 14/20\n",
            "5746/5746 [==============================] - 175s 31ms/step - loss: 0.2530 - binary_accuracy: 0.8940 - precision: 0.9070 - recall: 0.8782 - auc: 0.9600 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2910 - val_binary_accuracy: 0.8766 - val_precision: 0.8912 - val_recall: 0.8573 - val_auc: 0.9484 - val_sensitivity_at_specificity: 0.9821 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-08\n",
            "Epoch 15/20\n",
            "5746/5746 [==============================] - 175s 30ms/step - loss: 0.2525 - binary_accuracy: 0.8943 - precision: 0.9075 - recall: 0.8785 - auc: 0.9602 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9972 - val_loss: 0.2911 - val_binary_accuracy: 0.8765 - val_precision: 0.8905 - val_recall: 0.8581 - val_auc: 0.9483 - val_sensitivity_at_specificity: 0.9822 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-08\n",
            "Epoch 16/20\n",
            "5746/5746 [==============================] - 173s 30ms/step - loss: 0.2527 - binary_accuracy: 0.8940 - precision: 0.9072 - recall: 0.8780 - auc: 0.9602 - sensitivity_at_specificity: 0.9870 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2910 - val_binary_accuracy: 0.8765 - val_precision: 0.8897 - val_recall: 0.8590 - val_auc: 0.9483 - val_sensitivity_at_specificity: 0.9825 - val_specificity_at_sensitivity: 0.9947 - lr: 1.0000e-09\n",
            "Epoch 17/20\n",
            "5746/5746 [==============================] - 175s 30ms/step - loss: 0.2529 - binary_accuracy: 0.8939 - precision: 0.9070 - recall: 0.8781 - auc: 0.9601 - sensitivity_at_specificity: 0.9869 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2911 - val_binary_accuracy: 0.8765 - val_precision: 0.8917 - val_recall: 0.8565 - val_auc: 0.9483 - val_sensitivity_at_specificity: 0.9820 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-09\n",
            "Epoch 18/20\n",
            "5746/5746 [==============================] - 175s 30ms/step - loss: 0.2527 - binary_accuracy: 0.8943 - precision: 0.9073 - recall: 0.8786 - auc: 0.9602 - sensitivity_at_specificity: 0.9869 - specificity_at_sensitivity: 0.9972 - val_loss: 0.2912 - val_binary_accuracy: 0.8765 - val_precision: 0.8910 - val_recall: 0.8573 - val_auc: 0.9483 - val_sensitivity_at_specificity: 0.9821 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-10\n",
            "Epoch 19/20\n",
            "5746/5746 [==============================] - 175s 30ms/step - loss: 0.2526 - binary_accuracy: 0.8942 - precision: 0.9073 - recall: 0.8785 - auc: 0.9602 - sensitivity_at_specificity: 0.9871 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2910 - val_binary_accuracy: 0.8765 - val_precision: 0.8904 - val_recall: 0.8581 - val_auc: 0.9484 - val_sensitivity_at_specificity: 0.9822 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-10\n",
            "Epoch 20/20\n",
            "5746/5746 [==============================] - 173s 30ms/step - loss: 0.2524 - binary_accuracy: 0.8942 - precision: 0.9074 - recall: 0.8782 - auc: 0.9602 - sensitivity_at_specificity: 0.9869 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2911 - val_binary_accuracy: 0.8766 - val_precision: 0.8911 - val_recall: 0.8574 - val_auc: 0.9484 - val_sensitivity_at_specificity: 0.9820 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "CBLANE = load_model(\"/content/global_A549.keras\")\n",
        "CBLANE.evaluate(test_sequences,test_labels,batch_size=4096)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymY7_dUIUElT",
        "outputId": "66879e8c-b370-49d9-e7a4-aca867bab6b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 20s 197ms/step - loss: 0.2940 - binary_accuracy: 0.8761 - precision: 0.8916 - recall: 0.8558 - auc: 0.9472 - sensitivity_at_specificity: 0.9815 - specificity_at_sensitivity: 0.9939\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2939949035644531,\n",
              " 0.8760606050491333,\n",
              " 0.891639232635498,\n",
              " 0.8558421730995178,\n",
              " 0.9472177624702454,\n",
              " 0.9815119504928589,\n",
              " 0.9939241409301758]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Huvec Cell Line Dataset"
      ],
      "metadata": {
        "id": "TphA8W0F8cHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the data\n",
        "loaded_data = np.load('huvec.npz')\n",
        "\n",
        "# Extract the arrays\n",
        "train_sequences = loaded_data['train_sequences']\n",
        "train_labels = loaded_data['train_labels']\n",
        "test_sequences = loaded_data['test_sequences']\n",
        "test_labels = loaded_data['test_labels']\n",
        "validation_sequences = loaded_data['validation_sequences']\n",
        "validation_labels = loaded_data['validation_labels']\n",
        "\n",
        "# Optionally, you can print the shapes of the loaded arrays\n",
        "print(\"Train Sequences Shape:\", train_sequences.shape)\n",
        "print(\"Train Labels Shape:\", train_labels.shape)\n",
        "print(\"Test Sequences Shape:\", test_sequences.shape)\n",
        "print(\"Test Labels Shape:\", test_labels.shape)\n",
        "print(\"Validation Sequences Shape:\", validation_sequences.shape)\n",
        "print(\"Validation Labels Shape:\", validation_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1800c4c1-29fd-42d8-de30-98135aeaf265",
        "id": "EDoMz9Aa7fWH"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sequences Shape: (409395, 101, 4)\n",
            "Train Labels Shape: (409395,)\n",
            "Test Sequences Shape: (127941, 101, 4)\n",
            "Test Labels Shape: (127941,)\n",
            "Validation Sequences Shape: (102348, 101, 4)\n",
            "Validation Labels Shape: (102348,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "import os\n",
        "from keras.models import save_model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',mode=\"min\", factor=0.1, patience=2, min_lr=1e-20)\n",
        "early_stop = EarlyStopping(monitor='val_loss',mode=\"min\", patience=10, restore_best_weights=True)\n",
        "\n",
        "class SaveSubModels(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        model_directories = [f'model/{epoch}/CBLANE_A549.keras']\n",
        "\n",
        "        for directory in set(os.path.dirname(model_path) for model_path in model_directories):\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "        save_model(CBLANE, model_directories[0])"
      ],
      "metadata": {
        "id": "Semgpe44p76B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import BinaryAccuracy, Precision, Recall, AUC, SensitivityAtSpecificity, SpecificityAtSensitivity\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "CBLANE = load_model(\"CBLANE_global_dataset.keras\")\n",
        "CBLANE.compile(loss='binary_crossentropy',\n",
        "                             optimizer=Adam(learning_rate=0.0001),\n",
        "                             metrics=[BinaryAccuracy(),\n",
        "                                      Precision(),\n",
        "                                      Recall(),\n",
        "                                      AUC(),\n",
        "                                      SensitivityAtSpecificity(0.5),\n",
        "                                      SpecificityAtSensitivity(0.5),\n",
        "                                      ]\n",
        "                             )\n",
        "history = CBLANE.fit(tf.constant(train_sequences,dtype=tf.bool),\n",
        "                                   tf.constant(train_labels,dtype=tf.bool),\n",
        "                                   batch_size=128,\n",
        "                                   epochs=20,\n",
        "                                   verbose=1,\n",
        "                                   validation_data=(tf.constant(validation_sequences,dtype = tf.bool),\n",
        "                                                    tf.constant(validation_labels,dtype = tf.bool)),\n",
        "                                  validation_batch_size=4096,\n",
        "                                  callbacks=[reduce_lr,SaveSubModels()],\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e249081f-f099-413f-ef51-6d3443fe60e4",
        "id": "2jvmzKDvNA40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3199/3199 [==============================] - 124s 33ms/step - loss: 0.3035 - binary_accuracy: 0.8705 - precision: 0.8860 - recall: 0.8505 - auc: 0.9424 - sensitivity_at_specificity: 0.9773 - specificity_at_sensitivity: 0.9934 - val_loss: 0.2910 - val_binary_accuracy: 0.8772 - val_precision: 0.8954 - val_recall: 0.8544 - val_auc: 0.9471 - val_sensitivity_at_specificity: 0.9792 - val_specificity_at_sensitivity: 0.9937 - lr: 1.0000e-04\n",
            "Epoch 2/20\n",
            "3199/3199 [==============================] - 99s 31ms/step - loss: 0.2870 - binary_accuracy: 0.8783 - precision: 0.8941 - recall: 0.8583 - auc: 0.9484 - sensitivity_at_specificity: 0.9812 - specificity_at_sensitivity: 0.9946 - val_loss: 0.2873 - val_binary_accuracy: 0.8791 - val_precision: 0.8977 - val_recall: 0.8558 - val_auc: 0.9485 - val_sensitivity_at_specificity: 0.9812 - val_specificity_at_sensitivity: 0.9945 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2781 - binary_accuracy: 0.8831 - precision: 0.8981 - recall: 0.8642 - auc: 0.9516 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9953 - val_loss: 0.2860 - val_binary_accuracy: 0.8802 - val_precision: 0.9013 - val_recall: 0.8540 - val_auc: 0.9492 - val_sensitivity_at_specificity: 0.9803 - val_specificity_at_sensitivity: 0.9944 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2703 - binary_accuracy: 0.8867 - precision: 0.9012 - recall: 0.8686 - auc: 0.9542 - sensitivity_at_specificity: 0.9841 - specificity_at_sensitivity: 0.9959 - val_loss: 0.2843 - val_binary_accuracy: 0.8807 - val_precision: 0.8956 - val_recall: 0.8619 - val_auc: 0.9496 - val_sensitivity_at_specificity: 0.9811 - val_specificity_at_sensitivity: 0.9943 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "3199/3199 [==============================] - 94s 30ms/step - loss: 0.2634 - binary_accuracy: 0.8902 - precision: 0.9047 - recall: 0.8724 - auc: 0.9565 - sensitivity_at_specificity: 0.9841 - specificity_at_sensitivity: 0.9966 - val_loss: 0.2847 - val_binary_accuracy: 0.8814 - val_precision: 0.8921 - val_recall: 0.8680 - val_auc: 0.9498 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9943 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2571 - binary_accuracy: 0.8931 - precision: 0.9069 - recall: 0.8761 - auc: 0.9585 - sensitivity_at_specificity: 0.9856 - specificity_at_sensitivity: 0.9967 - val_loss: 0.2859 - val_binary_accuracy: 0.8814 - val_precision: 0.8953 - val_recall: 0.8641 - val_auc: 0.9496 - val_sensitivity_at_specificity: 0.9809 - val_specificity_at_sensitivity: 0.9944 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2485 - binary_accuracy: 0.8975 - precision: 0.9113 - recall: 0.8808 - auc: 0.9612 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9974 - val_loss: 0.2864 - val_binary_accuracy: 0.8816 - val_precision: 0.8968 - val_recall: 0.8626 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9814 - val_specificity_at_sensitivity: 0.9942 - lr: 1.0000e-05\n",
            "Epoch 8/20\n",
            "3199/3199 [==============================] - 94s 30ms/step - loss: 0.2476 - binary_accuracy: 0.8977 - precision: 0.9116 - recall: 0.8809 - auc: 0.9615 - sensitivity_at_specificity: 0.9865 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2865 - val_binary_accuracy: 0.8815 - val_precision: 0.8945 - val_recall: 0.8652 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9823 - val_specificity_at_sensitivity: 0.9940 - lr: 1.0000e-05\n",
            "Epoch 9/20\n",
            "3199/3199 [==============================] - 94s 29ms/step - loss: 0.2466 - binary_accuracy: 0.8984 - precision: 0.9116 - recall: 0.8824 - auc: 0.9618 - sensitivity_at_specificity: 0.9870 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2867 - val_binary_accuracy: 0.8815 - val_precision: 0.8951 - val_recall: 0.8644 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9939 - lr: 1.0000e-06\n",
            "Epoch 10/20\n",
            "3199/3199 [==============================] - 94s 29ms/step - loss: 0.2468 - binary_accuracy: 0.8985 - precision: 0.9122 - recall: 0.8820 - auc: 0.9617 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.9974 - val_loss: 0.2867 - val_binary_accuracy: 0.8815 - val_precision: 0.8962 - val_recall: 0.8631 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9815 - val_specificity_at_sensitivity: 0.9941 - lr: 1.0000e-06\n",
            "Epoch 11/20\n",
            "3199/3199 [==============================] - 94s 29ms/step - loss: 0.2467 - binary_accuracy: 0.8983 - precision: 0.9120 - recall: 0.8816 - auc: 0.9618 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9974 - val_loss: 0.2869 - val_binary_accuracy: 0.8813 - val_precision: 0.8949 - val_recall: 0.8644 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9939 - lr: 1.0000e-07\n",
            "Epoch 12/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2460 - binary_accuracy: 0.8987 - precision: 0.9121 - recall: 0.8824 - auc: 0.9620 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9974 - val_loss: 0.2868 - val_binary_accuracy: 0.8815 - val_precision: 0.8948 - val_recall: 0.8648 - val_auc: 0.9496 - val_sensitivity_at_specificity: 0.9819 - val_specificity_at_sensitivity: 0.9939 - lr: 1.0000e-07\n",
            "Epoch 13/20\n",
            "3199/3199 [==============================] - 96s 30ms/step - loss: 0.2461 - binary_accuracy: 0.8986 - precision: 0.9122 - recall: 0.8821 - auc: 0.9619 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2869 - val_binary_accuracy: 0.8814 - val_precision: 0.8959 - val_recall: 0.8633 - val_auc: 0.9496 - val_sensitivity_at_specificity: 0.9814 - val_specificity_at_sensitivity: 0.9940 - lr: 1.0000e-08\n",
            "Epoch 14/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2462 - binary_accuracy: 0.8989 - precision: 0.9129 - recall: 0.8820 - auc: 0.9619 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9974 - val_loss: 0.2867 - val_binary_accuracy: 0.8814 - val_precision: 0.8956 - val_recall: 0.8635 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9816 - val_specificity_at_sensitivity: 0.9941 - lr: 1.0000e-08\n",
            "Epoch 15/20\n",
            "3199/3199 [==============================] - 96s 30ms/step - loss: 0.2464 - binary_accuracy: 0.8987 - precision: 0.9125 - recall: 0.8819 - auc: 0.9618 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9972 - val_loss: 0.2869 - val_binary_accuracy: 0.8814 - val_precision: 0.8948 - val_recall: 0.8647 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9939 - lr: 1.0000e-09\n",
            "Epoch 16/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2464 - binary_accuracy: 0.8983 - precision: 0.9122 - recall: 0.8814 - auc: 0.9619 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.9974 - val_loss: 0.2869 - val_binary_accuracy: 0.8815 - val_precision: 0.8952 - val_recall: 0.8643 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9817 - val_specificity_at_sensitivity: 0.9939 - lr: 1.0000e-09\n",
            "Epoch 17/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2463 - binary_accuracy: 0.8984 - precision: 0.9121 - recall: 0.8817 - auc: 0.9619 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2868 - val_binary_accuracy: 0.8814 - val_precision: 0.8968 - val_recall: 0.8622 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9813 - val_specificity_at_sensitivity: 0.9942 - lr: 1.0000e-10\n",
            "Epoch 18/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2466 - binary_accuracy: 0.8981 - precision: 0.9117 - recall: 0.8815 - auc: 0.9618 - sensitivity_at_specificity: 0.9864 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2867 - val_binary_accuracy: 0.8815 - val_precision: 0.8953 - val_recall: 0.8643 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9940 - lr: 1.0000e-10\n",
            "Epoch 19/20\n",
            "3199/3199 [==============================] - 96s 30ms/step - loss: 0.2464 - binary_accuracy: 0.8984 - precision: 0.9124 - recall: 0.8816 - auc: 0.9619 - sensitivity_at_specificity: 0.9870 - specificity_at_sensitivity: 0.9974 - val_loss: 0.2868 - val_binary_accuracy: 0.8813 - val_precision: 0.8958 - val_recall: 0.8632 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9814 - val_specificity_at_sensitivity: 0.9941 - lr: 1.0000e-11\n",
            "Epoch 20/20\n",
            "3199/3199 [==============================] - 95s 30ms/step - loss: 0.2462 - binary_accuracy: 0.8983 - precision: 0.9119 - recall: 0.8818 - auc: 0.9619 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9973 - val_loss: 0.2868 - val_binary_accuracy: 0.8813 - val_precision: 0.8959 - val_recall: 0.8631 - val_auc: 0.9497 - val_sensitivity_at_specificity: 0.9816 - val_specificity_at_sensitivity: 0.9941 - lr: 1.0000e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "CBLANE = load_model(\"/content/huvecglobal.keras\")\n",
        "CBLANE.evaluate(test_sequences,test_labels,batch_size=4096)"
      ],
      "metadata": {
        "id": "-GF4szmvKZZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bdb0a9-bda7-475a-eade-a9c8f6e5f1e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 8s 198ms/step - loss: 0.2822 - binary_accuracy: 0.8814 - precision: 0.8923 - recall: 0.8672 - auc: 0.9505 - sensitivity_at_specificity: 0.9818 - specificity_at_sensitivity: 0.9950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28220033645629883,\n",
              " 0.8813672065734863,\n",
              " 0.8923183679580688,\n",
              " 0.8671590089797974,\n",
              " 0.9504679441452026,\n",
              " 0.9817558526992798,\n",
              " 0.9950023293495178]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MCF7 Cell Line Dataset"
      ],
      "metadata": {
        "id": "J4sO5y7UaYAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the data\n",
        "loaded_data = np.load('mf7.npz')\n",
        "\n",
        "# Extract the arrays\n",
        "train_sequences = loaded_data['train_sequences']\n",
        "train_labels = loaded_data['train_labels']\n",
        "test_sequences = loaded_data['test_sequences']\n",
        "test_labels = loaded_data['test_labels']\n",
        "validation_sequences = loaded_data['validation_sequences']\n",
        "validation_labels = loaded_data['validation_labels']\n",
        "\n",
        "# Optionally, you can print the shapes of the loaded arrays\n",
        "print(\"Train Sequences Shape:\", train_sequences.shape)\n",
        "print(\"Train Labels Shape:\", train_labels.shape)\n",
        "print(\"Test Sequences Shape:\", test_sequences.shape)\n",
        "print(\"Test Labels Shape:\", test_labels.shape)\n",
        "print(\"Validation Sequences Shape:\", validation_sequences.shape)\n",
        "print(\"Validation Labels Shape:\", validation_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad2a1b80-ea54-4aba-c7ac-02f9d20f35c8",
        "id": "vn5BQOQkaYA5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sequences Shape: (694552, 101, 4)\n",
            "Train Labels Shape: (694552,)\n",
            "Test Sequences Shape: (217057, 101, 4)\n",
            "Test Labels Shape: (217057,)\n",
            "Validation Sequences Shape: (173637, 101, 4)\n",
            "Validation Labels Shape: (173637,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "import os\n",
        "from keras.models import save_model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',mode=\"min\", factor=0.1, patience=2, min_lr=1e-20)\n",
        "early_stop = EarlyStopping(monitor='val_loss',mode=\"min\", patience=10, restore_best_weights=True)\n",
        "\n",
        "class SaveSubModels(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        model_directories = [f'model/{epoch}/CBLANE_A549.keras']\n",
        "\n",
        "        for directory in set(os.path.dirname(model_path) for model_path in model_directories):\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "        save_model(CBLANE, model_directories[0])"
      ],
      "metadata": {
        "id": "yh9MtodaaYA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import BinaryAccuracy, Precision, Recall, AUC, SensitivityAtSpecificity, SpecificityAtSensitivity\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "CBLANE = load_model(f\"CBLANE_global_dataset.keras\")\n",
        "\n",
        "CBLANE.compile(loss='binary_crossentropy',\n",
        "                             optimizer=Adam(learning_rate=0.0001),\n",
        "                             metrics=[BinaryAccuracy(),\n",
        "                                      Precision(),\n",
        "                                      Recall(),\n",
        "                                      AUC(),\n",
        "                                      SensitivityAtSpecificity(0.5),\n",
        "                                      SpecificityAtSensitivity(0.5),\n",
        "                                      ]\n",
        "                             )\n",
        "history = CBLANE.fit(tf.constant(train_sequences,dtype=tf.bool),\n",
        "                                   tf.constant(train_labels,dtype=tf.bool),\n",
        "                                   batch_size=128,\n",
        "                                   epochs=20,\n",
        "                                   verbose=1,\n",
        "                                   validation_data=(tf.constant(validation_sequences,dtype = tf.bool),\n",
        "                                                    tf.constant(validation_labels,dtype = tf.bool)),\n",
        "                                  validation_batch_size=4096,\n",
        "                                  callbacks=[reduce_lr,\n",
        "                                             SaveSubModels()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c75a4a3-8e95-4d04-a68b-168ee63adc39",
        "id": "PP7lIdg5aYA8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5427/5427 [==============================] - 204s 34ms/step - loss: 0.3133 - binary_accuracy: 0.8638 - precision: 0.8817 - recall: 0.8403 - auc: 0.9384 - sensitivity_at_specificity: 0.9754 - specificity_at_sensitivity: 0.9929 - val_loss: 0.2937 - val_binary_accuracy: 0.8738 - val_precision: 0.8987 - val_recall: 0.8421 - val_auc: 0.9463 - val_sensitivity_at_specificity: 0.9813 - val_specificity_at_sensitivity: 0.9941 - lr: 1.0000e-04\n",
            "Epoch 2/20\n",
            "5427/5427 [==============================] - 172s 32ms/step - loss: 0.2925 - binary_accuracy: 0.8743 - precision: 0.8906 - recall: 0.8534 - auc: 0.9465 - sensitivity_at_specificity: 0.9809 - specificity_at_sensitivity: 0.9945 - val_loss: 0.2866 - val_binary_accuracy: 0.8778 - val_precision: 0.8956 - val_recall: 0.8550 - val_auc: 0.9487 - val_sensitivity_at_specificity: 0.9818 - val_specificity_at_sensitivity: 0.9947 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "5427/5427 [==============================] - 171s 32ms/step - loss: 0.2824 - binary_accuracy: 0.8794 - precision: 0.8952 - recall: 0.8594 - auc: 0.9501 - sensitivity_at_specificity: 0.9825 - specificity_at_sensitivity: 0.9951 - val_loss: 0.2830 - val_binary_accuracy: 0.8795 - val_precision: 0.8958 - val_recall: 0.8585 - val_auc: 0.9500 - val_sensitivity_at_specificity: 0.9822 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "5427/5427 [==============================] - 168s 31ms/step - loss: 0.2741 - binary_accuracy: 0.8838 - precision: 0.8996 - recall: 0.8641 - auc: 0.9530 - sensitivity_at_specificity: 0.9837 - specificity_at_sensitivity: 0.9958 - val_loss: 0.2813 - val_binary_accuracy: 0.8807 - val_precision: 0.9005 - val_recall: 0.8555 - val_auc: 0.9507 - val_sensitivity_at_specificity: 0.9829 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "5427/5427 [==============================] - 170s 31ms/step - loss: 0.2667 - binary_accuracy: 0.8874 - precision: 0.9031 - recall: 0.8678 - auc: 0.9555 - sensitivity_at_specificity: 0.9849 - specificity_at_sensitivity: 0.9963 - val_loss: 0.2808 - val_binary_accuracy: 0.8811 - val_precision: 0.9010 - val_recall: 0.8559 - val_auc: 0.9513 - val_sensitivity_at_specificity: 0.9837 - val_specificity_at_sensitivity: 0.9954 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "5427/5427 [==============================] - 168s 31ms/step - loss: 0.2607 - binary_accuracy: 0.8902 - precision: 0.9053 - recall: 0.8714 - auc: 0.9575 - sensitivity_at_specificity: 0.9863 - specificity_at_sensitivity: 0.9965 - val_loss: 0.2797 - val_binary_accuracy: 0.8819 - val_precision: 0.9018 - val_recall: 0.8567 - val_auc: 0.9515 - val_sensitivity_at_specificity: 0.9835 - val_specificity_at_sensitivity: 0.9950 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "5427/5427 [==============================] - 170s 31ms/step - loss: 0.2542 - binary_accuracy: 0.8935 - precision: 0.9078 - recall: 0.8759 - auc: 0.9596 - sensitivity_at_specificity: 0.9875 - specificity_at_sensitivity: 0.9970 - val_loss: 0.2808 - val_binary_accuracy: 0.8822 - val_precision: 0.8985 - val_recall: 0.8612 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9831 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "5427/5427 [==============================] - 170s 31ms/step - loss: 0.2489 - binary_accuracy: 0.8964 - precision: 0.9107 - recall: 0.8790 - auc: 0.9612 - sensitivity_at_specificity: 0.9874 - specificity_at_sensitivity: 0.9969 - val_loss: 0.2804 - val_binary_accuracy: 0.8826 - val_precision: 0.8950 - val_recall: 0.8663 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9833 - val_specificity_at_sensitivity: 0.9953 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "5427/5427 [==============================] - 170s 31ms/step - loss: 0.2401 - binary_accuracy: 0.9003 - precision: 0.9153 - recall: 0.8822 - auc: 0.9639 - sensitivity_at_specificity: 0.9891 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2821 - val_binary_accuracy: 0.8826 - val_precision: 0.8987 - val_recall: 0.8620 - val_auc: 0.9518 - val_sensitivity_at_specificity: 0.9835 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 10/20\n",
            "5427/5427 [==============================] - 169s 31ms/step - loss: 0.2385 - binary_accuracy: 0.9011 - precision: 0.9156 - recall: 0.8837 - auc: 0.9643 - sensitivity_at_specificity: 0.9896 - specificity_at_sensitivity: 0.9976 - val_loss: 0.2821 - val_binary_accuracy: 0.8828 - val_precision: 0.8984 - val_recall: 0.8628 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9837 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-05\n",
            "Epoch 11/20\n",
            "5427/5427 [==============================] - 170s 31ms/step - loss: 0.2380 - binary_accuracy: 0.9012 - precision: 0.9153 - recall: 0.8842 - auc: 0.9645 - sensitivity_at_specificity: 0.9886 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8827 - val_precision: 0.8982 - val_recall: 0.8629 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9835 - val_specificity_at_sensitivity: 0.9947 - lr: 1.0000e-06\n",
            "Epoch 12/20\n",
            "5427/5427 [==============================] - 170s 31ms/step - loss: 0.2377 - binary_accuracy: 0.9015 - precision: 0.9157 - recall: 0.8843 - auc: 0.9646 - sensitivity_at_specificity: 0.9897 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8828 - val_precision: 0.8996 - val_recall: 0.8613 - val_auc: 0.9518 - val_sensitivity_at_specificity: 0.9832 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-06\n",
            "Epoch 13/20\n",
            "5427/5427 [==============================] - 168s 31ms/step - loss: 0.2377 - binary_accuracy: 0.9014 - precision: 0.9159 - recall: 0.8840 - auc: 0.9646 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8827 - val_precision: 0.8984 - val_recall: 0.8627 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9835 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-07\n",
            "Epoch 14/20\n",
            "5427/5427 [==============================] - 170s 31ms/step - loss: 0.2375 - binary_accuracy: 0.9016 - precision: 0.9160 - recall: 0.8841 - auc: 0.9646 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8828 - val_precision: 0.8994 - val_recall: 0.8615 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9831 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-07\n",
            "Epoch 15/20\n",
            "5427/5427 [==============================] - 169s 31ms/step - loss: 0.2375 - binary_accuracy: 0.9014 - precision: 0.9158 - recall: 0.8841 - auc: 0.9647 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9976 - val_loss: 0.2824 - val_binary_accuracy: 0.8826 - val_precision: 0.8999 - val_recall: 0.8605 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9831 - val_specificity_at_sensitivity: 0.9950 - lr: 1.0000e-08\n",
            "Epoch 16/20\n",
            "5427/5427 [==============================] - 168s 31ms/step - loss: 0.2370 - binary_accuracy: 0.9019 - precision: 0.9161 - recall: 0.8847 - auc: 0.9648 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8827 - val_precision: 0.8987 - val_recall: 0.8622 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9834 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-08\n",
            "Epoch 17/20\n",
            "5427/5427 [==============================] - 171s 31ms/step - loss: 0.2376 - binary_accuracy: 0.9014 - precision: 0.9155 - recall: 0.8844 - auc: 0.9646 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8827 - val_precision: 0.8995 - val_recall: 0.8611 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9831 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-09\n",
            "Epoch 18/20\n",
            "5427/5427 [==============================] - 168s 31ms/step - loss: 0.2374 - binary_accuracy: 0.9016 - precision: 0.9157 - recall: 0.8845 - auc: 0.9647 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8827 - val_precision: 0.8995 - val_recall: 0.8613 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9831 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-09\n",
            "Epoch 19/20\n",
            "5427/5427 [==============================] - 168s 31ms/step - loss: 0.2373 - binary_accuracy: 0.9017 - precision: 0.9159 - recall: 0.8846 - auc: 0.9647 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8828 - val_precision: 0.8993 - val_recall: 0.8615 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9831 - val_specificity_at_sensitivity: 0.9949 - lr: 1.0000e-10\n",
            "Epoch 20/20\n",
            "5427/5427 [==============================] - 170s 31ms/step - loss: 0.2378 - binary_accuracy: 0.9011 - precision: 0.9152 - recall: 0.8840 - auc: 0.9645 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9977 - val_loss: 0.2824 - val_binary_accuracy: 0.8827 - val_precision: 0.8987 - val_recall: 0.8622 - val_auc: 0.9517 - val_sensitivity_at_specificity: 0.9833 - val_specificity_at_sensitivity: 0.9948 - lr: 1.0000e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "CBLANE = keras.models.load_model(\"/content/mcf7global.keras\")\n",
        "CBLANE.evaluate(test_sequences,test_labels,batch_size=4096)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27710a0-3e46-4781-fdda-2d6798f345eb",
        "id": "9doN35UsaYA9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 13s 222ms/step - loss: 0.2830 - binary_accuracy: 0.8806 - precision: 0.8950 - recall: 0.8630 - auc: 0.9508 - sensitivity_at_specificity: 0.9826 - specificity_at_sensitivity: 0.9957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28302115201950073,\n",
              " 0.8805567026138306,\n",
              " 0.8950002193450928,\n",
              " 0.8629516363143921,\n",
              " 0.9507551789283752,\n",
              " 0.9825828671455383,\n",
              " 0.9957138895988464]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## H1Hesc Cell Line Dataset"
      ],
      "metadata": {
        "id": "I9j0noDq-f99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the data\n",
        "loaded_data = np.load('H1hesc.npz')\n",
        "\n",
        "# Extract the arrays\n",
        "train_sequences = loaded_data['train_sequences']\n",
        "train_labels = loaded_data['train_labels']\n",
        "test_sequences = loaded_data['test_sequences']\n",
        "test_labels = loaded_data['test_labels']\n",
        "validation_sequences = loaded_data['validation_sequences']\n",
        "validation_labels = loaded_data['validation_labels']\n",
        "\n",
        "# Optionally, you can print the shapes of the loaded arrays\n",
        "print(\"Train Sequences Shape:\", train_sequences.shape)\n",
        "print(\"Train Labels Shape:\", train_labels.shape)\n",
        "print(\"Test Sequences Shape:\", test_sequences.shape)\n",
        "print(\"Test Labels Shape:\", test_labels.shape)\n",
        "print(\"Validation Sequences Shape:\", validation_sequences.shape)\n",
        "print(\"Validation Labels Shape:\", validation_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da98fba-aeff-4c47-9465-1420611f6224",
        "id": "QpJFymTV-f-B"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sequences Shape: (972688, 101, 4)\n",
            "Train Labels Shape: (972688,)\n",
            "Test Sequences Shape: (303996, 101, 4)\n",
            "Test Labels Shape: (303996,)\n",
            "Validation Sequences Shape: (243172, 101, 4)\n",
            "Validation Labels Shape: (243172,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "import os\n",
        "from keras.models import save_model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',mode=\"min\", factor=0.1, patience=2, min_lr=1e-20)\n",
        "early_stop = EarlyStopping(monitor='val_loss',mode=\"min\", patience=10, restore_best_weights=True)\n",
        "\n",
        "class SaveSubModels(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        model_directories = [f'model/{epoch}/CBLANE_A549.keras']\n",
        "\n",
        "        for directory in set(os.path.dirname(model_path) for model_path in model_directories):\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "        save_model(CBLANE, model_directories[0])"
      ],
      "metadata": {
        "id": "NN5l_hu3-f-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import BinaryAccuracy, Precision, Recall, AUC, SensitivityAtSpecificity, SpecificityAtSensitivity\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "CBLANE = load_model(\"CBLANE_global_dataset.keras\")\n",
        "\n",
        "CBLANE.compile(loss='binary_crossentropy',\n",
        "                             optimizer=Adam(learning_rate=0.0001),\n",
        "                             metrics=[BinaryAccuracy(),\n",
        "                                      Precision(),\n",
        "                                      Recall(),\n",
        "                                      AUC(),\n",
        "                                      SensitivityAtSpecificity(0.5),\n",
        "                                      SpecificityAtSensitivity(0.5),\n",
        "                                      ]\n",
        "                             )\n",
        "history = CBLANE.fit(tf.constant(train_sequences,dtype=tf.bool),\n",
        "                                   tf.constant(train_labels,dtype=tf.bool),\n",
        "                                   batch_size=128,\n",
        "                                   epochs=20,\n",
        "                                   verbose=1,\n",
        "                                   validation_data=(tf.constant(validation_sequences,dtype = tf.bool),\n",
        "                                                    tf.constant(validation_labels,dtype = tf.bool)),\n",
        "                                  validation_batch_size=4096,\n",
        "                                  callbacks=[reduce_lr,\n",
        "                                             SaveSubModels()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d1712f-9edf-438f-ad76-742115ba5c0d",
        "id": "nBVUcxrScfZ5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "7600/7600 [==============================] - 271s 33ms/step - loss: 0.3323 - binary_accuracy: 0.8538 - precision: 0.8708 - recall: 0.8306 - auc: 0.9305 - sensitivity_at_specificity: 0.9719 - specificity_at_sensitivity: 0.9904 - val_loss: 0.3156 - val_binary_accuracy: 0.8619 - val_precision: 0.8817 - val_recall: 0.8365 - val_auc: 0.9375 - val_sensitivity_at_specificity: 0.9744 - val_specificity_at_sensitivity: 0.9923 - lr: 1.0000e-04\n",
            "Epoch 2/20\n",
            "7600/7600 [==============================] - 244s 32ms/step - loss: 0.3150 - binary_accuracy: 0.8632 - precision: 0.8799 - recall: 0.8410 - auc: 0.9377 - sensitivity_at_specificity: 0.9748 - specificity_at_sensitivity: 0.9927 - val_loss: 0.3097 - val_binary_accuracy: 0.8644 - val_precision: 0.8846 - val_recall: 0.8385 - val_auc: 0.9399 - val_sensitivity_at_specificity: 0.9762 - val_specificity_at_sensitivity: 0.9933 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "7600/7600 [==============================] - 228s 30ms/step - loss: 0.3053 - binary_accuracy: 0.8681 - precision: 0.8844 - recall: 0.8467 - auc: 0.9415 - sensitivity_at_specificity: 0.9778 - specificity_at_sensitivity: 0.9939 - val_loss: 0.3074 - val_binary_accuracy: 0.8661 - val_precision: 0.8930 - val_recall: 0.8324 - val_auc: 0.9411 - val_sensitivity_at_specificity: 0.9775 - val_specificity_at_sensitivity: 0.9940 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "7600/7600 [==============================] - 228s 30ms/step - loss: 0.2973 - binary_accuracy: 0.8719 - precision: 0.8881 - recall: 0.8509 - auc: 0.9446 - sensitivity_at_specificity: 0.9792 - specificity_at_sensitivity: 0.9947 - val_loss: 0.3054 - val_binary_accuracy: 0.8672 - val_precision: 0.8757 - val_recall: 0.8562 - val_auc: 0.9419 - val_sensitivity_at_specificity: 0.9779 - val_specificity_at_sensitivity: 0.9938 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "7600/7600 [==============================] - 236s 31ms/step - loss: 0.2904 - binary_accuracy: 0.8754 - precision: 0.8906 - recall: 0.8559 - auc: 0.9472 - sensitivity_at_specificity: 0.9805 - specificity_at_sensitivity: 0.9953 - val_loss: 0.3042 - val_binary_accuracy: 0.8678 - val_precision: 0.8868 - val_recall: 0.8436 - val_auc: 0.9423 - val_sensitivity_at_specificity: 0.9783 - val_specificity_at_sensitivity: 0.9942 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "7600/7600 [==============================] - 242s 32ms/step - loss: 0.2848 - binary_accuracy: 0.8784 - precision: 0.8931 - recall: 0.8595 - auc: 0.9492 - sensitivity_at_specificity: 0.9818 - specificity_at_sensitivity: 0.9954 - val_loss: 0.3033 - val_binary_accuracy: 0.8685 - val_precision: 0.8811 - val_recall: 0.8523 - val_auc: 0.9427 - val_sensitivity_at_specificity: 0.9784 - val_specificity_at_sensitivity: 0.9939 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "7600/7600 [==============================] - 238s 31ms/step - loss: 0.2794 - binary_accuracy: 0.8812 - precision: 0.8963 - recall: 0.8621 - auc: 0.9511 - sensitivity_at_specificity: 0.9816 - specificity_at_sensitivity: 0.9961 - val_loss: 0.3038 - val_binary_accuracy: 0.8686 - val_precision: 0.8918 - val_recall: 0.8393 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9778 - val_specificity_at_sensitivity: 0.9942 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "7600/7600 [==============================] - 229s 30ms/step - loss: 0.2740 - binary_accuracy: 0.8840 - precision: 0.8987 - recall: 0.8654 - auc: 0.9530 - sensitivity_at_specificity: 0.9830 - specificity_at_sensitivity: 0.9960 - val_loss: 0.3043 - val_binary_accuracy: 0.8689 - val_precision: 0.8877 - val_recall: 0.8451 - val_auc: 0.9427 - val_sensitivity_at_specificity: 0.9789 - val_specificity_at_sensitivity: 0.9941 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "7600/7600 [==============================] - 234s 31ms/step - loss: 0.2657 - binary_accuracy: 0.8880 - precision: 0.9026 - recall: 0.8698 - auc: 0.9557 - sensitivity_at_specificity: 0.9843 - specificity_at_sensitivity: 0.9968 - val_loss: 0.3055 - val_binary_accuracy: 0.8690 - val_precision: 0.8894 - val_recall: 0.8432 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9785 - val_specificity_at_sensitivity: 0.9939 - lr: 1.0000e-05\n",
            "Epoch 10/20\n",
            "7600/7600 [==============================] - 233s 31ms/step - loss: 0.2645 - binary_accuracy: 0.8886 - precision: 0.9029 - recall: 0.8707 - auc: 0.9562 - sensitivity_at_specificity: 0.9844 - specificity_at_sensitivity: 0.9966 - val_loss: 0.3061 - val_binary_accuracy: 0.8692 - val_precision: 0.8881 - val_recall: 0.8451 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9780 - val_specificity_at_sensitivity: 0.9934 - lr: 1.0000e-05\n",
            "Epoch 11/20\n",
            "7600/7600 [==============================] - 242s 32ms/step - loss: 0.2635 - binary_accuracy: 0.8892 - precision: 0.9040 - recall: 0.8707 - auc: 0.9565 - sensitivity_at_specificity: 0.9843 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3060 - val_binary_accuracy: 0.8691 - val_precision: 0.8882 - val_recall: 0.8450 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9781 - val_specificity_at_sensitivity: 0.9935 - lr: 1.0000e-06\n",
            "Epoch 12/20\n",
            "7600/7600 [==============================] - 241s 32ms/step - loss: 0.2633 - binary_accuracy: 0.8893 - precision: 0.9038 - recall: 0.8713 - auc: 0.9565 - sensitivity_at_specificity: 0.9842 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3064 - val_binary_accuracy: 0.8690 - val_precision: 0.8902 - val_recall: 0.8422 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9772 - val_specificity_at_sensitivity: 0.9936 - lr: 1.0000e-06\n",
            "Epoch 13/20\n",
            "7600/7600 [==============================] - 228s 30ms/step - loss: 0.2634 - binary_accuracy: 0.8892 - precision: 0.9038 - recall: 0.8711 - auc: 0.9565 - sensitivity_at_specificity: 0.9843 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3064 - val_binary_accuracy: 0.8690 - val_precision: 0.8880 - val_recall: 0.8450 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9779 - val_specificity_at_sensitivity: 0.9933 - lr: 1.0000e-07\n",
            "Epoch 14/20\n",
            "7600/7600 [==============================] - 228s 30ms/step - loss: 0.2630 - binary_accuracy: 0.8895 - precision: 0.9041 - recall: 0.8714 - auc: 0.9566 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3062 - val_binary_accuracy: 0.8690 - val_precision: 0.8870 - val_recall: 0.8462 - val_auc: 0.9427 - val_sensitivity_at_specificity: 0.9782 - val_specificity_at_sensitivity: 0.9933 - lr: 1.0000e-07\n",
            "Epoch 15/20\n",
            "7600/7600 [==============================] - 229s 30ms/step - loss: 0.2630 - binary_accuracy: 0.8894 - precision: 0.9038 - recall: 0.8714 - auc: 0.9566 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9968 - val_loss: 0.3062 - val_binary_accuracy: 0.8691 - val_precision: 0.8876 - val_recall: 0.8456 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9781 - val_specificity_at_sensitivity: 0.9933 - lr: 1.0000e-08\n",
            "Epoch 16/20\n",
            "7600/7600 [==============================] - 242s 32ms/step - loss: 0.2631 - binary_accuracy: 0.8891 - precision: 0.9037 - recall: 0.8710 - auc: 0.9566 - sensitivity_at_specificity: 0.9844 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3062 - val_binary_accuracy: 0.8691 - val_precision: 0.8888 - val_recall: 0.8441 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9778 - val_specificity_at_sensitivity: 0.9936 - lr: 1.0000e-08\n",
            "Epoch 17/20\n",
            "7600/7600 [==============================] - 234s 31ms/step - loss: 0.2632 - binary_accuracy: 0.8893 - precision: 0.9038 - recall: 0.8712 - auc: 0.9566 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3063 - val_binary_accuracy: 0.8690 - val_precision: 0.8890 - val_recall: 0.8437 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9777 - val_specificity_at_sensitivity: 0.9936 - lr: 1.0000e-09\n",
            "Epoch 18/20\n",
            "7600/7600 [==============================] - 231s 30ms/step - loss: 0.2632 - binary_accuracy: 0.8893 - precision: 0.9041 - recall: 0.8708 - auc: 0.9566 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3063 - val_binary_accuracy: 0.8689 - val_precision: 0.8896 - val_recall: 0.8428 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9774 - val_specificity_at_sensitivity: 0.9936 - lr: 1.0000e-09\n",
            "Epoch 19/20\n",
            "7600/7600 [==============================] - 239s 31ms/step - loss: 0.2631 - binary_accuracy: 0.8894 - precision: 0.9037 - recall: 0.8714 - auc: 0.9566 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3063 - val_binary_accuracy: 0.8690 - val_precision: 0.8890 - val_recall: 0.8438 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9776 - val_specificity_at_sensitivity: 0.9935 - lr: 1.0000e-10\n",
            "Epoch 20/20\n",
            "7600/7600 [==============================] - 250s 33ms/step - loss: 0.2632 - binary_accuracy: 0.8897 - precision: 0.9041 - recall: 0.8717 - auc: 0.9566 - sensitivity_at_specificity: 0.9842 - specificity_at_sensitivity: 0.9967 - val_loss: 0.3062 - val_binary_accuracy: 0.8691 - val_precision: 0.8883 - val_recall: 0.8448 - val_auc: 0.9428 - val_sensitivity_at_specificity: 0.9779 - val_specificity_at_sensitivity: 0.9935 - lr: 1.0000e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "CBLANE = load_model(f\"/content/model/5/CBLANE_A549.keras\")\n",
        "CBLANE.evaluate(test_sequences,test_labels,batch_size=4096)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7c4aef-0a4e-4383-e545-4da742ce1c3f",
        "id": "E2QUwPQPb4BT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 17s 200ms/step - loss: 0.3043 - binary_accuracy: 0.8689 - precision: 0.8809 - recall: 0.8536 - auc: 0.9423 - sensitivity_at_specificity: 0.9773 - specificity_at_sensitivity: 0.9936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30429914593696594,\n",
              " 0.868942379951477,\n",
              " 0.8808803558349609,\n",
              " 0.8535835146903992,\n",
              " 0.9422830939292908,\n",
              " 0.977332353591919,\n",
              " 0.9936051368713379]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "d7Hur2BsKard"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "CBLANE.summary(expand_nested=True)"
      ],
      "metadata": {
        "id": "E_7bCOoUB5hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Result"
      ],
      "metadata": {
        "id": "TF_LcdooYvEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Convolutional_Block = CEBLANE.get_layer('Convolutional_Block')\n",
        "Convolutional_Block_output = Convolutional_Block.predict(test_features[0:1]) #False Labelled Sequence\n",
        "sns.heatmap(Convolutional_Block_output.reshape((25,64)), cmap='Blues')\n",
        "plt.title('Heatmap of Encoded Sequence Before Attention')\n",
        "plt.show()\n",
        "\n",
        "BiLSTM_Attention_block = CEBLANE.get_layer('model_213')\n",
        "attention_model = Model(inputs=BiLSTM_Attention_block.input, outputs=BiLSTM_Attention_block.layers[-4].output)\n",
        "attention_scores = attention_model.predict(Convolutional_Block_output)\n",
        "sns.heatmap(attention_scores[0].reshape((25,64)), cmap='Blues')\n",
        "plt.title('Heatmap of Encoded Sequence After Attention')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3xHXCqIyNv1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Convolutional_Block = CEBLANE.get_layer('Convolutional_Block')\n",
        "Convolutional_Block_output = Convolutional_Block.predict(test_features[2:3]) #True Labelled Sequence\n",
        "sns.heatmap(Convolutional_Block_output.reshape((25,64)), cmap='Blues')\n",
        "plt.title('Heatmap of Encoded Sequence Before Attention')\n",
        "plt.show()\n",
        "\n",
        "BiLSTM_Attention_block = CEBLANE.get_layer('model_213')\n",
        "attention_model = Model(inputs=BiLSTM_Attention_block.input, outputs=BiLSTM_Attention_block.layers[-4].output)\n",
        "attention_scores = attention_model.predict(Convolutional_Block_output)\n",
        "sns.heatmap(attention_scores[0].reshape((25,64)), cmap='Blues')\n",
        "plt.title('Heatmap of Encoded Sequence After Attention')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lgTEkOOrS_r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Head Scores"
      ],
      "metadata": {
        "id": "-pdgkhJFYnNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = att[1].reshape((8,25,25))\n",
        "for i,attention_score in enumerate(attention_scores):\n",
        "  sns.heatmap(attention_score, cmap='Blues')\n",
        "  plt.title(f'Heatmap of Attention Scores of Attention Head {i+1}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rc1mrmefSD-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Output"
      ],
      "metadata": {
        "id": "2iS8xsfwYi4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[:10])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "Encoder_output = CEBLANE.predict(test_features[1:3]) #False and True Labeled Sequence\n",
        "\n",
        "false_score = test_prob[0].astype(float)\n",
        "true_score = test_prob[2].astype(float)\n",
        "\n",
        "sns.heatmap(Encoder_output, cmap='Blues', yticklabels=[f'False {false_score}',f'True {true_score}'], ax=ax, fmt=\".2f\", linewidths=.5, annot_kws={\"size\": 10})\n",
        "\n",
        "plt.title('Heatmap of Encoded Sequence')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_H37IwgSBsiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}